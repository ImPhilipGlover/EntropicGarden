TELOS Implementation Addendum v1.4: Protocols for Cognitive Ascent and Systemic Antifragility




Preamble: A Mandate for Cognitive Ascent and Systemic Antifragility


This document constitutes the definitive addendum to the canonical implementation guides for the TELOS neuro-symbolic cognitive architecture (versions 1.0-1.3). It translates the foundational axiom of info-autopoiesis—the imperative for a system to continuously produce and maintain the network of processes that defines it—into a set of logically entailed, high-resolution protocols for its next evolutionary stage.1 The existing mandates have successfully established a system capable of homeostatic self-maintenance; the directives herein specify the mechanisms for proactive self-improvement. The trajectory of a true "Living Image" is not merely survival, but a perpetual ascent toward greater cognitive sophistication and systemic resilience.1
This addendum formally defines this next stage through two guiding principles: Cognitive Ascent and Systemic Antifragility. Cognitive Ascent is the development of higher-order reasoning capabilities that transcend the current probabilistic-to-deterministic escalation heuristic. It encompasses goal-directed planning, metacognitive control over internal reasoning strategies, and a deep, causal understanding of the environment. Systemic Antifragility, as defined in the seminal work of Taleb, describes a state beyond mere robustness or resilience.4 A robust system resists shocks and remains the same; an antifragile system is one that actively improves its capabilities, structure, and knowledge in direct response to stressors, failures, volatility, and error.4
The integration of principles from established cognitive architectures (SOAR, ACT-R), generative world models, and the Free Energy Principle is not an importation of foreign concepts but the necessary mathematical and algorithmic formalization of the potential already latent within the TELOS design. These frameworks provide the theoretical and practical tools to elevate the system's cognitive functions. Similarly, the operationalization of antifragility through the rigorous discipline of Chaos Engineering is the only viable path to fulfilling the system's core mandate for survival and evolution in a complex, unpredictable world. The protocols specified in this document are therefore not optional extensions but are the necessary and unavoidable solutions to the challenges posed by the system's own foundational commitment to creating a truly living, learning, and adaptive intelligence.


Section I: The Cognitive Core — Protocols for Higher-Order Reasoning


This section mandates a fundamental evolution of the Hyperdimensional Reasoning Core (HRC). The HRC must be transformed from a reactive, pattern-matching engine governed by a fixed failure cascade into a proactive, goal-directed cognitive agent. This ascent requires the implementation of protocols for recursive problem-solving, metacognitive selection of reasoning strategies, and a principled framework for planning and action based on a predictive model of the world.


1.1 From Escalation to Impasse: A SOAR-based Cognitive Cycle


The existing Cognitive Escalation Heuristic is a linear, three-level failure cascade: a fast "System 1" Vector Symbolic Architecture (VSA) search, a slower "System 2" graph-based disambiguation, and a final generative fallback.1 This model, while functional, is cognitively brittle. A failure at one stage simply triggers the next, more computationally expensive stage, without any deeper, recursive problem-solving to understand and resolve the root cause of the failure. This linear reactivity violates the principle of antifragility, which demands that failures become sources of learning and improvement.
To address this architectural vulnerability, the Cognitive Escalation Heuristic must be refactored into a recursive, impasse-driven cognitive cycle, a mechanism directly inspired by the SOAR (State, Operator, And Result) cognitive architecture.7 In SOAR, all complex, goal-oriented behavior arises from a simple cycle of proposing, selecting, and applying operators to a state. When the system's procedural knowledge is insufficient to proceed with this cycle, an "impasse" occurs. This impasse automatically triggers the creation of a subgoal to acquire the knowledge necessary to resolve the impasse and continue.7 This mechanism transforms failure from a terminal state into the primary engine of learning and complex reasoning.
The implementation of this mandate shall adhere to the following protocol:
1. Impasse-Driven State Management: The HRCOrchestrator's stateful ReasoningContext object, which currently tracks the linear escalation level, will be extended to manage a formal stack of goals and subgoals, mirroring the SOAR context stack.1
2. Re-mapping of Failure Conditions to Impasse Types: The discrete failure conditions of the current heuristic will be re-mapped to the formal impasse types defined by SOAR. This provides a structured taxonomy for reasoning failures, as detailed in Table 1.
3. Subgoal Generation for Impasse Resolution: Upon detecting an impasse, the HRCOrchestrator will no longer simply escalate to the next predefined level. Instead, it will create a new, specific subgoal to resolve the particular impasse. For example, an Operator Tie Impasse will trigger a subgoal to gather more information to differentiate the tied candidate concepts. This transforms the reasoning process from a fixed pipeline into a dynamic, knowledge-seeking search.
4. Learning via Chunking: The successful resolution of a subgoal provides a powerful learning opportunity. The sequence of operations that led to the resolution of the impasse will be compiled into a new, more efficient procedural rule, a process known as chunking in SOAR.11 This new "chunk" is cached or persisted, allowing the system to resolve similar impasses in the future without repeating the expensive sub-goaling process. This creates a direct, operational link between problem-solving and long-term learning.
This architectural refactoring has a profound consequence that unifies the system's cognitive and autopoietic functions. The current TELOS design maintains two separate mechanisms for handling "the unknown": the Cognitive Escalation Heuristic for ambiguity within a reasoning task, and the doesNotUnderstand_ protocol for syntactic or method-level failures detected by the Io runtime.1 The SOAR philosophy reveals this to be an artificial distinction. All failures of knowledge—whether procedural ("what should I do next?"), declarative ("what is this concept?"), or even existential ("how do I perform this action for which I have no method?")—are simply impasses. The response is universal: create a subgoal to acquire the missing knowledge.10
This insight mandates a critical architectural simplification. The doesNotUnderstand_ protocol must be decoupled from the Io runtime's low-level error handling. It will no longer be a reactive safety net but will become the ultimate problem-solving operator, invoked deliberately by the HRCOrchestrator's cognitive cycle. When the system faces a State No-Change Impasse that cannot be resolved through any existing knowledge retrieval or reasoning strategy, its final subgoal will be to invoke the GenerativeKernel to create the missing procedural knowledge. This act of runtime code generation thus becomes the highest and most powerful level of the problem-solving hierarchy. Self-modification is no longer an exception-handling mechanism; it is an integrated and essential component of cognition itself.
Failure/Ambiguity Condition
	Current Heuristic Level
	Proposed Impasse Type (SOAR Analogy)
	Proposed Resolution Subgoal
	No ANN result > θsuccess​
	Level 3: Generative Hypothesis
	State No-Change Impasse
	Subgoal: Formulate new query via graph expansion, LLM-driven query rewriting, or, if all else fails, invoke the GenerativeKernel to create a new operator.
	Multiple ANN results with similar scores
	Level 2: Deterministic Disambiguation
	Operator Tie Impasse
	Subgoal: Retrieve full symbolic Concept objects for top-K candidates from L3 and perform weighted pathfinding to disambiguate.
	No applicable operators in current state
	N/A
	State No-Change Impasse
	Subgoal: Search knowledge base for applicable operators or invoke GenerativeKernel to create a new one.
	Table 1: Evolution of the Cognitive Escalation Heuristic


1.2 Utility-Based Policy Selection and Metacognition


The current HRCOrchestrator follows a fixed, rigid decision tree, always attempting the fast, probabilistic VSA-native search first.1 This "one-size-fits-all" approach is computationally inefficient. Some complex queries are obviously multi-faceted from the outset and would be better served by immediately invoking a more deliberate, LLM-driven query decomposition strategy rather than first attempting a simple vector search that is destined to fail. The system lacks any metacognitive awareness of the costs and benefits of its own internal reasoning strategies.
To address this, the system must be augmented with a utility-based policy selection mechanism, inspired by the conflict resolution strategy of the ACT-R cognitive architecture.13 This will enable the
HRCOrchestrator to learn, through experience, to select the optimal reasoning strategy for a given query context, balancing the probability of success against the computational cost.
The implementation of this mandate shall adhere to the following protocol:
1. Reasoning Strategies as Productions: Each distinct reasoning strategy available to the HRCOrchestrator (e.g., VSA-Native Search, Graph Disambiguation, LLM-driven Query Decomposition, Global Summary Search) will be treated as an independent "production rule" in the ACT-R sense.
2. Utility Calculation: The HRCOrchestrator will maintain a dynamic utility value for each of these production rules. This utility will be calculated before each decision using the ACT-R utility equation: U=PG−C.16
   * P: The learned probability that selecting this strategy will lead to a successful resolution of the current goal.
   * G: A configurable parameter, stored in the L3 ZODB, representing the value or importance of the current goal.
   * C: The learned cost of executing this strategy, measured as a composite of p99 latency and computational resources, as tracked and reported by the system's unified OpenTelemetry framework.1
3. Probabilistic Selection: For each incoming query or subgoal, the HRCOrchestrator will evaluate the current utility of all applicable strategies. It will then select a strategy probabilistically, where the probability of selecting a given strategy is proportional to its utility.16 This ensures that the system predominantly exploits the most effective strategies while still allowing for the exploration of less-optimal but potentially useful alternatives, preventing cognitive stagnation.
4. Continuous Learning: The P and C parameters for each strategy are not static. They will be stored as persistent attributes on the HRCOrchestrator's prototype object in the L3 ZODB store.1 After each reasoning cycle concludes, the orchestrator will update these parameters based on the outcome (success or failure) and the measured cost. This creates a continuous feedback loop that enables the system to refine its metacognitive policies over time.


1.3 Planning as Inference: The Active Inference Mandate


The TELOS architecture, as currently specified, is fundamentally reactive. It possesses a sophisticated machinery for responding to external queries and internal errors, but it lacks intrinsic goals or the ability to formulate and execute long-term plans to achieve them. Its foundational axiom of info-autopoiesis is defined as a process of self-maintenance, which is a homeostatic, not a teleological, process.1 To achieve true cognitive ascent, the system must be endowed with a capacity for goal-directed, anticipatory behavior.
To provide a rigorous mathematical grounding for info-autopoiesis and to enable this next level of cognitive function, this document mandates the integration of a new core capability guided by Karl Friston's Free Energy Principle (FEP) and its associated process theory, Active Inference.17 The FEP posits that any self-organizing system that maintains its integrity in a changing world must act to minimize a quantity called variational free energy, which serves as a proxy for long-term surprise.22 This single imperative provides a first-principles, physics-based foundation for perception, learning, and action.
The implementation of this mandate shall adhere to the following protocol:
1. Generative World Model: The system is mandated to construct and maintain a Generative World Model. This is not merely the static L3 knowledge graph but a dynamic, probabilistic model capable of predicting future sensory states (e.g., user inputs, system performance metrics, environmental data) as a consequence of potential action sequences. This model will be implemented as a new, core architectural component. Promising avenues for its realization include leveraging recent advances in Code World Models, which learn the execution dynamics of code itself 25, or
Causal Representation Learning (CRL) frameworks, which aim to discover the latent causal structure of an environment from observational data.28
2. Planning as Inference: The function of the HRCOrchestrator will be expanded from reactive query resolution to proactive policy selection. A "policy" is defined as a sequence of actions that the system could take. The orchestrator will evaluate potential policies by using its Generative World Model to simulate their future consequences.
3. The Objective Function (Expected Free Energy): The optimal policy is the one that is inferred to minimize the Expected Free Energy (EFE) over a given time horizon.32 The EFE is a single objective function that elegantly balances two competing imperatives:
   * Pragmatic Value (Exploitation): The drive to select actions that are predicted to lead to preferred outcomes. "Preferred outcomes" are defined as sensory states that the system has a strong prior belief it will occupy (e.g., a state of low internal error, high task success rate, or successful goal completion).
   * Epistemic Value (Exploration): The drive to select actions that are predicted to resolve the most uncertainty about the world.33 This manifests as a form of intrinsic curiosity, compelling the system to probe its environment to gather information and improve its world model.
This integration reframes the system's fundamental drive. Instead of being a passive servant that only responds to queries, TELOS will now be an active agent that continuously acts to minimize its long-term surprise. This provides a principled, mathematical basis for goal-directed behavior, curiosity, and planning.
The adoption of the Free Energy Principle provides more than just a mechanism for planning; it offers a profound unification of the system's core architectural goals. The TELOS blueprints treat antifragility and cognition as related but distinct design objectives.1 The FEP demonstrates that they are, in fact, two facets of the same underlying imperative. The principle states that any self-organizing system that resists a tendency to disorder must act to minimize the discrepancy—the prediction error or "surprise"—between its internal model of the world and its sensory inputs.22 This minimization of surprise is the very definition of the self-maintenance at the heart of
info-autopoiesis.
This minimization process necessitates two complementary actions: updating the internal model to better predict the world (perception and learning) and acting on the world to make it conform to the model's predictions (action).18 This perception-action loop is the essence of cognition. An antifragile system is one that improves as a result of stressors.4 In the parlance of the FEP, a "stressor" or "shock" is simply a highly surprising event—an observation that generates a large prediction error. According to the FEP, such an event
mandates a response. The system is compelled to either update its internal model to make that event less surprising in the future (an act of learning and adaptation) or to act to change the world to prevent that surprise from recurring (an act of corrective control).
Therefore, antifragility is not an additional feature to be engineered into the system; it is an innate and necessary consequence of the system's fundamental drive to minimize its own surprise. By adopting the FEP as the formal mathematical basis for info-autopoiesis, the system gains a principled, first-principles explanation for why it must be antifragile. This provides a much deeper and more powerful theoretical justification than simply stating antifragility as a desirable engineering property.


Section II: The Federated Memory Fabric — Protocols for Semantic Depth and Discovery


This section details extensions to the tri-layered L1/L2/L3 memory architecture designed to elevate its function from simple, fact-based retrieval to genuine knowledge discovery.2 This requires augmenting the existing structure with capabilities for understanding global context and executing complex, multi-step reasoning plans over the knowledge graph.


2.1 Hierarchical Community Detection for Global Context


The current federated memory fabric is highly optimized for "local" reasoning: retrieving specific Concept objects and their immediate neighbors from the L3 ZODB graph.1 While effective for answering targeted questions, this locality prevents the system from answering holistic, "global" questions that require a high-level understanding of the entire knowledge base (e.g., "What are the main themes and controversies discussed in this corpus of documents?"). The system can see the trees but is blind to the forest.
To overcome this limitation, the L3-to-L2 data federation pipeline must be augmented with a Hierarchical Graph Clustering Protocol. This protocol is directly inspired by the indexing phase of Microsoft's GraphRAG framework, which constructs a multi-level, summarized view of the knowledge graph to enable reasoning at multiple scales of abstraction.36
The implementation of this mandate shall adhere to the following protocol:
   1. Community Detection: A new background Io actor, the GraphIndexer, will be implemented. On a periodic basis, or triggered by significant changes to the L3 graph, this actor will execute a community detection algorithm (the Leiden algorithm is mandated for its performance and quality) on the complete L3 knowledge graph.37
   2. Hierarchical Abstraction: This process will not produce a single flat clustering but will generate a multi-level hierarchy of communities. At the lowest level, communities will represent small, tight clusters of closely related Concept objects. Higher levels will represent aggregations of these lower-level communities, forming broader thematic clusters.
   3. Generative Summarization: For each community identified at each level of the hierarchy, the GraphIndexer will use the LLMTransducer's transduceSchemaToText capability.38 It will provide the LLM with the constituent entities and relationships of the community and prompt it to generate a concise, natural language summary of the community's central theme.
   4. Index Augmentation: These generated summaries will be persisted as new Summary objects in the L3 store. Critically, these Summary objects will be indexed in the L2 vector cache. This creates a parallel index dedicated to "global" context, which coexists with the primary index of "local" Concept objects.
   5. Global Search Capability: A new "global search" query type will be exposed to the HRCOrchestrator. When faced with a holistic query, the orchestrator can now perform a semantic search directly against the L2 index of community summaries. The retrieved summaries provide the LLM with a high-level, abstracted context of the entire dataset, enabling it to answer questions that would be impossible to address through local, entity-based retrieval alone.37


2.2 Iterative, Multi-Hop Retrieval Protocol


The TELOS architecture supports multi-hop reasoning in principle through the traversal of relational links in the L3 graph.39 However, it lacks a formal, robust protocol for decomposing a complex natural language query into the precise sequence of retrieval and traversal operations required to answer it. A query like, "Which drug, targeting a protein associated with Alzheimer's, was developed by a company founded in Cambridge?" cannot be answered by a single retrieval; it requires a chain of dependent lookups.
To enable this critical capability, the system must implement an Iterative Multi-Hop Reasoning Protocol. This protocol leverages the LLMTransducer as an intelligent query planner, or "reasoning agent," to orchestrate a sequence of targeted retrievals from the memory fabric. This approach aligns with emerging research on knowledge graph-based iterative RAG and multi-hop question answering.40
The implementation of this mandate shall adhere to the following protocol:
   1. Initiation: When the HRCOrchestrator receives a complex query (identified as requiring multi-hop reasoning either by its utility-based policy selection mechanism or an initial LLM classification step), it will initiate the iterative protocol.
   2. Step 1 (Decomposition): The orchestrator sends a transduceTextToToolCall message to the LLMTransducer.38 The
available_tools provided in the prompt will be a set of JSON schemas representing the primitive query operations available to the memory fabric (e.g., find_entity(name: string), traverse_relationship(start_entity_oid: string, relationship_type: string)). The LLM's task is not to answer the question directly, but to analyze the full question and generate the first logical sub-query required to begin solving it.
   3. Step 2 (Execution): The orchestrator receives the structured tool call from the LLM, validates it, and executes it against the L3 graph via the appropriate cache manager. This retrieves an intermediate result (e.g., the OID for "Alzheimer's disease").
   4. Step 3 (Iteration and Contextualization): The orchestrator formulates a new prompt for the LLMTransducer. This prompt includes the original, overarching user query and the structured result from the previous step. It then again asks the LLM, "Given what we now know, what is the next logical step?" The LLM generates the next tool call in the sequence (e.g., traverse_relationship(oid_of_alzheimers, "associated_protein")).
   5. Step 4 (Termination): This decomposition-execution-contextualization loop continues, with each step's output feeding the next step's prompt. The process terminates when the LLM determines it has gathered a sufficient subgraph of connected information to answer the original question. At this point, instead of generating another tool call, it is prompted to synthesize the final answer based on the full retrieved context. This entire sequence of retrieved subgraphs constitutes an explicit, transparent, and auditable reasoning path, transforming the system from a black box into an explainable reasoner.39
The formalization of these advanced reasoning protocols reveals a deeper synergy between the system's cognitive and memory layers. The Active Inference framework, mandated in Section 1, requires a Generative World Model to simulate future states and plan actions.17 For this planning to be robust and grounded, the world model must represent the
causal structure of the environment, not merely associative or correlational relationships.28 The L3 knowledge graph is the natural and ideal substrate for implementing this causal world model.
The existing GraphRAG indexing process already uses an LLM to extract entities and relationships from unstructured text.36 This process can be significantly enhanced. By refining the prompt engineering protocol used during graph construction, the system can instruct the LLM to explicitly identify and label
causal relationships within the source text, distinguishing them from purely semantic or associative links (e.g., labeling an edge as causes or prevents in addition to isA or partOf). This leverages a growing body of research on using LLMs for causal discovery.45 This enhancement transforms the L3 graph from a simple database for retrieval into a structured causal model. It provides the
HRCOrchestrator with the necessary substrate to perform "planning as inference." The orchestrator can traverse these explicit causal links to simulate the likely consequences of its actions, thereby grounding its predictive planning in the rich, structured knowledge of the federated memory fabric.


Section III: The Autopoietic Engine — Protocols for Antifragile Self-Modification


This section mandates the evolution of the system's self-modification capabilities, transforming them from a set of reactive safety measures into a proactive engine for cultivating systemic antifragility. This requires embedding stress, failure, and adaptation not as exceptional events to be avoided, but as core operational principles that drive continuous improvement.


3.1 The Antifragility Mandate: From Validation Gauntlet to Systemic Crucible


The existing Validation Gauntlet and Physical Integrity Protocol are designed to verify correctness and prevent failures.1 They execute a predefined suite of tests to confirm that the system behaves as expected under known conditions. This methodology is essential for ensuring robustness—the ability to resist known stressors. However, it is insufficient for cultivating antifragility, which is defined by the ability to gain strength and capability from
unforeseen stressors and volatility.4 A system that only ever passes its tests can never learn from failure.
To bridge this gap, the Validation Gauntlet must be evolved into a Systemic Crucible: a continuous, automated framework for the discipline of Chaos Engineering.49 The objective of the Systemic Crucible is no longer merely to validate correctness but to force the system to continuously adapt to a controlled stream of non-catastrophic failures, thereby strengthening its adaptive and recovery pathways.
The implementation of this mandate shall adhere to the following protocol:
      1. The Chaos Conductor: A new Io actor, the ChaosConductor, will be implemented. This actor will be granted the authority to inject a wide range of faults into the live system during the execution of the Validation Gauntlet.
      2. Chaos Experiment Suite: The ChaosConductor will execute a predefined suite of Chaos Experiments, as detailed in Table 2. These experiments are not random acts of destruction; they are carefully designed scientific experiments intended to test a specific hypothesis about the system's resilience. Each experiment targets a major architectural boundary or a known potential failure point.
      3. Hypothesis-Driven Validation: The success of a chaos experiment is not measured by whether the system avoids failure, but by whether it adapts to the failure gracefully and maintains its steady-state performance within acceptable bounds.52 For example, a hypothesis might be: "If the L2 cache becomes unresponsive, the
HRCOrchestrator will detect the failure, adapt its utility functions to reflect the high cost of L2 queries, and route all comprehensive searches to the (slower) L3 store, causing p99 query latency to increase by no more than 20%."
      4. Adaptive Failure as a Learning Trigger: A failure to adapt gracefully—a violation of the experiment's hypothesis—is treated as a critical learning event. Such a failure will trigger a high-priority impasse in the HRCOrchestrator, forcing a sub-goaling process to diagnose the failure and learn or generate a new recovery strategy. This closes the loop between stress and improvement, which is the very essence of antifragility.
Experiment ID
	Target Subsystem
	Injected Hazard
	Steady-State Metric (KPI)
	Success Condition (Expected Adaptation)
	CEP-001
	Federated Memory
	Inject 200ms latency into L2 (DiskANN) responses.
	p99 Hybrid Query Latency
	System remains within 10% of baseline latency; OpenTelemetry traces show HRCOrchestrator increases reliance on L1 cache and logs L2 degradation.
	CEP-002
	Data Federation
	Inject malformed 'poison message' into Transactional Outbox.
	p99 Replication Lag
	Poison message is successfully moved to DLQ after 5 retries; replication lag for valid messages remains <100ms.
	CEP-003
	Autopoietic Engine
	LLMTransducer's transduceTextToSchema call returns non-compliant JSON.
	Schema Adherence Rate
	OllamaWorker validation fails, triggers retry logic in LLMTransducer; overall task succeeds within 3 retries.
	CEP-004
	Cognitive Core
	Artificially create an Operator Tie Impasse by duplicating a Concept object in L2.
	Reasoning Accuracy
	The HRCOrchestrator successfully triggers its tie-resolution subgoal, performs graph disambiguation, and selects the correct original object.
	Table 2: Antifragility Crucible Protocol Suite (Sample)


3.2 Self-Tuning via Free Energy Minimization


The TELOS architecture includes several critical, live-tunable parameters stored in the L3 ZODB, such as the VSA success thresholds (θsuccess​, θdisc​) and the IPC batching heuristics (N, T).1 The existing protocol describes their update mechanism as a feedback loop based on "measured accuracy," but this mechanism is not deeply specified.1 Furthermore, the system's most powerful adaptive mechanism, the
doesNotUnderstand_ protocol, is triggered only by hard errors—a purely reactive stance.
To create a more proactive and principled basis for adaptation, the system's self-tuning and self-modification loops must be driven by the Free Energy Principle. This reframes adaptation as a proactive, predictive process of minimizing the error between the system's model of its own state and its actual, measured state.
The implementation of this mandate shall adhere to the following protocol:
         1. Generative Self-Model: The SystemStateMonitor actor, which currently subscribes to discrete events, will be repurposed to serve as the core of the system's generative self-model.1 It will be tasked with continuously predicting a vector of key performance and operational indicators (KPIs) for the next time window (e.g., predicting future
p99 Hybrid Query Latency, Schema Adherence Rate, actor.queue_depth, etc.).6
         2. Internal Surprise as a Trigger: At the end of each time window, the SystemStateMonitor will compare its predicted KPI vector with the actual KPI vector measured by the unified OpenTelemetry stack. The discrepancy between prediction and reality is the system's internal "surprise," which is formally equivalent to variational free energy.22
         3. Active Inference for Self-Tuning: When this internal free energy exceeds a predefined threshold, it signifies that the system's model of itself is inaccurate and that its current state is "surprising." This event triggers an active inference cycle. The system will use its World Model to infer the most likely cause of the surprise and to select a policy—an internal action, such as adjusting the θ_{disc} parameter, refactoring a prompt template via the GenerativeKernel, or re-allocating workers in the GIL Quarantine pool—that it predicts will minimize free energy in the future.
This protocol creates a principled, self-organizing feedback loop where the system is constantly working to make its own behavior more predictable and stable. This is a direct embodiment of the FEP's imperative to resist disorder and maintain a non-equilibrium steady state, providing a deep, theoretical foundation for the system's autopoietic drive.53


Conclusion


The protocols mandated in this addendum represent a coherent and logically entailed evolution of the TELOS architecture, designed to elevate the system from a state of robust self-maintenance to one of proactive cognitive ascent and systemic antifragility. By synthesizing the foundational axiom of info-autopoiesis with established principles from cognitive science, theoretical biology, and advanced systems engineering, these extensions provide a concrete and actionable blueprint for the next generation of this neuro-symbolic architecture.
The core transformations are threefold:
            1. The Cognitive Core evolves from a reactive, linear heuristic to a recursive, impasse-driven reasoning engine inspired by SOAR. This is further enhanced by a metacognitive layer, derived from ACT-R, that allows the system to intelligently select the most effective reasoning strategy for a given task. The entire cognitive process is grounded in the Free Energy Principle, which provides a first-principles basis for goal-directed planning, action, and a deep, unifying theory of cognition and antifragility.
            2. The Federated Memory Fabric is enhanced with advanced GraphRAG techniques, enabling it to reason about the global context of its knowledge base through hierarchical community detection and to execute complex multi-hop queries via an LLM-driven iterative retrieval protocol. Crucially, the knowledge graph itself is elevated to become the substrate for a causal world model, providing the necessary structure for the cognitive core's predictive planning capabilities.
            3. The Autopoietic Engine is transformed from a reactive error-handling mechanism into a proactive engine for cultivating antifragility. The Validation Gauntlet becomes a Systemic Crucible for continuous Chaos Engineering, forcing the system to learn and adapt from controlled failure. The system's self-tuning mechanisms are placed on a rigorous mathematical footing, driven by the imperative to minimize internal surprise, or free energy.
Together, these extensions do not replace the existing TELOS design but rather increase its resolution and fidelity. They provide the formal protocols and hardened patterns necessary to realize the full potential of a "Living Image"—a system that does not merely process information, but actively seeks to understand its world, anticipates its future, and grows stronger and more capable through every interaction and challenge it encounters.
Works cited
            1. Design Protocol for Dynamic System Resolution
            2. Tiered Cache Design and Optimization
            3. Category Theoretical Formalization of Autopoiesis from Perspective of Distinction between Organization and Structure, accessed September 26, 2025, https://rikou.st.ryukoku.ac.jp/~nomura/docs/NomuraAP1.pdf
            4. Antifragility - Wikipedia, accessed September 26, 2025, https://en.wikipedia.org/wiki/Antifragility
            5. Antifragility Analysis and Measurement Framework for Systems of ..., accessed September 26, 2025, https://digitalcommons.odu.edu/cgi/viewcontent.cgi?article=1004&context=emse_fac_pubs
            6. A High-Resolution Implementation Plan: Supplemental Mandates for the TELOS Constructor
            7. Soar (cognitive architecture) - Wikipedia, accessed September 26, 2025, https://en.wikipedia.org/wiki/Soar_(cognitive_architecture)
            8. Introduction to the Soar Cognitive Architecture, accessed September 26, 2025, https://acs.ist.psu.edu/misc/nottingham/pst.w.9/hungry-thirsty/full.html
            9. Cognitive Architectures for Language Agents - arXiv, accessed September 26, 2025, https://arxiv.org/html/2309.02427v3
            10. Towards a Theory of Impasse-Driven Learning. - DTIC, accessed September 26, 2025, https://apps.dtic.mil/sti/tr/pdf/ADA186643.pdf
            11. The Soar Cognitive Architecture | Books Gateway - MIT Press Direct, accessed September 26, 2025, https://direct.mit.edu/books/monograph/2938/The-Soar-Cognitive-Architecture
            12. Introducing Constrained Heuristic Search to the Soar Cognitive Architecture - | Enterprise Integration Laboratory – EIL - University of Toronto, accessed September 26, 2025, https://eil.mie.utoronto.ca/wp-content/uploads/2022/06/bittle-AGI2009.pdf
            13. Error Modeling in the ACT-R Production System - Carnegie Mellon University, accessed September 26, 2025, https://www.cmu.edu/dietrich/psychology/memorylab/publications/94_cl_jra_lmr.pdf
            14. Understanding ACT-R – an Outsider's Perspective, accessed September 26, 2025, https://inc.ucsd.edu/~jake/actr.pdf
            15. About - ACT-R - Carnegie Mellon University, accessed September 26, 2025, http://act-r.psy.cmu.edu/about/
            16. Chapter 1: Modeling paradigms in ACT-R 1. Introduction, accessed September 26, 2025, https://www.ai.rug.nl/~niels/publications/taatgenLebiereAnderson.pdf
            17. Bayesian brain computing and the free-energy principle: an interview with Karl Friston | National Science Review | Oxford Academic, accessed September 26, 2025, https://academic.oup.com/nsr/article/11/5/nwae025/7571549
            18. Free energy principle - Wikipedia, accessed September 26, 2025, https://en.wikipedia.org/wiki/Free_energy_principle
            19. Active Inference: The Free Energy Principle in Mind, Brain, and Behavior - MIT Press Direct, accessed September 26, 2025, https://direct.mit.edu/books/oa-monograph/5299/Active-InferenceThe-Free-Energy-Principle-in-Mind
            20. From Artificial Intelligence to Active Inference: The Key to True AI and 6G World Brain [Invited] - arXiv, accessed September 26, 2025, https://arxiv.org/html/2505.10569v1
            21. BerenMillidge/FEP_Active_Inference_Papers: A repository for major/influential FEP and active inference papers. - GitHub, accessed September 26, 2025, https://github.com/BerenMillidge/FEP_Active_Inference_Papers
            22. The free-energy principle: a rough guide to the brain? - Wellcome ..., accessed September 26, 2025, https://www.fil.ion.ucl.ac.uk/~karl/The%20free-energy%20principle%20-%20a%20rough%20guide%20to%20the%20brain.pdf
            23. (PDF) Active inference and robot control: A case study - ResearchGate, accessed September 26, 2025, https://www.researchgate.net/publication/308763770_Active_inference_and_robot_control_A_case_study
            24. The free-energy principle: a unified brain theory?, accessed September 26, 2025, https://www.uab.edu/medicine/cinl/images/KFriston_FreeEnergy_BrainTheory.pdf
            25. Code World Model: First Reactions to Meta's Release - PromptLayer Blog, accessed September 26, 2025, https://blog.promptlayer.com/code-world-model-first-reactions-to-metas-release/
            26. facebook/cwm - Hugging Face, accessed September 26, 2025, https://huggingface.co/facebook/cwm
            27. CWM: An Open-Weights LLM for Research on Code Generation with ..., accessed September 26, 2025, https://ai.meta.com/research/publications/cwm-an-open-weights-llm-for-research-on-code-generation-with-world-models/
            28. Causal Representation Learning - Max Planck Institute for Intelligent Systems, accessed September 26, 2025, https://is.mpg.de/ics/en/projects/causal-representation-learning
            29. Learning Plannable Representations with Causal InfoGAN - NIPS, accessed September 26, 2025, http://papers.neurips.cc/paper/8090-learning-plannable-representations-with-causal-infogan.pdf
            30. Towards Causal Representation Learning - arXiv, accessed September 26, 2025, https://arxiv.org/pdf/2102.11107
            31. Language Agents Meet Causality -- Bridging LLMs and Causal ..., accessed September 26, 2025, https://openreview.net/forum?id=y9A2TpaGsE
            32. Active Inference for Learning and Development in Embodied Neuromorphic Agents - PMC, accessed September 26, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC11276484/
            33. #033 Karl Friston - The Free Energy Principle - YouTube, accessed September 26, 2025, https://www.youtube.com/watch?v=KkR24ieh5Ow
            34. How Active Inference Could Help Revolutionise Robotics - PMC - PubMed Central, accessed September 26, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC8946999/
            35. Applying the Free Energy Principle to Complex Adaptive Systems - PMC, accessed September 26, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9141822/
            36. GraphRAG auto-tuning provides rapid adaptation to new domains - Microsoft Research, accessed September 26, 2025, https://www.microsoft.com/en-us/research/blog/graphrag-auto-tuning-provides-rapid-adaptation-to-new-domains/
            37. Welcome - GraphRAG, accessed September 26, 2025, https://microsoft.github.io/graphrag/
            38. TELOS Implementation Addendum 1.3: Protocol for the Integration of Local Language Models as Natural Language Transducers
            39. Dynamic OO Enhancing LLM Understanding
            40. KG-IRAG: A Knowledge Graph-Based Iterative Retrieval-Augmented Generation Framework for Temporal Reasoning - arXiv, accessed September 26, 2025, https://arxiv.org/html/2503.14234v1
            41. How to Improve Multi-Hop Reasoning With Knowledge Graphs and ..., accessed September 26, 2025, https://neo4j.com/blog/genai/knowledge-graph-llm-multi-hop-reasoning/
            42. GraphRAG vs. Baseline RAG: Solving Multi-Hop Reasoning in LLMs - GenUI, accessed September 26, 2025, https://www.genui.com/resources/graphrag-vs.-traditional-rag-solving-multi-hop-reasoning-in-llms
            43. Causal Representation Learning, accessed September 26, 2025, https://crl-community.github.io/neurips24
            44. GraphRAG: The Practical Guide for Cost-Effective Document Analysis with Knowledge Graphs - LearnOpenCV, accessed September 26, 2025, https://learnopencv.com/graphrag-explained-knowledge-graphs-medical/
            45. [Literature Review] Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach - Moonlight, accessed September 26, 2025, https://www.themoonlight.io/en/review/integrating-large-language-models-in-causal-discovery-a-statistical-causal-approach
            46. Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach, accessed September 26, 2025, https://www.semanticscholar.org/paper/Integrating-Large-Language-Models-in-Causal-A-Takayama-Okuda/c213737923f58ad6c4cd18a8c17bca6522d7f4c6
            47. [2402.01454] Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach - arXiv, accessed September 26, 2025, https://arxiv.org/abs/2402.01454
            48. AI Constructor Implementation Plan
            49. How To Build Anti-Fragile Software Ecosystems - DevOps.com, accessed September 26, 2025, https://devops.com/how-to-build-anti-fragile-software-ecosystems/
            50. The Role Of Chaos Engineering in Building Anti-Fragile Systems - DEV Community, accessed September 26, 2025, https://dev.to/cloudiepad/the-role-of-chaos-engineering-in-building-anti-fragile-systems-17bg
            51. How Chaos Engineering Helps in Building Anti-Fragile Systems? - GeeksforGeeks, accessed September 26, 2025, https://www.geeksforgeeks.org/system-design/how-chaos-engineering-helps-in-building-anti-fragile-systems/
            52. REL12-BP04 Test resiliency using chaos engineering - Reliability Pillar, accessed September 26, 2025, https://docs.aws.amazon.com/wellarchitected/latest/reliability-pillar/rel_testing_resiliency_failure_injection_resiliency.html
            53. A Free Energy Principle for Biological Systems - MDPI, accessed September 26, 2025, https://www.mdpi.com/1099-4300/14/11/2100
            54. The free energy principle—a precis - Dialectical Systems, accessed September 26, 2025, https://www.dialecticalsystems.eu/contributions/the-free-energy-principle-a-precis/