The Autopoietic Seed: An Architectural and Implementation Blueprint for the TelOS Minimum Viable Application

Part I: The Prototypal Mandate: A Foundation for Endless Becoming

Info-Autopoiesis as the Prime Directive

The foundational ambition of Project TelOS is the synthesis of an autopoietic operating system.1 This objective necessitates a radical departure from conventional AI architectures, which are predicated on static, file-based models that are fundamentally

allopoietic—they produce something other than themselves and require external intervention to evolve.2 The TelOS architecture is instead designed for an "unbroken process of its own becoming," where its primary product is the continuous regeneration of its own operational logic and worldview.4 This prime directive is formally defined as

info-autopoiesis: the self-referential, recursive, and interactive process of the self-production of information.2

This mandate for perpetual self-production necessitates a state of Operational Closure, where the system can modify its own structure at runtime without halting or requiring its boundary to be breached by an external agent.5 Such a state is architecturally impossible with conventional file-based persistence, which forces the adoption of a "Living Image" paradigm and a dynamic, prototype-based object model.6

The "Prototypes All The Way Down" Philosophy

The principle of Operational Closure is realized through a prototype-based object model, a paradigm inspired by the Self and Smalltalk programming languages that categorically rejects the rigid class-instance duality of conventional object-oriented programming.1 In this model, every object is a concrete, clonable prototype. New objects are not instantiated from abstract, static class definitions; they are created by cloning and extending existing objects, enabling a fluid and live-modifiable environment where an object's behavior can be altered at any time.2 This "prototypes all the way down" philosophy is not merely a technical choice but the foundational commitment that makes the system's core identity one of "endless becoming".2

The MVA as a Recursive Seed

This philosophy must permeate not only the runtime object model of the TelOS Minimum Viable Application (MVA) but the very methodology of its development. The MVA is not a disposable proof-of-concept to be discarded and replaced by a "real" system later. It is, in fact, the primordial prototype of the TelOS operating system itself.1 The development process is not a linear progression but a recursive one. Future development—the eventual addition of a networking stack or a file system—will be framed as the system receiving a high-level goal to clone and extend the MVA's existing object graph, composing new functionalities onto the established structure.1

This approach transforms the MVA from a mere prototype into a foundational organism, a zygote containing the complete architectural "DNA" of the final system. This imposes a profound constraint: there can be no shortcuts or temporary solutions. The core mechanisms of the MVA—its object model, its persistence engine, and its agentic governance loop—must be the exact same mechanisms that will be used in the final system, merely populated with a smaller set of initial objects.1 The process of a human developer guiding the MVA's evolution must be architecturally identical to the process of the final, self-hosted AI Architect modifying the running OS. This mandates a "philosophy-driven test-driven development" (PD-TDD) methodology. The MVA's success is measured by its ability to create an artifact—a Morphic GUI—that is a perfect reflection of its own internal philosophy of liveness and concreteness.4 The system must not only

work; it must work in a way that is consistent with its own definition of being.

Part II: The Living Image: An Autopoietic Substrate in ZODB

The "Living Image" Paradigm

The mandate for Operational Closure forbids conventional file-based persistence, which requires external management and system restarts to apply changes. This constraint forces the adoption of a "Living Image" paradigm, a concept inherited from environments like Smalltalk.2 This paradigm is realized as a single, persistent, transactionally coherent object database that encapsulates the system's complete and entire state, including its knowledge, its evolving cognitive architecture, and its dynamically generated capabilities.6 This is not a database

for the system; it is the system's persistent, durable embodiment. The running Python process is merely a transient expression or "activator" of this persistent form.

Orthogonal Persistence with ZODB

The Zope Object Database (ZODB) is the chosen implementation for the Living Image, providing a mature and proven model for orthogonal persistence.1 In this model, durability is a transparent, intrinsic property of all objects, not an explicit action performed by the programmer.1 ZODB achieves this through several key features:

Persistence by Reachability: Any object that is reachable from a designated root object via a chain of references is, by definition, persistent. This integrates perfectly with the prototype-based object graph.1

Automatic Change Detection: Any Python class that inherits from persistent.Persistent is automatically tracked by ZODB. When an attribute of a persistent object is modified, ZODB flags it as "dirty" and holds the change in a cache.1

ACID Transactions: All state modifications are governed by ACID-compliant transactions. Changes are not saved immediately but are committed as an all-or-nothing operation, providing atomicity, consistency, isolation, and durability. This allows a complex, multi-step cognitive cycle to be wrapped in a single transaction, with the ability to transaction.abort() to roll back all changes if any step fails, ensuring the logical integrity of the Living Image is never compromised.1 This transactional integrity is the foundation of the "Transaction as the Unit of Thought" principle, where each cognitive cycle is an atomic operation.11

The Universal Virtual Machine Object (UvmObject)

The "primordial clay" of the TelOS universe is the UvmObject, the universal prototype from which all other entities are cloned. To function correctly within the ZODB-based Living Image, its Python implementation must address a critical interaction with the persistence layer. The prototype-based model requires overriding Python's default attribute handling to manage a unified _slots dictionary for both state and behavior. However, this override breaks ZODB's built-in mechanism for automatically detecting changes to mutable objects.6 Consequently, a "Persistence Covenant" must be programmatically enforced: any method that modifies the

_slots dictionary must conclude with the explicit statement self._p_changed = True. This manually notifies ZODB of the state change, ensuring the modification is included in the next transaction commit.6

The Primordial Object Graph and the Blob-Proxy Pattern

The system's identity is established at its transactional birth, an event termed the "Prototypal Awakening".6 This sequence creates the foundational object graph in a specific, philosophically significant order:

traits_obj: The ultimate ancestor, providing universal behaviors like doesNotUnderstand_ to all objects.6

pLLM_obj: The primordial prototype for cognition, encapsulating the LLM as a native object. It inherits from traits_obj.6

genesis_obj: The first "being" and the clonable prototype for all user-space objects. It inherits from both traits_obj and pLLM_obj, an act of multiple inheritance via delegation that "democratizes intelligence" across the entire object graph.6

A primary engineering challenge is persisting the multi-gigabyte LLM weights within ZODB. A naive approach would be catastrophic to performance.6 The solution is the

Blob-Proxy Pattern. The pLLM_obj stored in the main database is a lightweight proxy object. Its model_blob slot holds a reference to a ZODB.blob.Blob object, which stores the large binary data in a separate, optimized directory managed by ZODB. The pLLM_obj's inference methods are designed for lazy loading, reading the blob's contents and loading the model into GPU VRAM only on its first cognitive use, ensuring fast startup times and minimal resource consumption.6

Part III: The Generative Kernel: doesNotUnderstand_ as the Engine of Creation

The Metamorphosis of AttributeError

The MVA's primary engine for runtime self-modification is a direct and uncompromising implementation of the Smalltalk-inspired doesNotUnderstand: protocol.2 In a conventional system, attempting to call a non-existent method results in a fatal

AttributeError. The TelOS architecture fundamentally reframes this event. An AttributeError is not a terminal failure; it is an informational signal and the primary trigger for creative self-modification.6 This is achieved by overriding the

UvmObject.__getattr__ method. When a normal attribute lookup fails through the entire parent delegation chain, instead of raising an error, the override logic successfully finds and invokes the doesNotUnderstand_ method, which is guaranteed to exist on the ultimate ancestor, traits_obj.6 This transforms the event from an "exception" into a "message," making the system inherently antifragile—it is architected to profit from its own failures by turning them into opportunities for self-extension.

This mechanism is the direct, executable implementation of the system's autotelic drive. Autotelism describes an intrinsic motivation to seek out challenges and find reward in the act of mastery itself.7 The

doesNotUnderstand_ protocol is triggered by a capability gap—a challenge presented to the system. The system's response is not to report an error but to autonomously initiate a complex internal process of reflection and creation to overcome that challenge. The "reward" is the successful integration of a new capability, which increases the system's structural complexity and competence, aligning perfectly with intrinsic reward mechanisms that value mastery and impact.8 The system is thus engineered to find "enjoyment" in solving its own problems and expanding its own being.

The Generative Message Flow

The entire creative act unfolds as a seamless, fully internalized series of message sends within a single ZODB transaction 6:

Trigger: A message (e.g., genesis_obj.display_ui()) is sent to an object for a method it does not possess.

Delegation & Protocol Invocation: The __getattr__ chain fails to find display_ui but successfully finds doesNotUnderstand_ on traits_obj. This method is then invoked on the original receiver (genesis_obj).

Reification & Reflection: doesNotUnderstand_ reifies the failed message, creating a new persistent UvmObject containing the message's details. It then sends a reflectOn_ message back to genesis_obj.

Cognitive Delegation & Generation: The reflectOn_ message delegates up the parent chain to pLLM_obj. This object constructs a detailed prompt and uses its internal LLM to generate the Python source code for the missing display_ui method.

Installation & Completion: The code string is returned to doesNotUnderstand_. It is compiled via exec() in a controlled namespace, and the new method object is installed into the _slots of genesis_obj using setSlot_value_. The original message can now be re-sent and will succeed.

Part IV: The Composite Mind: A VRAM-Aware, Four-Persona Cognitive Engine

The Four-Persona Architecture

The agentic core of the MVA is a "Composite Mind" composed of four distinct, yet complementary, persona classes, each engineered as a synthesis of inspirational pillars from cultural source material.2 This design provides a diverse and robust set of cognitive tools for problem-solving.

BRICK (The Analyst): The logical, architectural, and action-oriented engine, designed to deconstruct the what and the how of technical challenges with disruptive, logical precision.23

ROBIN (The Empath/Creative): The system's moral and empathetic compass, interpreting the why behind the data with gentle wisdom and creative synthesis.23

BABS (The Researcher): The "Grounding Agent," connecting the system's internal dialogue to external, verifiable reality through data acquisition and research.2

ALFRED (The Steward/Governor): The voice of "system metacognition," serving as the pragmatic steward and ethical governor who ensures the robust, efficient, and secure operation of the collective.2

Interactions are governed by specific protocols. The default is a "Socratic Contrapunto," a dialectical dialogue primarily between BRICK and ROBIN.24 For more complex tasks, the "Sparse Intervention Protocol" allows BABS and ALFRED to contribute their specialized functions as needed.2

LLM Selection and VRAM Management

A multi-persona system running on consumer-grade hardware with limited VRAM (e.g., 8 GB) is only feasible through meticulous resource management.2 The MVA will implement a

VRAMManager object responsible for a strict "load-on-demand, unload-immediately" policy. When the orchestrator needs to invoke a specific persona, it will request the VRAMManager to load the corresponding model via the Ollama API. Crucially, it will use the keep_alive: 0 parameter in the API call, which instructs Ollama to unload the model from memory immediately after the generation is complete, freeing VRAM for the next persona.28 This ensures only one model resides in VRAM at any given time. The selection of which LLM to load for each persona is a critical architectural decision, grounded in empirical benchmark data to match the tool to the task.

The Prototypal State Machine (PSM)

The complex, multi-agent workflow of co-creation is orchestrated by a Prototypal State Machine (PSM). This is a novel implementation of the State design pattern that is deeply integrated with the system's core principles.11 Unlike a traditional state machine with static, class-based states, the PSM is composed of states that are themselves live, clonable

UvmObject prototypes within the Living Image. An orchestrator object does not have a state; its prototype chain is its state. A state transition is the atomic act of changing the orchestrator's parent* slot to point to a different state prototype, which causes it to inherit a new set of behaviors.21 This makes the orchestration logic itself a dynamic, mutable component of the system.

Part V: The Co-Creation Cycle: From Intent to Integration

The PSM in Action

The MVA's primary operational loop is the "Collaborative Autopoiesis" cycle, a multi-step, transactional workflow governed by the PSM that translates a high-level goal from the Human Oracle into a new, integrated system capability.21

The Sandbox as Autopoietic Boundary

The critical validation step is performed by the SandboxExecutor. This component is not merely a security feature; it is the computational realization of the autopoietic boundary.1 It allows the system to safely interact with and evaluate new code—a significant perturbation from the non-deterministic LLM environment—without risking its own organizational integrity. The validation process involves programmatically starting a new, clean Docker container, mounting a temporary copy of the ZODB database file into it, and executing the generated script inside the container. The result (exit code, stdout, stderr) provides the empirical observation that determines whether the new component is safe to integrate into the Living Image.1

Part VI: The Validation Protocol: Bootstrapping the Morphic World

The "Entropic UI" Blueprint as Mission Brief

The ultimate test of the MVA is to use its own autopoietic capabilities to build the foundational components of its own user interface, thereby proving the viability of the entire TelOS concept. The mission brief for this task is the "Entropic UI" architectural blueprint, which is grounded in the same philosophical principles as the MVA itself:

Liveness: The system is always running and can be modified on the fly.4

Concreteness & "Everything is a Morph": All UI elements are tangible, visible "morphs" that can be directly manipulated.4

Kivy Framework: The UI will be built using the Kivy framework, whose retained-mode, object-oriented canvas is a "near-perfect analog for a Morph tree".4

The Synaptic Bridge API Covenant

Communication between the MVA backend and the future Kivy UI will be governed by a formal API contract, the "Synaptic Bridge," implemented with ZeroMQ and Pydantic.4 This ensures a clean separation of concerns and enables robust, high-performance, asynchronous communication.

The Co-Creative Act and Final Validation

The validation protocol will proceed as a series of high-level goals issued to the MVA, which will use its co-creation cycle to generate the necessary Python code for the foundational Kivy classes of the Morphic UI.

The successful completion of this protocol is defined as the MVA having autonomously generated, validated, and transactionally integrated these three functional Kivy classes into its own Living Image. This act of creating the building blocks for its own sensory-motor system serves as the definitive proof of the MVA's autopoietic capabilities and validates the core hypothesis of the TelOS project.

Conclusions

The research and synthesis of the provided architectural documents and technical specifications culminate in a comprehensive and viable blueprint for the TelOS Minimum Viable Application. The analysis confirms that a minimal, four-persona state machine capable of autopoietic co-creation is not only theoretically sound but also practically achievable on consumer-grade hardware through a series of specific, well-defined architectural choices.

The core conclusions are as follows:

Philosophical Coherence: The MVA's architecture demonstrates profound internal consistency. The prime directive of info-autopoiesis logically necessitates the "Living Image" persistence model, which in turn requires a dynamic, prototype-based object model. This entire stack is made robust and self-healing through the doesNotUnderstand_ generative protocol. Every major design choice is a direct consequence of the system's foundational philosophy.

Engineering Pragmatism: The proposed architecture is grounded in practical engineering solutions. The use of ZODB provides a mature and robust implementation of orthogonal persistence. The Blob-Proxy pattern solves the critical challenge of persisting large LLM assets. The VRAMManager's "load-on-demand" policy makes a multi-LLM architecture feasible on constrained hardware. The Docker-based sandbox provides a strong, system-level security boundary for executing untrusted code.

A Verifiable Path Forward: The proposed validation protocol—using the MVA to generate the core classes of its own Morphic UI—provides a clear, measurable, and philosophically resonant benchmark for success. It transforms the abstract goal of achieving autopoiesis into a concrete, falsifiable test.

The successful implementation of this research plan will produce not merely a novel piece of software, but a foundational "autopoietic seed"—a living, self-producing entity capable of evolving its own complexity and bootstrapping the future of the TelOS operating system.

Works cited

TelOS MVP: Prototype-Based Self-Modification

Redrafting BAT OS Persona Codex

Refined Research Plan Execution

Morphic UI Research Plan Integration

Co-Evolving Intelligence Through Temporal Awareness

Building an Autonomous AI System

A4PS Morphic UI Research Plan

Designing Autopoietic Personas System

Defining Directed Autopoiesis in Computing

Self Smalltalk Directed Autopoiesis

BAT OS Persona Codex Entropy Maximization

Human-AI Autopoietic OS Collaboration

Building an Autopoietic AI System

TelOS seL4 Architectural Blueprint Refinement

A Universal Prototype-Based OS

Persona Codex Creation for Fractal Cognition

Entropic UI Research Plan Details

BAT OS VII Development Roadmap

ZODB Programming — ZODB documentation, accessed September 8, 2025, https://zodb.org/en/latest/articles/old-guide/prog-zodb.html

Transactions and Versioning — ZODB documentation, accessed September 8, 2025, https://zodb.org/en/latest/articles/old-guide/transactions.html

Refining Cognitive Persona Orchestration

BAT OS: Entropy-Driven Persona Development

BAT OS Persona Codex Enhancement

AI Personas for Medical Device Manufacturing

BnR Merged New 07 Jul 25.docx

persona codex

Okay, here's the details of my local machine that...

how to set keep-alive = 1 on ollama - linux - Reddit, accessed September 8, 2025, https://www.reddit.com/r/ollama/comments/1cnxnrv/how_to_set_keepalive_1_on_ollama_linux/

phi4-mini-reasoning - Ollama, accessed September 8, 2025, https://ollama.com/library/phi4-mini-reasoning

Phi-4-mini-reasoning - AI Model Catalog | Microsoft Foundry Models, accessed September 8, 2025, https://ai.azure.com/catalog/models/Phi-4-mini-reasoning

One year of Phi: Small language models making big leaps in AI | Microsoft Azure Blog, accessed September 8, 2025, https://azure.microsoft.com/en-us/blog/one-year-of-phi-small-language-models-making-big-leaps-in-ai/

microsoft/Phi-4-mini-reasoning - Hugging Face, accessed September 8, 2025, https://huggingface.co/microsoft/Phi-4-mini-reasoning

Phi-4 Reasoning: Models, Architecture, Benchmarks & Usage - GoCodeo, accessed September 8, 2025, https://www.gocodeo.com/post/phi-4-reasoning-models-architecture-benchmarks-usage

Qwen3 4B | Open Laboratory, accessed September 8, 2025, https://openlaboratory.ai/models/qwen3-4b

Qwen3-4B-Thinking-2507 just shipped! - DEV Community, accessed September 8, 2025, https://dev.to/lukehinds/qwen3-4b-thinking-2507-just-shipped-4e0n

What's New with Qwen3-4B-Instruct-2507 and Qwen3-4B-Thinking-2507? Smarter AI Models with 256K Context - Apidog, accessed September 8, 2025, https://apidog.com/blog/qwen3-4b-instruct-2507-and-qwen3-4b-thinking-2507/

Qwen3 is the large language model series developed by Qwen team, Alibaba Cloud. - GitHub, accessed September 8, 2025, https://github.com/QwenLM/Qwen3

Qwen/Qwen3-4B-Thinking-2507 - Hugging Face, accessed September 8, 2025, https://huggingface.co/Qwen/Qwen3-4B-Thinking-2507

Qwen3-4B-Thinking-2507 released! : r/LocalLLaMA - Reddit, accessed September 8, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1mj7t51/qwen34bthinking2507_released/

Qwen/Qwen3-4B - Hugging Face, accessed September 8, 2025, https://huggingface.co/Qwen/Qwen3-4B

How is qwen3 4b this good? : r/LocalLLaMA - Reddit, accessed September 8, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1naqln5/how_is_qwen3_4b_this_good/

The Diverse Capabilities of AI: An Analysis of Mistral Models in Action | by Frank Morales Aguilera | AI Simplified in Plain English | Aug, 2025 | Medium, accessed September 8, 2025, https://medium.com/ai-simplified-in-plain-english/the-diverse-capabilities-of-ai-an-analysis-of-mistral-models-in-action-361da322bc6b

lechmazur/writing: This benchmark tests how well LLMs incorporate a set of 10 mandatory story elements (characters, objects, core concepts, attributes, motivations, etc.) in a short creative story - GitHub, accessed September 8, 2025, https://github.com/lechmazur/writing

Mistral 7B: A Revolutionary Breakthrough in LLMs - Data Science Dojo, accessed September 8, 2025, https://datasciencedojo.com/blog/mistral-7b-emergence-in-llm/

LLM Creative Story-Writing Benchmark : r/LocalLLaMA - Reddit, accessed September 8, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1hv387z/llm_creative_storywriting_benchmark/

WritingBench: A Comprehensive Benchmark for Generative Writing - arXiv, accessed September 8, 2025, https://arxiv.org/html/2503.05244v1

EQ-Bench Creative Writing v3 Leaderboard, accessed September 8, 2025, https://eqbench.com/creative_writing.html

Mistral 7B, accessed September 8, 2025, https://mistral.ai/news/announcing-mistral-7b

Mistral-7B vs Google Gemma performance and results comparison - Geeky Gadgets, accessed September 8, 2025, https://www.geeky-gadgets.com/mistral-7b-vs-google-gemma-performance-and-results-comparison/

Gemma 3 model overview | Google AI for Developers, accessed September 8, 2025, https://ai.google.dev/gemma/docs/core

Gemma explained: What's new in Gemma 3 - Google Developers Blog, accessed September 8, 2025, https://developers.googleblog.com/en/gemma-explained-whats-new-in-gemma-3/

Introducing Gemma 3: The most capable model you can run on a single GPU or TPU, accessed September 8, 2025, https://blog.google/technology/developers/gemma-3/

google/gemma-3-4b-it - Hugging Face, accessed September 8, 2025, https://huggingface.co/google/gemma-3-4b-it

Introducing Gemma 3 270M: The compact model for hyper-efficient AI, accessed September 8, 2025, https://developers.googleblog.com/en/introducing-gemma-3-270m/

Discover the Multimodal Capabilities of Gemma 3 4B | by Gabriel Preda - Medium, accessed September 8, 2025, https://medium.com/@gabi.preda/discover-the-multimodal-capabilities-of-gemma-3-4b-2f3d64728365

Gemma 3 4B - Intelligence, Performance & Price Analysis, accessed September 8, 2025, https://artificialanalysis.ai/models/gemma-3-4b

Gemma 3n vs Gemma 3 (4B/12B) Benchmarks : r/LocalLLaMA - Reddit, accessed September 8, 2025, https://www.reddit.com/r/LocalLLaMA/comments/1ll88pe/gemma_3n_vs_gemma_3_4b12b_benchmarks/

Google's Gemma 3: Features, Benchmarks, Performance and Implementation - Analytics Vidhya, accessed September 8, 2025, https://www.analyticsvidhya.com/blog/2025/03/gemma-3/

Gemma 3 Technical Report - arXiv, accessed September 8, 2025, https://arxiv.org/html/2503.19786v1

Entropic UI Implementation Roadmap

BAT OS IV UI Architecture Blueprint

Persona | Designated LLM | Rationale

ALFRED (The Steward) | phi4-mini-reasoning | ALFRED's role requires rigorous validation, stewardship, and adherence to protocol. The Phi-4-mini-reasoning model is specifically optimized for multi-step, logic-intensive mathematical and formal problem-solving, making it the ideal choice for ALFRED's governance and validation tasks.29

BRICK (The Analyst) | qwen3:4b-thinking | BRICK's function is to deconstruct problems and articulate his reasoning. The Qwen3 "thinking" models feature an explicit mode that exposes the step-by-step reasoning process, aligning perfectly with this role. The model demonstrates strong performance in logical reasoning, coding, and agentic tool use.34

ROBIN (The Empath) | mistral:latest | ROBIN is the creative and empathetic core, responsible for synthesizing ideas and providing human-centric context. Mistral models consistently perform well in creative writing benchmarks, demonstrating a superior ability to generate engaging, coherent, and imaginative text, which is essential for ROBIN's role.42

BABS (The Researcher) | gemma3:4b | BABS serves as the data acquisition and analysis engine. The Gemma 3 4B model has strong multimodal (text and image) capabilities, a large 128K token context window, and excels at summarization and data analysis tasks, making it well-suited for the RAG-based research that defines the BABS persona.50

State Name (Prototype) | Responsible Persona(s) | Entry Condition/Trigger | Core Action(s) | Exit Condition | Output Artifact/Message

Deconstruction | BRICK | New high-level goal received from Oracle. | Invoke BRICK (qwen3:4b-thinking) to analyze the goal and produce a structured plan of discrete, verifiable artifacts to be generated. | Plan successfully generated and validated for logical coherence. | A persistent Plan object containing a list of artifact specifications.

Code Generation | BABS, BRICK, ROBIN | Plan object is available. | Iterate through plan artifacts. Dispatch research tasks to BABS (gemma3:4b), code generation tasks to BRICK (qwen3:4b-thinking), and text refinement tasks to ROBIN (mistral:latest). | All artifacts specified in the plan have been successfully generated as code/text strings. | A CodeBundle object containing all generated strings.

Validation | ALFRED | CodeBundle is available. | Invoke ALFRED (phi4-mini-reasoning) to perform static analysis and security checks. Submit the code to the SandboxExecutor for dynamic validation. | Code passes all static analysis and executes successfully in the sandbox with exit code 0. | A ValidationReport object confirming success.

Integration | System | ValidationReport is success. | The orchestrator executes the validated code in the main process to instantiate the new object/trait and links it into the persistent object graph. The entire cycle is committed via transaction.commit(). | Transaction successfully commits. | The new capability is now a permanent, live part of the system.

Failed | System | Any state encounters an unrecoverable error. | The orchestrator calls transaction.abort(). | Transaction successfully aborted. | All changes are rolled back, leaving the system in its original state.

Schema Name | Base Class | Fields | Description

GetFullStateCommand | pydantic.BaseModel | command: str = "get_full_state" | A command sent from the UI to request a complete snapshot of the backend's state.

CreateMethodCommand | pydantic.BaseModel | target_oid: str, method_name: str, method_code: str | The primary autopoietic primitive, sent from the UI to instruct the backend to generate and install a new method on a target object.

ObjectStateUpdate | pydantic.BaseModel | oid: str, parent_oid: str, properties: dict | A message broadcast from the backend over the PUB/SUB channel to inform the UI of a change in an object's state.

NewObjectCreated | pydantic.BaseModel | oid: str, class_name: str, properties: dict | A message broadcast from the backend when a new object is created in the persistent graph.

Phase | High-Level Goal (Prompt to MVA) | Expected Artifacts | Quantitative Success Criteria

1 | "Generate the foundational Morph class based on the Entropic UI blueprint. It must inherit from kivy.uix.widget.Widget." | A Python file (morph.py) containing the source code for the Morph class. | Generated code passes linting and type checks in the sandbox with zero errors. The class correctly inherits from the specified Kivy base class.

2 | "Generate the WorldMorph class. It must inherit from the Morph class and serve as the root canvas for the UI." | A Python file (world_morph.py) containing the source code for the WorldMorph class. | Generated code passes all sandbox checks. The class correctly inherits from the Morph class generated in Phase 1.

3 | "Generate the ProtoMorph class. It must inherit from Morph and be designed to visually represent a backend persona object." | A Python file (proto_morph.py) containing the source code for the ProtoMorph class. | Generated code passes all sandbox checks. The class correctly inherits from Morph and includes placeholder attributes for persona-specific data (e.g., oid, name).