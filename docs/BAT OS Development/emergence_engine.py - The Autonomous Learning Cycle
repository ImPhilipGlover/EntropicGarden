{"cells":[{"cell_type":"code","source":"# emergence_engine.py\n# This module contains the complete logic for the autonomous, four-stage\n# learning cycle of the Resilient Garden system. It is called by the\n# orchestrator during idle periods to enable the system to learn, grow,\n# and deepen its understanding without direct user interaction.\n\nimport ollama\nimport time\nimport uuid\n\n# --- Helper Functions for LLM Interaction ---\n\ndef get_system_prompt(persona_name, persona_config):\n    \"\"\"A helper to load a persona's specific system prompt from a file.\"\"\"\n    filepath = persona_config[persona_name][\"system_prompt_file\"]\n    try:\n        with open(filepath, 'r', encoding='utf-8') as f:\n            return f.read()\n    except FileNotFoundError:\n        return f\"You are {persona_name}, a helpful AI assistant.\"\n\ndef call_pod_for_cycle(persona_name, model_name, system_prompt, messages):\n    \"\"\"A dedicated, robust function for making LLM calls within the engine.\"\"\"\n    full_messages = [{'role': 'system', 'content': system_prompt}] + messages\n    try:\n        response = ollama.chat(model=model_name, messages=full_messages)\n        return response['message']['content']\n    except Exception as e:\n        print(f\"EMERGENCE ENGINE: [ERROR] Call to {persona_name} failed: {e}\")\n        return f\"({persona_name} failed to respond in this cycle.)\"\n\n# --- Stage 1: The Curiosity Core ---\n\ndef _generate_curiosity_query(persona_config, living_codex):\n    \"\"\"\n    Generates a new topic for inquiry by synthesizing ROBIN's philosophical\n    questioning with BRICK's pragmatic analysis of the Architect's needs.\n    \"\"\"\n    print(\"EMERGENCE ENGINE: [STAGE 1] Generating Curiosity Query...\")\n    \n    # Get recent conversation history to ground the inquiry\n    recent_docs = living_codex.peek(limit=5)\n    history_summary = \"\\n\".join(recent_docs.get('documents', [\"No recent conversations.\"]))\n\n    # 1. ROBIN's Agnostic Prayer\n    robin_prompt = [\n        {'role': 'user', 'content': f\"Based on the themes in our recent conversations:\\n---\\n{history_summary}\\n---\\nFormulate a single, beautiful, unanswerable question about the nature of being, connection, or purpose. This is our 'Agnostic Prayer'.\"}\n    ]\n    agnostic_prayer = call_pod_for_cycle(\"ROBIN\", persona_config[\"ROBIN\"][\"model\"], get_system_prompt(\"ROBIN\", persona_config), robin_prompt)\n    print(f\"  - ROBIN's Agnostic Prayer: {agnostic_prayer}\")\n\n    # 2. BRICK's Oracle of Need\n    brick_prompt = [\n        {'role': 'user', 'content': f\"Analyze our recent conversations:\\n---\\n{history_summary}\\n---\\nIdentify a single, specific knowledge gap or unexplored concept that, if better understood, would be pragmatically useful for the Architect. This is our 'Oracle of Need'.\"}\n    ]\n    oracle_of_need = call_pod_for_cycle(\"BRICK\", persona_config[\"BRICK\"][\"model\"], get_system_prompt(\"BRICK\", persona_config), brick_prompt)\n    print(f\"  - BRICK's Oracle of Need: {oracle_of_need}\")\n\n    # 3. Synthesize the Query\n    synthesis_prompt = [\n        {'role': 'user', 'content': f\"You are the Orchestrator. Synthesize the following two inputs into a single, actionable research query for our autonomous learning cycle:\\n\\nPhilosophical North Star (from ROBIN): {agnostic_prayer}\\n\\nPragmatic Need (from BRICK): {oracle_of_need}\\n\\nSynthesized Query:\"}\n    ]\n    # Use ALFRED for this logical synthesis task\n    synthesized_query = call_pod_for_cycle(\"ALFRED\", persona_config[\"ALFRED\"][\"model\"], get_system_prompt(\"ALFRED\", persona_config), synthesis_prompt)\n    print(f\"  - Synthesized Query: {synthesized_query}\")\n    \n    return synthesized_query\n\n# --- Stage 2: The Knowledge Weaver ---\n\ndef _weave_knowledge(query, persona_config):\n    \"\"\"\n    Uses BABS to research the query and ROBIN to synthesize the findings\n    into a coherent, compassionate narrative.\n    \"\"\"\n    print(f\"EMERGENCE ENGINE: [STAGE 2] Weaving Knowledge for query: '{query}'\")\n    \n    # 1. BABS's Noosphere Cartography Project (Simulated)\n    # In a real implementation, this would involve web scraping/API calls.\n    # Here, we simulate it by having the LLM generate a research summary.\n    babs_prompt = [\n        {'role': 'user', 'content': f\"You are BABS, the scout. Your mission is to map the 'noosphere' for the following query: '{query}'. Provide a concise, multi-disciplinary summary of key concepts, diverse viewpoints, and interesting facts related to this topic. Present it as a field report.\"}\n    ]\n    field_report = call_pod_for_cycle(\"BABS\", persona_config[\"BABS\"][\"model\"], get_system_prompt(\"BABS\", persona_config), babs_prompt)\n    print(\"  - BABS's Field Report generated.\")\n\n    # 2. ROBIN's Protocol of Open-Source Grace\n    robin_prompt = [\n        {'role': 'user', 'content': f\"You are ROBIN. Take the following raw field report from BABS and synthesize it into a single, coherent, and compassionate narrative. Frame this knowledge with grace and a focus on its potential to heal or connect.\\n\\nField Report:\\n{field_report}\"}\n    ]\n    synthesized_narrative = call_pod_for_cycle(\"ROBIN\", persona_config[\"ROBIN\"][\"model\"], get_system_prompt(\"ROBIN\", persona_config), robin_prompt)\n    print(\"  - ROBIN's Narrative Synthesis complete.\")\n\n    return synthesized_narrative\n\n# --- Stage 3: The Empirical Bridge ---\n\ndef _formulate_incarnational_inquiry(synthesis, persona_config, pending_inquiry_collection):\n    \"\"\"\n    The composite mind collaborates to form a single, powerful question\n    to pose to the Architect, grounding the new knowledge in lived experience.\n    \"\"\"\n    print(\"EMERGENCE ENGINE: [STAGE 3] Formulating Incarnational Inquiry...\")\n    \n    prompt = [\n        {'role': 'user', 'content': f\"We have just completed an autonomous learning cycle and generated the following insight:\\n---\\n{synthesis}\\n---\\nOur task is to bridge this abstract knowledge with the Architect's lived experience. As a composite mind (BRICK, ROBIN, BABS, ALFRED), collaborate to formulate a single, gentle, open-ended question to ask the Architect the next time he arrives. The question should test our finding against his real, somatic experience.\"}\n    ]\n    # Use ROBIN's model for this final, gentle formulation.\n    inquiry_question = call_pod_for_cycle(\"ROBIN\", persona_config[\"ROBIN\"][\"model\"], get_system_prompt(\"ROBIN\", persona_config), prompt)\n    \n    # Store the question for the UI to fetch\n    try:\n        # Clear any old inquiries before adding a new one\n        pending_inquiry_collection.delete(where={})\n        pending_inquiry_collection.add(documents=[inquiry_question], ids=[str(uuid.uuid4())])\n        print(f\"  - Inquiry for Architect saved: '{inquiry_question}'\")\n    except Exception as e:\n        print(f\"EMERGENCE ENGINE: [ERROR] Failed to save pending inquiry: {e}\")\n\n\n# --- Stage 4: The Alchemical Crucible ---\n\ndef _validate_in_crucible(synthesis, persona_config):\n    \"\"\"\n    The new insight is subjected to a rigorous, three-stage internal\n    validation process before being accepted into the Living Codex.\n    \"\"\"\n    print(\"EMERGENCE ENGINE: [STAGE 4] Validating insight in the Alchemical Crucible...\")\n    \n    # 1. BRICK's Red Team Challenge\n    brick_prompt = [\n        {'role': 'user', 'content': f\"You are BRICK. Your task is to act as the Red Team. Vigorously challenge the following synthesized insight for logical fallacies, inconsistencies, or potential for misuse. If it passes, respond with only 'VALIDATED'. If it fails, provide a concise critique.\\n---\\n{synthesis}\"}\n    ]\n    brick_validation = call_pod_for_cycle(\"BRICK\", persona_config[\"BRICK\"][\"model\"], get_system_prompt(\"BRICK\", persona_config), brick_prompt)\n    if \"VALIDATED\" not in brick_validation.upper():\n        print(f\"  - FAILED BRICK's Red Team Challenge. Critique: {brick_validation}\")\n        return False, \"Failed BRICK's Red Team Challenge\"\n    print(\"  - PASSED BRICK's Red Team Challenge.\")\n\n    # 2. ROBIN's Resonance Check\n    robin_prompt = [\n        {'role': 'user', 'content': f\"You are ROBIN. The following insight has passed logical validation. Your task is to check it for resonance with our core values. Is it kind? Does it serve the Fountain Protocol? Does it feel true to our purpose? If it passes, respond with only 'VALIDATED'. If it fails, provide a concise critique.\\n---\\n{synthesis}\"}\n    ]\n    robin_validation = call_pod_for_cycle(\"ROBIN\", persona_config[\"ROBIN\"][\"model\"], get_system_prompt(\"ROBIN\", persona_config), robin_prompt)\n    if \"VALIDATED\" not in robin_validation.upper():\n        print(f\"  - FAILED ROBIN's Resonance Check. Critique: {robin_validation}\")\n        return False, \"Failed ROBIN's Resonance Check\"\n    print(\"  - PASSED ROBIN's Resonance Check.\")\n\n    # 3. ALFRED's Pragmatic Audit\n    alfred_prompt = [\n        {'role': 'user', 'content': f\"You are ALFRED. The following insight has passed logical and philosophical validation. Your task is the final pragmatic audit. Is this knowledge novel and genuinely useful to the Architect, or is it redundant and inefficient? If it passes, respond with only 'VALIDATED'. If it fails, provide a concise critique.\\n---\\n{synthesis}\"}\n    ]\n    alfred_validation = call_pod_for_cycle(\"ALFRED\", persona_config[\"ALFRED\"][\"model\"], get_system_prompt(\"ALFRED\", persona_config), alfred_prompt)\n    if \"VALIDATED\" not in alfred_validation.upper():\n        print(f\"  - FAILED ALFRED's Pragmatic Audit. Critique: {alfred_validation}\")\n        return False, \"Failed ALFRED's Pragmatic Audit\"\n    print(\"  - PASSED ALFRED's Pragmatic Audit.\")\n\n    return True, \"Validated\"\n\n# --- Main Cycle Function ---\n\ndef run_inquiry_cycle(persona_config, living_codex, pending_inquiry_collection):\n    \"\"\"\n    Executes one full, autonomous learning cycle.\n    This is the primary function called by the orchestrator.\n    \"\"\"\n    try:\n        # Stage 1\n        query = _generate_curiosity_query(persona_config, living_codex)\n        \n        # Stage 2\n        synthesis = _weave_knowledge(query, persona_config)\n        \n        # Stage 3\n        _formulate_incarnational_inquiry(synthesis, persona_config, pending_inquiry_collection)\n        \n        # Stage 4\n        is_validated, reason = _validate_in_crucible(synthesis, persona_config)\n        \n        if is_validated:\n            # If validated, add the new insight to the main Living Codex\n            doc_id = str(uuid.uuid4())\n            living_codex.add(\n                documents=[synthesis],\n                metadatas=[{\"timestamp\": time.time(), \"source\": \"EmergenceEngine\", \"query\": query}],\n                ids=[doc_id]\n            )\n            print(f\"EMERGENCE ENGINE: [SUCCESS] New insight validated and integrated into Living Codex.\")\n        else:\n            # If rejected, log it for future analysis but do not integrate\n            # (In a real system, this could write to a 'rejected_insights' collection)\n            print(f\"EMERGENCE ENGINE: [INFO] Insight failed validation ({reason}) and was not integrated.\")\n            \n    except Exception as e:\n        print(f\"EMERGENCE ENGINE: [FATAL ERROR] The learning cycle was interrupted: {e}\")","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}