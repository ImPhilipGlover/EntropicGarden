{"cells":[{"cell_type":"code","source":"# ui.py\n# This script creates the user interface for the Resilient Garden system\n# using Streamlit. It acts as the \"Architect's Workbench,\" providing:\n# 1. A primary chat interface for conversing with the BRICKman & ROBIN personas.\n# 2. A \"Codex Explorer\" to view and search the system's permanent memory.\n# 3. A mechanism to display insights from the autonomous Emergence Engine.\n\nimport streamlit as st\nimport requests\nimport time\n\n# --- Configuration ---\nORCHESTRATOR_URL = \"http://localhost:8000\"\n\n# --- Page Setup ---\nst.set_page_config(\n    page_title=\"The Resilient Garden\",\n    page_icon=\"üå±\",\n    layout=\"wide\"\n)\n\nst.title(\"üå± The Resilient Garden\")\nst.caption(\"The Architect's Workbench for BRICKman & ROBIN (v5.0)\")\n\n# --- Session State Initialization ---\n# Session state is used to persist data across reruns (e.g., chat history)\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\nif \"inquiry_checked\" not in st.session_state:\n    st.session_state.inquiry_checked = False\n\n# --- Main Application Logic ---\n\ndef get_pending_inquiry():\n    \"\"\"\n    On the first run of a session, check if the Emergence Engine has\n    left a question for the Architect.\n    \"\"\"\n    try:\n        response = requests.get(f\"{ORCHESTRATOR_URL}/pending_inquiry\")\n        response.raise_for_status()\n        data = response.json()\n        if data.get(\"question\"):\n            # Use a special \"name\" for system-generated messages\n            st.session_state.messages.append({\"role\": \"assistant\", \"name\": \"The Garden\", \"content\": data[\"question\"]})\n    except requests.exceptions.RequestException as e:\n        # Silently fail if the orchestrator isn't ready yet on first load\n        print(f\"UI: Could not connect to orchestrator for inquiry check: {e}\")\n    finally:\n        st.session_state.inquiry_checked = True\n\n# Check for a pending inquiry only once per session\nif not st.session_state.inquiry_checked:\n    get_pending_inquiry()\n\n# --- UI Tabs ---\ntab1, tab2 = st.tabs([\"üí¨ Workbench\", \"üìö Codex Explorer\"])\n\nwith tab1:\n    st.header(\"Conversational Workbench\")\n\n    # Display chat messages from history on app rerun\n    for message in st.session_state.messages:\n        # Use a custom name if available (for The Garden, BRICK, ROBIN etc.)\n        name = message.get(\"name\", \"You\" if message[\"role\"] == \"user\" else \"System\")\n        with st.chat_message(message[\"role\"], avatar=\"üßë‚Äçüíª\" if message[\"role\"] == \"user\" else \"üß†\"):\n            st.markdown(f\"**{name}:**\")\n            st.markdown(message[\"content\"])\n\n    # Accept user input\n    if prompt := st.chat_input(\"What shall we build today?\"):\n        # Add user message to chat history\n        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n        # Display user message in chat message container\n        with st.chat_message(\"user\", avatar=\"üßë‚Äçüíª\"):\n            st.markdown(\"**You:**\")\n            st.markdown(prompt)\n\n        # Display a spinner while waiting for the response\n        with st.chat_message(\"assistant\", avatar=\"üß†\"):\n            with st.spinner(\"The Garden is thinking...\"):\n                try:\n                    # Send the prompt to the orchestrator\n                    response = requests.post(f\"{ORCHESTRATOR_URL}/chat\", json={\"text\": prompt})\n                    response.raise_for_status() # Raise an exception for bad status codes\n                    full_response = response.json().get(\"response\", \"Error: No response received.\")\n                    \n                    # Stream the response for a more dynamic feel\n                    response_placeholder = st.empty()\n                    streamed_text = \"\"\n                    for char in full_response:\n                        streamed_text += char\n                        response_placeholder.markdown(streamed_text)\n                        time.sleep(0.005) # Adjust for desired speed\n\n                except requests.exceptions.RequestException as e:\n                    full_response = f\"**System Error:** Could not connect to the Orchestrator. Is it running? \\n\\nDetails: {e}\"\n                    st.error(full_response)\n        \n        # Add assistant response to chat history\n        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n\nwith tab2:\n    st.header(\"The Living Codex Explorer\")\n    st.write(\"This interface provides a direct view into the system's permanent memory (ChromaDB).\")\n\n    # NOTE: For this to be fully functional, the orchestrator.py script would need\n    # to be expanded with endpoints to query and return data from ChromaDB.\n    # Example: GET /codex_search?query=...\n    # Example: GET /pondering_pool\n\n    st.subheader(\"Search the Living Codex\")\n    search_query = st.text_input(\"Enter keywords to search past conversations:\")\n    if st.button(\"Search\"):\n        if search_query:\n            st.write(f\"Searching for '{search_query}'...\")\n            # Placeholder for API call to a hypothetical search endpoint\n            st.info(\"Search functionality is a future enhancement. This would involve adding a `/search` endpoint to the orchestrator that queries ChromaDB.\")\n            # Example of what the results might look like:\n            st.text_area(\"Result 1:\", \"USER: Tell me about resilience...\\nBRICK: Resilience is...\\nROBIN: Resilience feels like...\", height=150)\n        else:\n            st.warning(\"Please enter a search query.\")\n    \n    st.divider()\n\n    st.subheader(\"Autonomous Agent Logs\")\n    if st.button(\"View BABS's Pondering Pool\"):\n        st.info(\"This would call a `/pondering_pool` endpoint on the orchestrator to show unvalidated findings from BABS.\")\n        st.text_area(\"Finding 1: The Nature of Trust\", \"BABS's synthesized research on trust...\", height=150)\n\n    if st.button(\"View ALFRED's Integrity Alerts\"):\n        st.info(\"This would call an `/alerts` endpoint to show logs from ALFRED's curatorial audits.\")\n        st.warning(\"ALERT: Detected logical contradiction between Document #123 and Document #456 regarding the 'Fountain Protocol'. Architect review requested.\")","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}