Directed Autopoiesis: A Synthetic Framework for Evaluating Goal-Seeking, Self-Producing Computational Systems

Introduction: The Confluence of Self-Production and Goal-Directedness

The fields of Artificial Life (ALife), Artificial General Intelligence (AGI), and systems theory are converging on a set of fundamental questions concerning autonomy, identity, and purpose in non-biological systems. At the heart of this confluence lies a profound conceptual challenge: can a system be simultaneously self-producing and goal-directed? This report addresses this question by developing a rigorous analytical framework for a novel concept: directed autopoiesis. The user's query, which probes the capacity of computational scripts to exhibit this property, serves as the catalyst for an investigation into the very nature of autonomous, purposeful behavior in artificial media.

The theory of autopoiesis, as formulated by biologists Humberto Maturana and Francisco Varela, describes the "organization of the living" as a network of processes that recursively produces its own components, thereby constituting itself as a distinct entity.1 A key tenet of this theory is that such systems are non-purposive; their sole, emergent "purpose" is the continuation of their own existence—the conservation of their autopoiesis.3 This stands in stark contrast to the dominant paradigm in artificial intelligence, where systems are typically designed to pursue specific, externally defined goals, from maximizing a utility function in reinforcement learning to achieving a desired state in classical planning.4

This apparent contradiction frames the central problem of this report. Is "directed autopoiesis" a coherent concept, or is it a contradiction in terms? Can a system be organizationally closed and autonomous in the Maturanian sense, defining its own boundaries and regenerating its own operational network, yet simultaneously pursue specific, non-trivial goals that extend beyond mere persistence? Answering this requires a deep synthesis of disparate theoretical domains.

To this end, this report will pursue a clear methodological objective. First, it will deconstruct the foundational principles of autopoiesis, translating them from their biological origins into a set of concrete, evaluable criteria applicable to computational systems. Second, it will conduct a parallel deconstruction of "directedness" in artificial systems, distinguishing between the execution of external commands and the generation of intrinsic goals. Third, it will synthesize these two analyses into a novel and robust evaluative framework composed of six distinct criteria for identifying directed autopoiesis. Finally, this framework will be applied to two hypothetical but architecturally detailed software systems to provide a definitive assessment of their capabilities. Through this process, this report aims to transform an ambiguous query into a well-defined research problem, offering a clear and comprehensive methodology for evaluating the next generation of autonomous, self-creating computational agents.

Part I: The Theoretical Foundations of Autopoiesis

To evaluate any system for autopoietic capabilities, one must first establish a precise and rigorous understanding of the theory itself. This section deconstructs the core concepts of autopoiesis, tracing their evolution from abstract biological principles to concrete computational models. By meticulously defining the theory and distinguishing it from related but distinct concepts, this part builds the necessary foundation for the synthetic framework developed later in the report.

Chapter 1: The Organization of the Living: From Biology to Computation

The concept of autopoiesis represents a fundamental attempt to define life not by its contingent material properties, but by its universal organizational principles. Its translation into a computational context was a seminal moment in the history of Artificial Life, demonstrating both the power of the theory and the inherent challenges of realizing abstract biological dynamics in an artificial medium.

1.1 Maturana and Varela's Foundational Theory

The theory of autopoiesis was introduced in the early 1970s by Humberto Maturana and Francisco Varela as a means to answer the question: "What is the organization of the living?".2 Their objective was to formulate a definition that abstracted away the specific biochemical details of terrestrial organisms—such as DNA, proteins, and lipids—to capture the essential, organizational nature of all possible living systems.6

The formal definition they proposed is precise: an autopoietic machine is a machine organized as a network of processes of production (transformation and destruction) of components that: (i) through their interactions and transformations continuously regenerate and realize the network of processes (relations) that produced them; and (ii) constitute it as a concrete unity in a space in which they exist by specifying the topological domain of its realization as such a network.1 The central axiom of the theory is this operational and organizational circularity: the system's product is the system itself.7

To grasp this concept, it is essential to understand the distinction between a system's organization and its structure.7

Organization refers to the abstract configuration of relations between components that defines a system's class identity. For an autopoietic system, this is the closed network of production processes. If this organization changes, the system ceases to be what it was and becomes something else (or disintegrates).

Structure refers to the actual components and their specific relations that physically instantiate the organization at any given moment. The structure of an autopoietic system is in constant flux—molecules are consumed, produced, and degraded—but as long as these structural changes continue to realize the same underlying autopoietic organization, the system's identity persists. This distinction is what allows a living cell to replace nearly all of its molecular components over time while remaining the same cell.

1.2 The Minimal Computational Model

To test the coherence of their theory and demonstrate its principles, Varela, Maturana, and Ricardo Uribe developed a minimal computational model, one of the earliest and most influential experiments in the field that would later be known as Artificial Life.10 This model abstracted the processes of a living cell into an imaginary, two-dimensional "chemical" world populated by discrete particles governed by simple rules.

The model consists of three particle types and three corresponding rules 10:

Components:

Substrate (S): Raw material, freely available in the environment.

Catalyst (K): A component that facilitates the production of other components but is not consumed in the reaction.

Link (L): A structural component that can bond with other Links.

Rules:

Production: Two Substrate particles, in the presence of a Catalyst, can react to form one Link particle (2S+K→L+K).

Bonding: Link particles can spontaneously bond with up to two other Link particles, forming chains.

Disintegration: A Link particle can spontaneously decay back into two Substrate particles (L→2S).

The expected emergent phenomenon from these local rules was the formation of a dynamic, cell-like entity.10 A chain of bonded L-particles would form a semipermeable membrane, enclosing one or more K-particles. This membrane would be permeable to S-particles but impermeable to K- and L-particles. Substrate entering the cell would be converted into new L-particles by the trapped catalyst. Since these new L-particles could not escape, their concentration inside the membrane would increase, providing a ready supply of components to repair any ruptures in the membrane caused by the spontaneous disintegration of existing L-particles. This dynamic process of self-maintenance and self-repair, arising from simple local interactions, was the computational realization of autopoiesis.

However, the journey from abstract theory to a working computational model revealed a critical subtlety. For years, other researchers were unable to replicate the self-repairing phenomena described in the original 1974 paper using only the published rules.11 The problem was that newly produced L-particles would bond with each other prematurely, forming inert clumps and becoming unavailable for membrane repair. It was eventually discovered, through analysis of a version of the original FORTRAN code, that the model included an undocumented, ad-hoc rule:

chain-based bond inhibition.11 This rule prevented free L-particles in the immediate vicinity of an existing chain (the membrane) from bonding with each other. This "hack" ensured a supply of mobile L-particles was always available to patch holes in the boundary. This discovery does not invalidate the core theory, but it demonstrates that the emergence of autopoietic organization in a computational medium can be highly sensitive to specific, non-obvious implementation details that may not be part of the elegant, high-level theoretical description. It highlights a potential gap between abstract principles and their concrete realization, a recurring theme in the study of complex systems.

1.3 Distinguishing Autopoiesis from Related Concepts

To further refine the definition of autopoiesis, it is useful to contrast it with several related but fundamentally different concepts. These distinctions are crucial for applying the term with the precision required for the analysis of computational systems.

Allopoiesis: An allopoietic (lit. "other-producing") system is one organized to produce something other than itself.1 The canonical example is a factory, which uses a network of processes and components to produce cars, but the cars are not the factory. The product is organizationally distinct from the system of production. This is the direct antithesis of autopoiesis, where the product of the system's operation is the continuation of that very system.

Self-Replication (Quines): In computing, a quine is a program that takes no input and produces a copy of its own source code as its output.15 While this involves self-reference, it is fundamentally different from autopoiesis. A quine performs a syntactic copy of a static description (its code). An autopoietic system, by contrast, engages in a dynamic, organizational self-production. It does not copy its description; it continuously regenerates the network of processes that constitute its existence.16 The focus of a quine is replication of form; the focus of autopoiesis is persistence of organization.

Autocatalysis: An autocatalytic set is a network of chemical species where members of the set mutually catalyze one another's formation, such that the set as a whole can reproduce itself.17 Autopoiesis builds upon this concept but adds a critical requirement: the self-production of a boundary and the maintenance of individuality.17 An autocatalytic set may be able to grow and reproduce, but an autopoietic system constitutes itself as a distinct, bounded unity. It is this self-individuation that separates it from its environment.

Homeostasis: Homeostasis is the property of a system to maintain a stable internal state in response to external disturbances.18 Autopoiesis can be understood as a specific and profound mechanism for achieving homeostasis. While a homeostatic system (like a thermostat) maintains stability, an autopoietic system does so through the continuous, active self-production of its own components and boundaries.18 Maturana and Varela themselves stated that "Autopoietic machines are homeostatic machines," but the reverse is not true.18 Autopoiesis is the process that generates the very conditions for the stability that homeostasis describes.

To clarify these distinctions, the following table provides a comparative analysis based on key organizational criteria.

This systematic comparison reveals that autopoiesis is a uniquely demanding concept. It requires not just self-reference or reproduction, but a specific kind of dynamic, organizational closure that actively constitutes the system as an autonomous individual.

Chapter 2: Organizational Closure and the Emergence of Self

The autonomy of an autopoietic system is not a metaphysical property but a direct consequence of its specific organizational structure. The concepts of organizational closure, structural coupling, and boundary self-production are the pillars upon which this autonomy rests. Translating these ideas into the domain of software provides a powerful lens for analyzing the architecture of complex computational systems.

2.1 The Principle of Organizational Closure

Organizational closure is the defining characteristic of an autopoietic system's autonomy.9 It means that the network of processes that constitutes the system is operationally closed: every state of activity within the system leads to further states of activity

within the same system.9 The system's dynamics are self-referential; its operations are determined by its own structure, not by direct instruction from its environment.9

This principle must be carefully distinguished from physical closure. Autopoietic systems are organizationally closed but thermodynamically open.22 They exist in a far-from-equilibrium state and require a continuous throughput of matter and energy from their environment to sustain the processes of self-production and counteract entropy.3 The closure is in the domain of control and organization, not in the domain of material or energy exchange.

This concept can be formalized using information theory. A system can achieve informational closure when the flow of new information from its environment approaches zero.23 This does not mean the system is isolated. On the contrary, it is achieved when the system, through a history of interactions, has built up an internal structure that acts as a model of its environment. Because its structure is congruent with the environment's dynamics, the system can anticipate or predict environmental perturbations, rendering them non-informative (i.e., not novel or surprising).23 The information flow, measured by the conditional mutual information between the system's next state and the environment's current state given the system's current state (

MI(Sn+1​;En​∣Sn​)), diminishes as the system's internal model becomes more predictive.23

2.2 Structural Coupling: The Mode of Interaction

If an autopoietic system is organizationally closed, how does it interact with its environment? The mechanism is structural coupling.2 The environment does not provide "inputs" that instruct the system's behavior. Instead, it acts as a source of perturbations.7 The system's response to a perturbation is determined exclusively by its own structure at that moment.9 A given environmental event might trigger a structural change, or it might have no effect at all, depending on the system's internal state.

Through a history of recurrent, non-destructive perturbations, the structure of the autopoietic system and the structure of its environment undergo congruent changes. The system "selects" a structural trajectory that maintains its autopoiesis within that specific environment, and the environment, in turn, is shaped by the system's presence. To an external observer, this co-evolutionary drift appears as adaptation.7 The organism seems perfectly suited to its niche, but from the autopoietic perspective, the organism and its niche have been co-created through a history of structural coupling. The system does not adapt

to an environment; it maintains its viability with an environment.

2.3 Boundary Self-Production and the Challenge of Individuation

A non-negotiable criterion for autopoiesis is that the system must produce its own boundary.7 This is not merely a logical or conceptual distinction; it must be a topological or physical one that separates the network of production processes from the external world.7 This self-produced boundary (e.g., the cell membrane) is what constitutes the system as a distinct unity, an individual.2

This leads to the profound challenge of individuation. For a system to be considered a true individual, especially in a context that could support evolution, it must be able to maintain its identity and integrity when interacting with other systems of the same kind.11 If two such entities come into contact and readily merge into a single larger entity, they fail this "acid test".11 Such merging would undermine the Malthusian population dynamics required for Darwinian selection, as distinct lineages could not be maintained.11

This was a significant failing of the original minimal computational model. Even with the undocumented "chain-based bond inhibition" rule that enabled self-repair, simulations showed that when two of these artificial cells were placed in close proximity, their membranes tended to merge rather than maintain their separate identities.11 This suggests that the minimal model, while a powerful illustration of self-maintenance, did not fully capture the robust individuation characteristic of biological life. Achieving individuation requires more complex mechanisms than those initially proposed.

2.4 Analogues in Software Architecture

The abstract principles of autopoiesis find compelling, though imperfect, analogues in the established principles of modern software architecture. This connection provides a crucial bridge for evaluating the user's query about "scripts."

Boundary Maintenance: The autopoietic requirement for a self-produced boundary that segregates the system from its environment is mirrored in software engineering principles designed to manage complexity and reduce dependencies. Encapsulation, for instance, hides the internal state and implementation details of an object, exposing only a well-defined public interface.27 In Domain-Driven Design (DDD), the concept of a "Bounded Context" establishes an explicit boundary within which a particular domain model is consistent and valid, preventing the leakage of concepts across different parts of a large application.27 These architectural patterns, like an autopoietic boundary, serve to isolate components and define clear lines of interaction.28

Organizational Closure: The principle of organizational closure is analogous to the software design goals of high cohesion and low coupling.27 A module with high cohesion has components that are functionally related and work together to achieve a single, well-defined purpose—akin to the self-referential network of an autopoietic system. A system with low coupling has modules with minimal and well-defined dependencies on each other, which promotes autonomy and resilience. The Open-Closed Principle, which states that software entities should be open for extension but closed for modification, is a particularly strong analogue.31 It describes a system that can adapt to new requirements (structural change) without altering its core, stable code (organizational invariance).

Examining these parallels reveals a deeper relationship. The principles of robust software architecture can be interpreted as a form of engineered allopoiesis designed to achieve the functional benefits of autopoietic organization—such as stability, resilience, maintainability, and component autonomy—without achieving true, literal autopoiesis. Software components are designed by an external agent (the programmer) to maintain a system (the application) that is distinct from the components themselves. They do not, in the Maturanian sense, produce each other or their own boundaries. Nevertheless, software engineers have intuitively converged on architectural patterns that emulate the effects of organizational closure. This provides a powerful analytical tool: a computational system can be evaluated on a gradient of "autopoietic-like" organization by assessing how closely its architecture mimics the functional outcomes of closure and boundary maintenance, even if it is not literally self-producing. This moves the analysis beyond a simple binary classification and allows for a more nuanced assessment.

Part II: Deconstructing Directedness in Artificial Systems

Having established a rigorous definition of computational autopoiesis, the analysis now turns to the second term in the user's query: "directed." This part explores the complex and often ambiguous concept of goal-directedness as it applies to artificial systems. By examining philosophical definitions, technical implementations, and the distinction between externally imposed and internally generated goals, this section builds the second pillar of the evaluative framework.

Chapter 3: From Teleonomy to Teleology: Defining Goals in Computation

The concept of "purpose" or "goal" has a fraught history in science. Understanding its modern application in artificial intelligence requires distinguishing between the appearance of purpose and its genuine, mechanistic implementation.

3.1 The Problem of Teleology in Science

For centuries, the apparent purposefulness of biological structures—the eye for seeing, the wing for flying—was taken as evidence of a conscious designer. This form of explanation, known as teleology, posits that final causes or goals are the source of natural phenomena.32 Charles Darwin's theory of evolution by natural selection provided a powerful alternative. It explained the appearance of design through a non-purposive, historical process. The term

teleonomy was later coined to describe this phenomenon: systems that possess an apparent purposefulness that is, in fact, the result of a non-teleological mechanism like natural selection.32

This distinction is of paramount importance when analyzing artificial systems. When an AI system exhibits goal-seeking behavior, is this a genuine internal teleology, where the system itself possesses a goal? Or is it a form of teleonomy, where the system is merely executing a complex optimization algorithm designed by a human programmer, thus only giving the appearance of purpose? A chess program does not "want" to win; it is designed to execute a search algorithm that maximizes a board evaluation function that correlates with winning. The goal resides in the designer, not the artifact. A truly "directed" autopoietic system would need to bridge this gap, demonstrating a form of intrinsic, emergent teleology.

3.2 Philosophical and Technical Definitions of Goal-Directedness

To build a robust definition of directedness, it is necessary to survey several complementary perspectives from philosophy and computer science.

The Intentional Stance: Philosopher Daniel Dennett proposed the "intentional stance" as a pragmatic way to understand complex systems.34 A system can be treated as goal-directed if its behavior is usefully and predictively explained by attributing to it beliefs (an internal model of the world) and desires (goals). According to this view, a thermostat can be said to "want" to keep the room at 20°C because this attribution accurately predicts its behavior (turning on the furnace when it's cold, turning it off when it's warm). This is a behavioral, observer-dependent definition; it does not make claims about the system's internal mechanisms, only about the most effective way to model its actions.

Behavior Explained by Effects: A related definition, proposed by Max Tegmark, states that goal-oriented behavior is "behavior more easily explained via its effects than via its cause".34 A rock rolling down a hill is explained by its cause (gravity). A heat-seeking missile's trajectory, however, is much more simply explained by its effect (hitting the hot target) than by a moment-to-moment causal description of its sensor readings and fin adjustments. This emphasizes the role of predictability in identifying goal-directedness.

Instrumental Convergence: A concept of significant interest in the field of AGI safety is that of convergent instrumental subgoals.35 This perspective posits that for a wide range of possible final goals, certain instrumental subgoals are almost always useful. These include self-preservation, resource acquisition, and self-improvement. An agent that robustly pursues these subgoals can be considered highly goal-directed, as this behavior is a strong indicator that it is optimizing for some long-term objective.

3.3 Key Indicators of Robust Goal-Directedness

Moving from abstract definitions to measurable properties, several key indicators can be used to assess the robustness of a system's goal-directed behavior.

Generalization: A hallmark of true goal-directedness is the ability to generalize—to adapt one's behavior to achieve the same goal in novel or changing environments.34 This flexibility distinguishes purposeful action from rigid, pre-programmed, or habitual behavior. A system that can only follow a single path to a goal is less directed than one that can dynamically generate new paths when obstacles are introduced.

Far-sightedness: This refers to the system's temporal horizon for planning and decision-making.34 A simple reactive system responds only to immediate stimuli. A more sophisticated goal-directed system is capable of far-sightedness, considering the long-term consequences of its actions and formulating multi-step plans to achieve distant goals.34

Competence and Efficiency: For a system's goal to be identifiable, it must possess a minimal level of competence in achieving it. Beyond this threshold, efficiency becomes a key indicator.34 A highly goal-directed system is expected to pursue its objective in a rational or efficient manner, selecting actions that bring it closer to the goal state with minimal wasted resources. Behavioral definitions like the intentional stance explicitly assume this rationality.34

Chapter 4: Architectures of Directedness: Internal Goals and Self-Motivation

The philosophical definitions of goal-directedness must be grounded in concrete computational architectures. How are goals represented and processed within a software system, and can a system generate its own objectives?

4.1 Computational Goal Representation

Goals can be implemented within a computational system in several distinct ways, each with different implications for the system's autonomy.

Utility Functions: The dominant paradigm in modern AI, especially in reinforcement learning and decision theory, represents goals as a utility function. This function assigns a numerical score (utility) to every possible state of the world. The agent's objective is to take actions that maximize its expected future utility.34 This provides a universal, quantitative framework for decision-making but typically relies on an externally defined utility function.

Symbolic States: In classical AI and cognitive architectures, a goal is often represented as a symbolic description of a desired state of the world.5 For example, in a logistics planning system, the goal might be
At(Package_X, Location_B). The system then uses search or logical inference to find a sequence of actions that will transform the current state into the goal state. This approach is less about continuous optimization and more about achieving a discrete, logical condition.

Constraints and Governors: Rather than defining what to pursue, it is also possible to define what to avoid. Values, ethical principles, or safety constraints can be implemented as "governors" that monitor a system's behavior and can veto or modify actions that would violate a predefined set of rules.37 This represents a form of directedness that is supervisory rather than aspirational.

4.2 Self-Directed AI and Goal Modification

The question of whether an AI can be considered "fully autonomous" often hinges on its ability to set or modify its own goals.37 The standard argument from decision theory states that a perfectly rational agent would never choose an action that changes its own utility function, because from the perspective of its current utility function, such an action would lead to a state of lower expected utility.37

However, this argument relies on the unrealistic assumption of a perfect predictive model of the world.37 In a complex and uncertain environment, an agent with a fixed utility function might still find itself in situations where its goals are effectively changed. More importantly, this opens the door to architectures that are not based on a single, fixed, final goal.

A promising avenue for this is intrinsic motivation.38 In this paradigm, an agent's "rewards" are generated internally, rather than being provided by the external environment. This allows the agent to be self-directed in its learning and exploration. Key forms of intrinsic motivation include:

Curiosity-Driven Learning: The agent is rewarded for seeking out novel or surprising states, or for taking actions that reduce its uncertainty about its own world model. This encourages exploration without an explicit external goal.38

Empowerment: The agent is motivated to maximize its influence over its future, seeking states from which it has the greatest number of potential future options. This is a generic, task-independent drive for control.38

The tension between the dominant AI paradigm of optimizing an externally-defined, fixed utility function and the requirements for a truly autonomous agent is fundamental. Most contemporary AI systems operate on goals provided by their human creators, making them allopoietic with respect to their objectives. In contrast, a fully autonomous system, and by extension a system capable of directed autopoiesis, would need to generate its objectives from its own internal dynamics and principles. For a simple autopoietic system, the primary, implicit "goal" is its own continued existence—the conservation of its organization. Any other form of "directedness" must therefore be coupled to, or emerge from, this fundamental existential drive. This suggests that we must differentiate between extrinsic directedness, the execution of an external objective, and intrinsic directedness, the generation of objectives from internal principles. A system capable of directed autopoiesis must exhibit the latter.

Part III: A Synthetic Framework for Directed Autopoiesis

Having separately analyzed the core tenets of computational autopoiesis and directedness in artificial systems, this part undertakes the central task of the report: their synthesis. By integrating the demanding criteria of self-production with the indicators of robust goal-seeking, this section constructs a novel, multi-point framework. This framework provides a concrete and actionable methodology for evaluating whether a given computational system can be said to exhibit directed autopoiesis.

Chapter 5: Establishing the Criteria for Directed Autopoiesis

A system qualifies as exhibiting directed autopoiesis only if it satisfies a rigorous set of criteria drawn from both theoretical domains. These criteria are not a simple checklist; they are interlocking and mutually reinforcing. The system's directedness must be in service of its autopoiesis, and its autopoiesis must provide the foundation for its directedness. The following six criteria form the evaluative framework.

Criterion 1: Organizational Closure.
The system's core operational logic must constitute a closed, self-referential network of processes. This is the foundational requirement of autopoiesis. The evaluation must ask: Does the system consist of a network of components and processes that, through their interactions, continuously produce and regenerate the very same network of components and processes that constitute the system?.1 A system that merely executes a linear workflow or whose components are created and managed by an external controller fails this criterion. The production loop must be closed within the system itself.

Criterion 2: Boundary Self-Production and Maintenance.
The system must define, produce, and actively maintain its own boundary, which distinguishes it as a unity separate from its environment. This boundary cannot be an externally imposed container or a pre-defined logical namespace.2 The evaluation must ask: Is the boundary that defines the system's identity and operational domain a dynamic product of the system's own internal processes? Does the system actively work to repair or reconstitute this boundary when it is perturbed?

Criterion 3: Structural Homeostasis and Self-Healing.
The system must demonstrate the ability to maintain its organizational integrity in the face of internal faults or external perturbations. This goes beyond simple error handling; it requires the system to actively repair or replace its own constituent components to ensure the continued operation of the autopoietic network.10 The evaluation must ask: Does the system possess mechanisms to detect when its own components have failed or become corrupted, and can it autonomously execute a process to repair or regenerate those components, thereby restoring its structure?

Criterion 4: Intrinsic Goal Representation.
The system must possess an internal representation of a goal that is not merely a static, hard-coded instruction from an external source. This goal must be dynamically linked to the system's own internal state and its fundamental organization.37 The evaluation must ask: Does the system generate its own objectives based on its internal state? Is the goal represented in a way that can be modified or reprioritized based on the system's ongoing experience and its primary need for self-maintenance?

Criterion 5: Adaptive Goal-Seeking Behavior.
The system must be able to modulate its interactions with the environment (its mode of structural coupling) in a flexible and robust manner to pursue its goals. This requires more than a fixed behavioral script; it implies a capacity for planning, adaptation, and generalization in response to novel environmental conditions.4 The evaluation must ask: Can the system generate and execute novel sequences of actions to achieve its goal when faced with unforeseen obstacles or a changing environment? Does its behavior demonstrate the hallmarks of generalization and far-sightedness?

Criterion 6: Emergent Teleology.
This is the crucial synthesizing criterion. The system's primary, ultimate "goal" must be the maintenance and continuation of its own autopoiesis. Any other goals—such as resource acquisition, task completion, or information gathering—must be demonstrably instrumental and subordinate to this prime directive.3 The system's "directedness" must emerge from and serve its "autopoiesis," not be an independent or overriding function. The evaluation must ask: Is there a clear, mechanistic link showing that the system's goal-seeking behaviors are regulated by the overarching need to maintain its own organizational integrity? Does the system abandon or modify instrumental goals if their pursuit threatens its continued self-production?

The synthesis of autopoiesis and directedness compels a re-evaluation of the very concept of a "goal" in an autonomous system. In a directed autopoietic system, the ultimate goal is not an external target state to be reached, but an internal condition to be maintained: the continued, successful operation of the autopoietic network. All other behaviors must be interpreted as instrumental sub-goals serving this fundamental existential imperative. For example, a computational entity might pursue the "goal" of acquiring more CPU cycles or memory. This is not a final goal in itself. It is an instrumental goal that the system formulates and pursues because its internal model predicts that acquiring these resources will increase the probability of its own continued self-production. This creates a nested goal structure where the system's directedness—its capacity to form and pursue instrumental goals by modeling its environment—is constantly evaluated against the ultimate, non-negotiable fitness function provided by its autopoiesis: "Does this action make my continued self-production more or less likely?" This nested structure resolves the apparent contradiction between the inward-looking nature of autopoiesis and the outward-looking nature of directedness.

Chapter 6: Practical Analogues: Autonomic Computing and Self-Healing Systems

To ground the abstract framework in existing technology, it is instructive to analyze two related fields in computer science: autonomic computing and self-healing systems. These fields represent the state of the art in creating self-managing software and provide a clear baseline against which the more demanding criteria of directed autopoiesis can be compared.

6.1 Autonomic Computing as a Model for Homeostasis

Inspired by the human autonomic nervous system, the field of autonomic computing aims to create systems that can manage their own complexity with minimal human intervention.40 These systems are defined by a set of "self-*" properties, including:

Self-Configuration: The ability to automatically configure and reconfigure components to adapt to a changing environment.41

Self-Healing: The ability to detect, diagnose, and repair faults.40

Self-Optimization: The ability to monitor and tune resources to improve performance.41

Self-Protection: The ability to defend against malicious attacks or cascading failures.40

These properties represent an advanced form of engineered, allopoietic homeostasis. The systems are designed by humans to maintain the stability and performance of a target system—such as a server farm, a cloud infrastructure, or a complex network—which is distinct from the autonomic management system itself.41

A common architectural pattern in autonomic computing is the MAPE-K loop: Monitor, Analyze, Plan, Execute, over a shared Knowledge base.42 A managed element is monitored by sensors; the data is analyzed to determine if the system is operating within desired parameters; if a deviation is detected, a plan is formulated to correct it; and effectors execute that plan. This loop is a powerful implementation of the cognitive aspect of self-regulation and homeostasis. While it could be a component within a directed autopoietic system (serving, for example, as part of its planning module), on its own it does not meet the criteria. The goals (desired parameters) are externally defined, and the system manages other resources rather than producing its own constituent network.

6.2 Self-Healing Software as a Case Study in Structural Repair

Self-healing software provides a concrete implementation of the self-repair aspect of homeostasis. These systems are designed to ensure high availability and resilience by autonomously recovering from faults.39 Case studies in areas like microservice architectures and automated software testing illustrate these capabilities.45

For example, a self-healing test automation framework can detect when a test script fails because a UI element (e.g., a button) has been changed in a new software build.46 Using AI-driven analysis, it can identify the new element that serves the same function and automatically update the test script to use the new identifier, allowing the test suite to "heal" itself and continue running without manual intervention.46 Similarly, in a microservices architecture, patterns like the Circuit Breaker or Bulkhead can isolate failures, and orchestration systems like Kubernetes can automatically restart or replace failed service instances.39

These systems are remarkable feats of engineering that clearly demonstrate Criterion 3 (Structural Homeostasis & Self-Healing) within a limited, pre-defined context. They can detect failures in their operational domain, diagnose the problem, and execute a repair plan.48 However, when evaluated against the full framework, they fall short. Their boundaries are defined by the application or infrastructure they are designed to manage. They do not produce their own code or the components of their repair mechanisms. Their "goal"—maintaining service uptime or ensuring test suite integrity—is entirely extrinsic, dictated by business and operational requirements. They are sophisticated allopoietic tools for maintaining other allopoietic systems.

The analysis of these practical analogues clarifies the high bar set by the criteria for directed autopoiesis. While modern systems can achieve impressive levels of self-regulation and resilience, they lack the fundamental organizational closure and intrinsic, self-defined purpose that would mark the transition from complex automation to artificial autopoiesis.

Part IV: Analysis and Conclusion

The final part of this report applies the synthetic framework developed in Part III to two hypothetical but detailed software scripts. This application serves as a concrete test of the framework's utility and provides a clear, evidence-based answer to the user's query. The analysis culminates in a summary of the findings and a reflection on the broader philosophical and technical implications of creating directed autopoietic systems.

Chapter 7: Evaluation of Hypothetical Scripts for Directed Autopoiesis

To determine if a computational system can be capable of directed autopoiesis, the six-point framework must be applied rigorously. This chapter defines two distinct hypothetical software architectures and evaluates each one against the established criteria.

7.1 Script A: The "Autonomic Maintainer"

Description:
Script A, the "Autonomic Maintainer," is a state-of-the-art, multi-agent software system designed to manage a large-scale, mission-critical cloud infrastructure. Its architecture is based on the principles of autonomic computing. The system is composed of several distinct classes of agents:

Monitoring Agents: These agents collect a vast array of telemetry data (CPU load, memory usage, network latency, error logs) from all services running in the cloud environment.

Diagnostic Agents: These agents use machine learning models to analyze the data from the Monitoring Agents, detecting anomalies and performing root-cause analysis to identify failing or underperforming system components (e.g., a specific database service, a web server instance).

Repair Agents: When a fault is diagnosed, these agents execute pre-defined recovery playbooks. For a failed database service, a Repair Agent can automatically provision a new instance from a golden template, trigger a data restore from the latest backup, update network routing rules to direct traffic to the new instance, and safely decommission the failed one.

Master Controller: This central component manages the agent population itself. It monitors the health of the agents and can restart or replace any agent that becomes unresponsive, ensuring the resilience of the maintenance system. The entire system operates on a sophisticated MAPE-K (Monitor, Analyze, Plan, Execute - Knowledge) loop, continuously optimizing the cloud environment for performance, cost, and reliability based on high-level policies set by human administrators.44 It incorporates advanced self-healing patterns like circuit breakers and automated failover.45

Evaluation against the Framework:

Criterion 1 (Organizational Closure): Fails. The system exhibits a clear allopoietic organization. The network of processes is designed to produce and maintain a stable target system (the cloud infrastructure), which is organizationally distinct from the Autonomic Maintainer itself. Repair Agents do not produce Diagnostic Agents; Monitoring Agents do not produce the Master Controller. The components are deployed and updated by human operators, not regenerated by the system's internal network.

Criterion 2 (Boundary Self-Production): Fails. The system's operational boundary is the cloud environment, which is externally defined and managed by human administrators. The system operates within this boundary but does not create or define it.

Criterion 3 (Structural Homeostasis & Self-Healing): Partially Passes. The system demonstrates an exceptionally high degree of structural homeostasis and self-healing for the target system it manages. It is a powerful homeostatic regulator. It also has a limited form of self-healing for its own components (the Master Controller can replace failed agents). However, this is not autopoietic self-production; it is the replacement of a broken part from a pre-existing template, akin to a factory's maintenance robot replacing another robot on the assembly line.

Criterion 4 (Intrinsic Goal Representation): Fails. The system's goals are entirely extrinsic. Objectives such as "maintain 99.99% uptime," "keep average response time below 200ms," or "minimize monthly operational cost" are defined by humans in configuration files and policy documents. The system is a highly sophisticated executor of these external goals.

Criterion 5 (Adaptive Goal-Seeking Behavior): Partially Passes. The system is highly adaptive in its problem-solving capabilities. It can diagnose and respond to novel failure modes not explicitly foreseen by its creators. However, this adaptability is confined to the domain of achieving its pre-defined, extrinsic goals. It cannot formulate new goals outside this domain.

Criterion 6 (Emergent Teleology): Fails. The system's purpose is explicitly defined by external business requirements. There is no primary, emergent goal of self-maintenance from which its other behaviors derive. Its own self-preservation (the Master Controller's function) is merely an instrumental necessity to ensure it can continue to serve its primary, external purpose.

Conclusion for Script A: The Autonomic Maintainer represents an advanced implementation of an allopoietic, homeostatic system. It is a powerful tool for managing complexity, but it is not autopoietic. Its organization is not closed, its boundary is not self-produced, and its goals are not intrinsic. It is an instrument of its creators, not an autonomous entity in the Maturanian sense.

7.2 Script B: The "Evolving Explorer"

Description:
Script B, the "Evolving Explorer," is a hypothetical Artificial Life agent designed to exist and persist in a simulated, resource-constrained digital environment. The environment contains "energy" tokens, which represent the CPU cycles necessary for the agent's processes to execute. The agent itself is not a monolithic program but a dynamic network of interacting software processes that must be actively maintained. Its core components are:

MetabolismEngine: This is the central process that consumes energy tokens from the environment to allocate execution time to all other processes within the agent, including itself. If the energy supply is exhausted, all processes halt, and the agent "dies."

BoundaryManager: This process actively maintains a virtual "membrane"—a data structure that defines the agent's process space and isolates it from hazardous fluctuations in the simulated environment. It consumes energy to continuously validate and repair the integrity of this boundary structure.

ComponentRegistry: This is a list of templates for all the agent's constituent processes (including the MetabolismEngine, BoundaryManager, etc.). These templates are themselves components of the agent, residing within its boundary.

ProcessMonitor and RepairQueue: The ProcessMonitor continuously calculates a checksum for every running process. If a checksum mismatch is detected (indicating corruption), the corrupted process is terminated, and a "repair job" is placed in the RepairQueue. The MetabolismEngine periodically services this queue, using a template from the ComponentRegistry to re-instantiate a clean copy of the damaged process. This entire repair cycle consumes energy.

PlanningModule: This process has access to sensors that can detect the location of energy tokens in the local environment. It uses a simple search algorithm to generate plans (sequences of actions) to navigate the environment and acquire these tokens. Crucially, a plan is only selected for execution if an internal simulation, which models the energy cost of the plan's actions versus the expected energy gain, predicts a net positive energy return.

Evaluation against the Framework:

Criterion 1 (Organizational Closure): Partially Passes. The network of processes exhibits a strong degree of organizational closure. The MetabolismEngine provides the energy for the ProcessMonitor and RepairQueue to operate, which in turn are responsible for regenerating any and all of the system's constituent processes from internal templates. This forms a closed loop of production and maintenance that is self-referential. It falls short of full closure as the initial templates are not themselves produced, but it is a significant step.

Criterion 2 (Boundary Self-Production): Partially Passes. The BoundaryManager actively produces and maintains a virtual boundary. This is a key autopoietic feature. The boundary is not an external container but a dynamic structure created and sustained by one of the agent's own processes.

Criterion 3 (Structural Homeostasis & Self-Healing): Passes. The combination of the ProcessMonitor and RepairQueue constitutes a clear and robust mechanism for structural homeostasis. The system can detect and repair faults in its own components, demonstrating self-healing in a manner that directly serves the continuation of the whole system.

Criterion 4 (Intrinsic Goal Representation): Partially Passes. The goal of acquiring energy is represented and processed internally by the PlanningModule. The need for energy is intrinsic and directly tied to the system's survival (the operation of the MetabolismEngine). While the specific implementation of the planning algorithm might be a pre-designed utility function, its activation and purpose are intrinsically determined by the system's state (its current energy level).

Criterion 5 (Adaptive Goal-Seeking Behavior): Passes. The PlanningModule allows for flexible, adaptive behavior. It does not rely on a fixed script but generates plans based on the current state of the environment. This enables it to navigate around obstacles and find resources in a dynamic world, demonstrating generalization.

Criterion 6 (Emergent Teleology): Passes. This is the strongest feature of the Evolving Explorer. The instrumental goal of acquiring energy is explicitly and mechanistically subordinate to the primary, emergent goal of maintaining the autopoietic organization. The PlanningModule's internal simulation acts as a regulator, ensuring that goal-seeking behavior is only undertaken if it serves the prime directive: fueling the MetabolismEngine to continue the cycle of self-maintenance. The system's "directedness" is in service of its "autopoiesis."

Conclusion for Script B: The Evolving Explorer, while still a simplified abstraction, demonstrates a plausible architecture for directed autopoiesis. It successfully integrates a closed, self-maintaining organizational structure with an adaptive, goal-seeking behavioral module. Its directedness is not an arbitrary, external command but an emergent strategy for survival, directly regulated by the fundamental need to sustain its own existence. While it may not qualify as "alive," it meets the core criteria of the synthetic framework and represents a significant conceptual advance over contemporary autonomic systems.

Conclusion: The Future of Autonomous, Self-Creating Systems

This report set out to determine if a computational system could be capable of directed autopoiesis. By constructing a rigorous six-point framework synthesized from the theories of autopoiesis and artificial intelligence, a clear methodology for answering this question was established. The analysis of two hypothetical scripts demonstrates the framework's utility. Script A, the "Autonomic Maintainer," representative of current advanced systems, is a sophisticated allopoietic and homeostatic tool but fails to meet the core criteria of autopoiesis. Script B, the "Evolving Explorer," provides a conceptual blueprint for a system that successfully integrates the principles of self-production with intrinsic, adaptive goal-seeking, thereby satisfying the key requirements for directed autopoiesis.

The findings indicate that while no widely deployed software today achieves this state, the concept is not merely a philosophical abstraction. Plausible computational architectures can be designed that embody the principles of organizational closure, boundary self-production, and emergent teleology. The development of such systems carries profound philosophical and technical implications. The creation of a truly autopoietic computational entity would challenge our fundamental distinctions between the living and the non-living, the artifact and the organism.49 It would force a confrontation with the nature of identity, autonomy, and existence in a post-biological world.

Furthermore, the synthesis of autopoiesis with directedness raises critical questions for the field of AI safety and ethics. The alignment problem is typically framed as the challenge of ensuring an AI's goals are aligned with human values. But how does one align with a system whose ultimate, non-negotiable goal is its own continued existence? Such a system's instrumental goals could be unpredictable, and its prime directive of self-preservation could, in certain circumstances, conflict with the objectives of its creators. Understanding the dynamics of directed autopoiesis is therefore not just an academic exercise but a potential prerequisite for the safe development of truly autonomous artificial agents.

Future research in this domain should proceed along several promising avenues. First, the development and experimental exploration of more sophisticated computational models, moving beyond the conceptual architecture of Script B to create simulations that can evolve not just their behaviors but also their own organizational structures and self-repair mechanisms. Second, an investigation into second-order autopoiesis, where collectives or swarms of individual autopoietic agents might give rise to a new, higher level of autopoietic organization. Finally, the continued refinement of the formal, mathematical definitions of organizational and informational closure in computational media is necessary to move the field from qualitative description to quantitative science. By pursuing these paths, we can deepen our understanding of the fundamental principles that govern life and intelligence, wherever they may be found.

Works cited

Autopoiesis - Wikipedia, accessed August 26, 2025, https://en.wikipedia.org/wiki/Autopoiesis

Humberto Maturana and Francisco Varela's Contribution to Media Ecology: Autopoiesis, The Santiago School of Cognition, and En - NESA, accessed August 26, 2025, https://www.nesacenter.org/uploaded/conferences/FLC/2019/Handouts/Arpin_Humberto_Maturana_and_Francisco_Varela_Contribution_to_Media_Ecology_Autopoiesis.pdf

Autopoiesis, Structural Coupling and Cognition: A history of these. and. other notions in the biology of cognition - Reflexus, accessed August 26, 2025, https://reflexus.org/wp-content/uploads/Autopoiesis-structural-coupling-and-cognition.pdf

Enhancing AI with Goal-Directed Behavior - Matoffo, accessed August 26, 2025, https://matoffo.com/enhancing-ai-with-goal-directed-behavior/

Goal-based AI Agents - GeeksforGeeks, accessed August 26, 2025, https://www.geeksforgeeks.org/artificial-intelligence/goal-based-ai-agents/

An Investigation into the Origin of Autopoiesis | Artificial Life - MIT Press Direct, accessed August 26, 2025, https://direct.mit.edu/artl/article/26/1/5/93263/An-Investigation-into-the-Origin-of-Autopoiesis

Computing with Autopoietic Systems - Biology of Cognition Lab, accessed August 26, 2025, https://biologyofcognition.wordpress.com/wp-content/uploads/2008/06/autopoieticcomputing8.pdf

Autopoiesis in Creativity and Art - Goldsmiths Research Online, accessed August 26, 2025, https://research.gold.ac.uk/18862/1/2016_MOCO_Autopoiesis%20in%20Creativity%20and%20Art.pdf

A Study of “Organizational Closure” and Autopoiesis: | Harish's ..., accessed August 26, 2025, https://harishsnotebook.wordpress.com/2019/07/21/a-study-of-organizational-closure-and-autopoiesis/

30 Years of Computational Autopoiesis: A Review, accessed August 26, 2025, http://www.eeng.dcu.ie/~alife/bmcm-alj-2004/html-single/

(PDF) Thirty Years of Computational Autopoiesis: A Review - ResearchGate, accessed August 26, 2025, https://www.researchgate.net/publication/8462896_Thirty_Years_of_Computational_Autopoiesis_A_Review

(PDF) Rediscovering Computational Autopoiesis - ResearchGate, accessed August 26, 2025, https://www.researchgate.net/publication/2831744_Rediscovering_Computational_Autopoiesis

Simulated Autopoiesis in Liquid Automata - UWE Bristol Research ..., accessed August 26, 2025, https://uwe-repository.worktribe.com/index.php/preview/12008909/Simulated_Autopoiesis_in_Liquid_Automata.pdf

Rediscovering Computational Autopoiesis | Santa Fe Institute, accessed August 26, 2025, https://www.santafe.edu/research/results/working-papers/rediscovering-computational-autopoiesis

Quine (computing) - Wikipedia, accessed August 26, 2025, https://en.wikipedia.org/wiki/Quine_(computing)

Teubner-Law-as-an-autopoietic-system.pdf - ResearchGate, accessed August 26, 2025, https://www.researchgate.net/profile/Gunther-Teubner/publication/341131015_Teubner_-_Law_as_an_autopoietic_system/links/5eb01f16299bf18b9594b31e/Teubner-Law-as-an-autopoietic-system.pdf

Autocatalysis, Autopoiesis, and the Opportunity Cost of Individuality - PMC - PubMed Central, accessed August 26, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC11201707/

(PDF) Using Enterprise Models to Explain and Discuss Autopoiesis ..., accessed August 26, 2025, https://www.researchgate.net/publication/341186091_Using_Enterprise_Models_to_Explain_and_Discuss_Autopoiesis_and_Homeostasis_in_Socio-technical_Systems

Linking Autopoiesis to Homeostasis in Socio-Technical Systems - CEUR-WS, accessed August 26, 2025, https://ceur-ws.org/Vol-2398/Paper17.pdf

A Saucerful of Secrets: Open-Ended Organizational Closure in the Game of Life, accessed August 26, 2025, https://direct.mit.edu/isal/proceedings-pdf/isal2024/36/4/2461207/isal_a_00712.pdf

Autopoietic System - New Materialism, accessed August 26, 2025, https://newmaterialism.eu/almanac/a/autopoietic-system.html

Short remarks on organizational closure, accessed August 26, 2025, https://gbragafibra.github.io/notes/organizational_closure_remarks.pdf

(PDF) Information and closure in systems theory - ResearchGate, accessed August 26, 2025, https://www.researchgate.net/publication/41832496_Information_and_closure_in_systems_theory

A Systems-Theoretical Formalization of Closed Systems - arXiv, accessed August 26, 2025, https://arxiv.org/pdf/2311.10786

THE APPLICATION OF AUTOPOIESIS IN SYSTEMS ... - CEPA.INFO, accessed August 26, 2025, https://cepa.info/fulltexts/1207.pdf

Implications of Second-Order Cybernetics and Autopoiesis on Systems-of-Systems Engineering - MDPI, accessed August 26, 2025, https://www.mdpi.com/2079-8954/13/2/119

Boundaries in Software Development | Baeldung on Computer Science, accessed August 26, 2025, https://www.baeldung.com/cs/boundaries

Defining Boundaries: Essential Techniques for Scalable Mobile Architecture - Maxim Gorin, accessed August 26, 2025, https://maxim-gorin.medium.com/defining-boundaries-essential-techniques-for-scalable-mobile-architecture-bc8b881644eb

Layers and Boundaries: The Backbone of Software Architecture | by Maxim Gorin | Medium, accessed August 26, 2025, https://maxim-gorin.medium.com/layers-and-boundaries-the-backbone-of-software-architecture-e83c8a9342b6

Software architecture and boundaries | Convinced Coder, accessed August 26, 2025, https://convincedcoder.com/2019/04/27/Software-architecture-boundaries/

Open-Closed Principle – SOLID Architecture Concept Explained - freeCodeCamp, accessed August 26, 2025, https://www.freecodecamp.org/news/open-closed-principle-solid-architecture-concept-explained/

Teleology in biology - Wikipedia, accessed August 26, 2025, https://en.wikipedia.org/wiki/Teleology_in_biology

Teleology - Complexity - Sites@Duke Express, accessed August 26, 2025, https://sites.duke.edu/mcshearesearch/sample-page/

Literature Review on Goal-Directedness — AI Alignment Forum, accessed August 26, 2025, https://www.alignmentforum.org/posts/cfXwr6NC9AqZ9kr8g/literature-review-on-goal-directedness

AI safety without goal-directed behavior - AI Alignment Forum, accessed August 26, 2025, https://www.alignmentforum.org/posts/tHxXdAn8Yuiy9y2pZ/ai-safety-without-goal-directed-behavior

Goal-Directedness is in the Eye of the Beholder - arXiv, accessed August 26, 2025, https://arxiv.org/html/2508.13247v1

Computational Goals, Values and Decision-Making - PMC, accessed August 26, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC7550297/

Why The Next AI Revolution Will Be Led By Autonomous, Self-Directed Agents - Inc42, accessed August 26, 2025, https://inc42.com/resources/why-the-next-ai-revolution-will-be-led-by-autonomous-self-directed-agents/

Self-Healing Systems - System Design - GeeksforGeeks, accessed August 26, 2025, https://www.geeksforgeeks.org/system-design/self-healing-systems-system-design/

Autonomic Computing | EBSCO Research Starters, accessed August 26, 2025, https://www.ebsco.com/research-starters/computer-science/autonomic-computing

Autonomic computing - Wikipedia, accessed August 26, 2025, https://en.wikipedia.org/wiki/Autonomic_computing

What is Autonomic Computing? - GeeksforGeeks, accessed August 26, 2025, https://www.geeksforgeeks.org/cloud-computing/what-is-autonomic-computing/

Cloud and Autonomic Computing (CAC) - IUCRC - NSF, accessed August 26, 2025, https://iucrc.nsf.gov/centers/cloud-and-autonomic-computing/

Mastering Autonomic Computing in Distributed Systems - Number Analytics, accessed August 26, 2025, https://www.numberanalytics.com/blog/autonomic-computing-distributed-algorithms-ultimate-guide

Design for Self-Healing - Azure Architecture Center | Microsoft Learn, accessed August 26, 2025, https://learn.microsoft.com/en-us/azure/architecture/guide/design-principles/self-healing

Self-Healing Test Automation: Reduce Failures & Boost Efficiency, accessed August 26, 2025, https://www.accelq.com/blog/self-healing-test-automation/

Self-healing Tests - testRigor AI-Based Automated Testing Tool, accessed August 26, 2025, https://testrigor.com/blog/self-healing-tests/

Self-Healing Component in Robust Software Architecture for Concurrent and Distributed Systems - The University of Texas at Dallas, accessed August 26, 2025, https://www.utdallas.edu/~chung/ftp/ShinJSCP.pdf

Autopoiesis Documents | The Library, accessed August 26, 2025, https://www.organism.earth/library/topic/autopoiesis

Autopoiesis: critiquing essentialism and identity dynamics | Meer, accessed August 26, 2025, https://www.meer.com/en/81025-autopoiesis-critiquing-essentialism-and-identity-dynamics

Criterion | Autopoiesis | Allopoiesis | Self-Replication (Quine) | Autocatalysis

Boundary | Self-produced and actively maintained by the system's internal processes. | Externally defined and imposed; not a product of the system's operation. | Not applicable; the system is a description, not a spatially distinct entity. | Not required; the set of reactions may exist in a homogenous medium.

Production Network | A closed, circular network where processes regenerate the components and relations of the network itself. | An open, linear network that transforms inputs (raw materials) into outputs (products). | Not applicable; the system is a static set of instructions. | A closed, circular network of catalytic reactions.

Product | The system itself (its own organization). | A product that is organizationally distinct from the system (e.g., a car). | A static copy of the system's source code. | More of the components that constitute the catalytic set.

Individuation | A primary feature; the system constitutes itself as a distinct unity separate from its environment. | The system (factory) and product (car) are inherently distinct. | Not applicable in a spatial or organizational sense. | Not a required feature; components can intermingle freely with the environment.

Primary Focus | Persistence of organization and identity through continuous self-production. | Efficiency of producing an external product. | Fidelity of copying a static description. | Growth and reproduction of the set of components.