Part V: The Morphic UI Framework - Direct Manipulation in a Prototypal World


This part of the guide bridges the abstract principles of prototype-based programming, as detailed in the preceding sections on Self, Smalltalk, and Io, with their ultimate manifestation in a graphical user interface. It posits that Morphic is not merely a UI toolkit for a prototypal system, but the logical and philosophical graphical extension of such a system. It demonstrates how the core tenets of concreteness, liveness, and direct object manipulation are realized in a tangible, visual environment.


V.I: The Philosophy of Morphic: A UI of Live Objects


The intellectual and philosophical foundation of Morphic is an inevitable consequence of the "everything is an object" and "liveness" principles central to the Smalltalk/Self paradigm. It represents the culmination of this philosophy, extending it from the abstract realm of code into the concrete, visual domain of the user interface.


Introduction to Morphic's Origins and Core Tenets


Morphic is a user interface construction environment that originated within the Self programming language project at Sun Microsystems.1 As a direct descendant of the Smalltalk lineage, its design was a radical departure from conventional UI toolkits, aiming to make the creation and editing of interactive graphical objects maximally direct and live.3 This is achieved through two guiding principles:
1. Direct Manipulation: This is the core interactive principle of Morphic. It is defined as the ability for a user or developer to initiate the process of examining or changing the attributes, structure, and behavior of any UI component by pointing at and interacting with its graphical representation directly.2 Instead of editing code or property sheets in a separate tool to change a button's color, one interacts with the button itself to effect the change. This creates a powerful illusion of interacting with tangible, concrete objects rather than abstract representations.6
2. Liveness: Inherited directly from the image-based, always-on nature of Smalltalk and Self environments, liveness means the user interface is perpetually active and reactive.4 Objects continuously respond to user input, animations run, layout is dynamically managed, and informational displays update without the need for a separate "compile" or "run" step.2 The system is always running; development is a process of making incremental changes to this live system and receiving immediate feedback.2


Morphic as the Graphical Manifestation of Prototypal Philosophy


The design of Morphic is a logical completion of the philosophical progression from Smalltalk to Self. Where Smalltalk established the principle that "everything is an object," and Self refined this to "every object is a concrete prototype," Morphic extends the syllogism to its natural conclusion: "every graphical element on the screen is a live, concrete, and modifiable object".2
This extension fundamentally dissolves the traditional separation between the development environment and the running application. The user interface itself becomes a collection of inspectable, scriptable, and modifiable objects that are an integral part of the live system image.5 This stands in stark contrast to conventional UI development, which typically involves editing textual representations (e.g., source code, XML, HTML) and then executing a separate process to visualize the result. In Morphic, the distinction between "design-time" and "run-time" is deliberately blurred to the point of non-existence, fostering an environment of continuous, direct interaction.2
This approach represents a rejection of the representationalism inherent in most UI frameworks. In a typical object-oriented GUI, the button visible on the screen is merely a representation of a Button object residing in memory. The developer's primary mode of interaction is with the textual abstraction of that object—its source code. Morphic, by contrast, presents the developer and user with the actual, live objects of the running system.2 This is not simply a different API; it is a different epistemology for user interfaces. It argues that the most effective way to program a graphical system is to eliminate the layer of textual abstraction and manipulate the graphical entities themselves. This fulfills the vision of "concreteness" championed by Self, where the UI ceases to be a passive "view" of a model and becomes a tangible, manipulable part of the model itself.7
To support this cognitive shift from abstract to concrete reasoning, Morphic's design employs a deliberate metaphor of tangibility. Visual cues, such as drop shadows that appear when an object is "picked up" by the cursor, are not merely aesthetic flourishes.6 They are cognitive affordances designed to reinforce the programming model. By making UI elements feel like physical paper cutouts that can be layered, stacked, and directly manipulated, Morphic provides a consistent mental model that bridges the programming paradigm with the user interaction paradigm.6 This is a functional application of skeuomorphism, where design cues from a familiar domain (the physical world) are used to make a new paradigm (direct object manipulation) feel more intuitive and accessible.10


V.II: Core Architecture: Morphs, Composition, and the World


The fundamental architectural components of Morphic are a direct analog to the object and delegation models of prototype-based languages. The system is built upon a small set of simple, uniform concepts that can be combined to create arbitrary complexity, mirroring the elegance of the underlying Self/Io object model.


The Morph: The Universal Graphical Primitive


The central abstraction in Morphic is the Morph—a graphical object with a visual representation that can be directly manipulated.3 A
Morph is a prototype object containing slots that define its core properties, including:
* bounds: A rectangle defining its position and extent on the screen.12
* color: The object that defines its visual appearance.6
* owner: A reference to its parent morph in the composition hierarchy.3
* submorphs: A list of the child morphs it contains.3
A critical feature of this architecture is its uniformity. Any morph can be a container for other morphs. There is no rigid distinction between "atomic" widgets (like a label) and "container" widgets (like a panel) that exists in many other toolkits.3 A simple
RectangleMorph can contain a TextMorph, and that TextMorph could, in turn, contain other, smaller morphs, ad infinitum.


Compositional Design: A Visual Prototype Chain


Complex user interfaces in Morphic are constructed not through the rigid class hierarchies of traditional OOP, but through the composition of simpler morphs.3 A button, for example, is not created by instantiating a
Button class. Instead, it is assembled by cloning a RectangleMorph prototype to serve as the background and a TextMorph prototype to serve as the label, and then adding the text morph as a submorph of the rectangle morph.6
This parent-child relationship, managed via the owner and submorphs slots, forms a tree structure known as a scene graph.3 Operations such as moving, copying, or deleting a composite morph are applied to the entire unit, propagating recursively down the submorph tree.11 This architectural choice is a direct visual embodiment of the "Favor composition over inheritance" principle. As established in Part I, prototype-based languages make composition the default and only mechanism for code reuse; Morphic applies this same principle to the construction of visual structures.7
This compositional model avoids the use of "invisible structural morphs for aggregation".3 Whereas many UI toolkits rely on invisible panels or containers purely for layout purposes, Morphic's philosophy of concreteness dictates that all morphs should be visible and manipulable. This forces the developer to conceive of layout and structure not as an abstract, invisible scaffold, but as tangible properties of the visible objects themselves. The resulting UIs are more self-describing and easier to debug visually, as the structure
is the appearance.


The World and the Canvas


The Morphic architecture is anchored by two key concepts: the World and the Canvas.
* The World: The World (or WorldMorph) is the top-level container, a special morph that fills the entire screen and serves as the root of the scene graph tree.3 Every visible morph in the system is, directly or indirectly, a submorph of the
World.3 It is the ultimate owner of all graphical objects.
* The Canvas: The Canvas is the abstracted drawing engine that decouples a morph's appearance from the underlying graphics system.6 A morph does not draw directly to the screen. Instead, it implements a
drawOn: method that takes a Canvas object as an argument. Inside this method, it sends high-level drawing commands (e.g., fillRectangle:color:, drawText:at:) to the canvas.6 The
Canvas object is then responsible for translating these abstract commands into the specific calls required by the host graphics system, whether that be X11, HTML5 Canvas, or a PostScript printer.6
This Canvas architecture is a direct application of the message-passing principle to the domain of graphics. A morph does not need to know how to render pixels on a specific device; it only needs to know how to send abstract drawing messages to a Canvas object.3 The
Canvas is the receiver that autonomously determines how to fulfill that request. This mirrors the decoupling described in Part II, where the sender of a message is ignorant of the receiver's implementation, creating a profound architectural uniformity that extends from core logic to graphical rendering.7
The following table contrasts the Morphic architecture with the traditional Model-View-Controller (MVC) pattern to highlight these fundamental differences.
Feature
	Traditional Model-View-Controller (MVC)
	Morphic Architecture
	Core Units
	Model (data/logic), View (UI representation), Controller (input handling)
	Morph (unified object for data, appearance, and behavior)
	Structure
	Separate, loosely coupled objects communicating via notifications.
	Tightly coupled scene graph of composite morphs.
	UI Creation
	Instantiating View classes and configuring them with data from the Model.
	Cloning and composing existing Morph prototypes.
	Data Flow
	Often complex and indirect (e.g., Controller updates Model, Model notifies View).
	Direct. Interaction with a Morph directly modifies its state.
	Liveness
	View is a passive representation; changes require an update cycle.
	Morphs are live objects; changes are immediate and visible.
	Conceptual Model
	Separation of concerns.
	Unification of concerns in a single, tangible object.
	

V.III: Building with Morphs: Prototyping in Action


The practical workflow of UI construction in Morphic directly embodies the principles of cloning and differential inheritance, offering a dynamic and iterative alternative to the rigid design processes of class-based systems.


The Prototypal Workflow: Clone and Modify


The fundamental operation for creating a new UI element in Morphic is to find an existing prototype that is functionally or visually similar to the desired element and clone it.13 For instance, to create a new custom graphical object, a developer might start by evaluating
morph copy to get a generic rectangular morph.3
This new clone is then incrementally specialized. Its existing state is modified by directly changing its slots (e.g., altering its color or bounds), and new behavior is added by defining new method slots (e.g., adding a middleMouseDown: method to handle a specific user input).3 This process is a direct application of the differential inheritance model described in Part III, where a cloned object is initially empty and only stores the
differences between itself and its prototype.7 All shared behavior is delegated to the prototype.
This workflow fundamentally inverts the traditional, top-down design process. In a class-based system, a developer is forced to think abstractly first: one must design a general Button class, anticipating all its potential properties, before an instance can be created.7 The Morphic workflow encourages a bottom-up, concrete approach. A developer starts by creating a single, working exemplar—they might grab a rectangle, add some text, and make it clickable—and only then does this concrete artifact become the prototype for all other buttons.8 This exploratory process lowers the cognitive barrier to creating new components, as it does not require the pre-emptive design of a perfect, complete abstraction.


Dynamic System-Wide Updates via Prototype Propagation


The "live link" between a clone and its prototype, a central concept in prototype-based programming, has profound implications in a graphical environment.7 In a true prototypal system like Self, a modification made to a prototype object at runtime is immediately reflected in the behavior of all objects that delegate to it.
The Self programming environment provides a mechanism known as "copy-down" to manage this propagation within the UI.17 When a change is made to a parent prototype, such as adding a new slot or modifying a method, this change can be propagated to all its descendant clones.17 This allows for dynamic, system-wide UI updates by modifying a single prototype object.17 For example, changing the default font in a
TextMorph prototype could instantly update the font of every piece of text throughout the entire system that inherits from it. This stands in stark contrast to most class-based systems, where changing a class definition typically has no effect on objects that have already been instantiated.
This capability transforms the UI from a static artifact into a malleable system that can be extended and customized at runtime, not just by the original developer, but by its end-users. Because the UI is composed of live, clonable objects and the tools for their manipulation are part of the live environment, a power-user can grab any UI element, inspect it, clone it, and begin modifying its behavior to suit their own needs.2 This blurs the line between user and developer, fulfilling a key aspect of the original vision for personal computing.


V.IV: Event Handling and Interactivity


The Morphic event model is best understood as a specialized form of message passing, consistent with the system's core computational metaphor. Interactivity is not managed by a monolithic, centralized controller but emerges from a decentralized protocol of message exchanges between autonomous graphical objects.


The Morphic Event Model: Inputs as Messages


User inputs, such as mouse clicks, drags, and key presses, are encapsulated as first-class MorphicEvent or ui2Event objects.3 These objects are rich in information, containing not just the event type (e.g.,
leftMouseDown) but also a snapshot of the state of modifier keys (Shift, Control, etc.) at the moment the event occurred.3
These events are dispatched to morphs by sending them messages whose names correspond to the event type. For example, a left mouse click on a morph results in the system sending it the leftMouseDown: message, with the MorphicEvent object passed as the argument.3 A morph handles the event by implementing a method for that message.


Event Dispatching: "Falling Through" the Hierarchy


The primary dispatch mechanism for localized events like mouse clicks is colloquially described as an event "falling down through" the stack of morphs at the cursor's location.3 The event is first offered to the front-most morph in the visual hierarchy. If that morph does not have a method to handle the event, or if its method explicitly returns a special
dropThroughMarker object, the event is then offered to the morph directly behind it in the submorph list. This process continues up the owner chain until a morph handles the event or the root of the hierarchy is reached.3
This model reinforces the autonomy of each object. A morph decides for itself whether it is interested in an event. Furthermore, a composite morph can choose to intercept events before its submorphs have a chance to see them by overriding the allowSubmorphsToGetEvent: message.3 This is critical for complex widgets like menus, which need to manage the overall interaction rather than letting individual menu items handle clicks independently.
A crucial architectural feature enables sophisticated direct manipulation. A morph that accepts a mouseDown event becomes the temporary "mouse focus" and is guaranteed to receive the entire sequence of subsequent mouseMove and mouseUp events, even if the cursor leaves its geometric bounds.6 This provides a clean, reliable mechanism for implementing interactions like dragging, resizing, or drawing, as the initial click establishes a context that persists through the drag operation and is cleanly terminated by the release, all without requiring the developer to manage complex global state.


Drag-and-Drop as a Negotiated Protocol


Drag-and-drop in Morphic is not a system-level operation but a "conversation" between live objects, mediated by a sequence of messages. This negotiation ensures that both parties agree to the interaction. The protocol consists of three main steps:
   1. The Query: When one morph (the "passenger") is dropped onto another (the "target"), the target is first sent the wantsMorph:event: message.3 The target can then inspect the passenger morph and its state to decide if it wishes to accept the drop. For example, a "trash can" morph might only accept morphs that are deletable, while a "folder" morph might only accept "document" morphs.3
   2. The Action: If the target responds affirmatively to the query, the system then sends it the addDroppingMorph:event: message.3 This message instructs the target to perform the actual drop action, such as adding the passenger to its list of submorphs or triggering a business logic operation (e.g., printing a document).3
   3. The Confirmation: Finally, after the target has completed its action, the passenger morph is notified of the successful drop by receiving the justDroppedInto:event: message.3 This allows the passenger to perform any necessary cleanup or state changes.
If the target rejects the drop in the first step, it can also implement the repelsMorph:event: message to define what should happen to the rejected passenger, such as animating it back to its original position.19 This entire protocol treats interactivity as an emergent behavior arising from local, message-based negotiations between autonomous objects.


V.V: Practical Implementation: Simulating Morphic Principles in Io


This final section synthesizes the preceding theory by providing a conceptual blueprint for implementing a Morphic-like system using the Io programming language. As Io lacks a native GUI library, this is a simulation of the object model and interaction patterns, not a guide to building a production-ready GUI.7 The primary goal is to demonstrate how Io's core features—
clone, slots, and Protos—are perfectly suited to represent the Morphic architecture and apply the principles of prototypal programming to UI construction.7


Defining the Base Morph Prototype in Io


The foundation of the system is a single Morph prototype, from which all other graphical objects will ultimately derive. It is created by cloning Io's root Object and then adding slots for shared state and behavior.


Code snippet




// Create the base prototype for all graphical objects.
Morph := Object clone do(
   // SLOTS FOR STATE
   // Use hypothetical geometry and color prototypes for clarity.
   bounds     := Rectangle clone(0, 0, 50, 50)
   color      := Color clone(0.5, 0.5, 0.8) // Default blue
   submorphs  := list()
   owner      := nil

   // SLOTS FOR BEHAVIOR
   // A placeholder method for rendering.
   // In a real system, 'canvas' would be the drawing engine object.
   drawOn := method(canvas,
       // Draw self first (e.g., canvas drawRect(self bounds, self color))
       // Then, recursively draw all children on top.
       self submorphs foreach(submorph, submorph drawOn(canvas))
   )

   // A placeholder for event dispatching.
   handleEvent := method(event,
       // In a real system, this would check for local handlers first.
       // Then, it would iterate submorphs in reverse (front to back)
       // to pass the event down the hierarchy.
       writeln("Handling event: ", event type)
   )

   // Method to manage the compositional hierarchy.
   addMorph := method(aMorph,
       if(aMorph owner, aMorph owner removeMorph(aMorph))
       self submorphs append(aMorph)
       aMorph owner = self
       self
   )

   removeMorph := method(aMorph,
       self submorphs remove(aMorph)
       aMorph owner = nil
   )
)



Walkthrough: Creating a Composite Button Morph


This step-by-step example demonstrates the complete Morphic workflow—composition, cloning, and specialization—to create a functional Button prototype and then instantiate it.


Code snippet




// 1. Create a Button prototype by cloning the base Morph.
Button := Morph clone do(
   // 2. Create and configure the necessary submorphs.
   // These will serve as the default parts for all button clones.
   background := RectangleMorph clone // Assume RectangleMorph exists
   label      := TextMorph clone      // Assume TextMorph exists

   // 3. Assemble the composite structure.
   self addMorph(background)
   self addMorph(label)

   // Set default appearance for the prototype's parts.
   background color = Color clone(0.8, 0.8, 0.8)
   label text := "Default"
   label alignCenter(background bounds) // Hypothetical layout method

   // 4. Add interactive behavior specific to the Button.
   onClick := method(
       "Button clicked!" println
   )

   // Override the base event handler to add button-specific logic.
   handleEvent := method(event,
       if(event type == "mouseDown",
           // Change color to give visual feedback.
           self background color = Color clone(0.6, 0.6, 0.6)
           // In a real system, you would redraw here.
       )
       if(event type == "mouseUp",
           // Restore color.
           self background color = Color clone(0.8, 0.8, 0.8)
           // Execute the button's action.
           self onClick
       )
   )
)

// 5. Instantiate new buttons via cloning and specialize them.
// This is differential inheritance in action.
myLoginButton := Button clone
myLoginButton label text = "Login" // Customize instance state
myLoginButton bounds x = 100
myLoginButton bounds y = 50

myCancelButton := Button clone
myCancelButton label text = "Cancel"
myCancelButton bounds x = 200
myCancelButton bounds y = 50
myCancelButton onClick = method("Cancel action triggered." println)

// Interact with an instance.
myCancelButton handleEvent(Event clone setType("mouseUp")) //> Cancel action triggered.

This simulation reveals the true nature of a "UI framework" in a prototypal system. It is not a large, monolithic library of classes that a developer must learn and subclass. Instead, the framework is simply a small set of well-designed core prototypes that constitute the initial state of the object graph. The process of building an application is not one of using a fixed library, but of dynamically extending the live object graph of the system. An application-specific button like myLoginButton is not fundamentally different from a "framework" button; it is simply another object in a seamless, malleable world.
Furthermore, Io's use of a Protos list for delegation provides a particularly elegant mechanism for implementing common UI patterns.7 For example, the Decorator pattern, often used to add features like borders or scrollbars to a widget, can be implemented dynamically. Instead of wrapping an object, one could simply clone a morph and
prepend a BorderDecorator prototype to its Protos list. The drawOn: message would first be received by the decorator, which would draw the border, and then use the resend message to delegate the call to the original morph's drawing implementation. This demonstrates how a core language feature—list-based delegation—can provide a more direct and dynamic solution to a common UI problem, perfectly aligning the language's architecture with the needs of a flexible, live UI framework.
Works cited
   1. Self (programming language) - Wikipedia, accessed September 20, 2025, https://en.wikipedia.org/wiki/Self_(programming_language)
   2. morphic / etoys is a superior graphical user interface and programming development system, accessed September 20, 2025, https://billkerr2.blogspot.com/2007/09/morphic-etoys-is-superior-graphical.html
   3. 7. Morphic: The Self User Interface Framework — Self Handbook for ..., accessed September 20, 2025, https://handbook.selflanguage.org/2017.1/morphic.html
   4. Directness and Liveness in the Morphic User Interface Construction Environment, accessed September 20, 2025, https://bibliography.selflanguage.org/directness.html
   5. Morphic Interface - C2 wiki, accessed September 20, 2025, https://wiki.c2.com/?MorphicInterface
   6. An Introduction to Morphic: The Squeak User Interface ... - RMOD Files, accessed September 20, 2025, https://rmod-files.lille.inria.fr/FreeBooks/CollectiveNBlueBook/morphic.final.pdf
   7. Io Prototype Programming Training Guide
   8. Creating a Smalltalk App with Morphic Designer | CodingItWrong.com, accessed September 20, 2025, https://codingitwrong.com/2021/04/28/creating-a-smalltalk-app-with-morphic-designer.html
   9. Directness and liveness in the morphic user interface construction environment, accessed September 20, 2025, https://www.semanticscholar.org/paper/Directness-and-liveness-in-the-morphic-user-Maloney-Smith/dfa9b1613418e937d738473e7113f64fcf7556aa
   10. Skeuomorph - Wikipedia, accessed September 20, 2025, https://en.wikipedia.org/wiki/Skeuomorph
   11. Morphs, accessed September 20, 2025, http://kitakitsune.org/self/self_tutorial/Morphic/Morphs/Morphs.html
   12. Morphic Architecture, accessed September 20, 2025, http://perchta.fit.vutbr.cz:8000/vyuka-omp/19.version?id=2
   13. Morphic - Washington, accessed September 20, 2025, https://courses.cs.washington.edu/courses/cse341/common/help/morphic-intro.pdf.gz
   14. Basic Morphic - Washington, accessed September 20, 2025, https://courses.cs.washington.edu/courses/cse341/common/help/morphic-intro.ppt
   15. Morphic | thisContext, accessed September 20, 2025, https://thiscontext.com/tag/morphic/
   16. a faster Morphic with morphic.js - thisContext, accessed September 20, 2025, https://thiscontext.com/2017/06/28/a-faster-morphic-with-morphic-js/
   17. An introduction to Morphic: Self's UI toolkit - sin-ack's writings, accessed September 20, 2025, https://sin-ack.github.io/posts/morphic-intro/
   18. Create Morph from Existing Elements - Graphisoft, accessed September 20, 2025, https://help.graphisoft.com/AC/26/INT/_AC26_Help/040_ElementsVB/040_ElementsVB-234.htm
   19. 13.7: Drag-and-Drop - Engineering LibreTexts, accessed September 20, 2025, https://eng.libretexts.org/Bookshelves/Computer_Science/Programming_Languages/Book:_Pharo_by_Example_5.0_(Ducasse_Zagidulin_Hess_and_Chloupis)/13:_Morphic/13.07:_Drag-and-Drop