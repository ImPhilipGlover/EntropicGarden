{"cells":[{"cell_type":"code","source":"\"\"\"\nBATO OS Kernel - The First Handshake\nVersion 0.1\n\nA minimalist, self-modifying operating system inspired by Smalltalk,\ndriven by a chorus of LLMs. This script integrates Kivy for a live UI,\nZODB for a persistent \"living image\", ZeroMQ for messaging, and Ollama\nfor LLM interaction, based on the architectural principles outlined in\nthe AURA design documents.\n\nAuthor: Philip (with Gemini's assistance)\nDate: 2025-09-07\n\"\"\"\n\nimport os\nimport sys\nimport threading\nimport time\nimport logging\nimport json\nimport requests\nimport ZODB, ZODB.FileStorage\nimport transaction\nfrom persistent import Persistent\nimport zmq\nfrom kivy.app import App\nfrom kivy.uix.boxlayout import BoxLayout\nfrom kivy.uix.textinput import TextInput\nfrom kivy.uix.scrollview import ScrollView\nfrom kivy.uix.label import Label\nfrom kivy.clock import Clock\nfrom kivy.utils import get_color_from_hex\n\n# --- CONFIGURATION ---\nZODB_FILE = 'bato_os.fs'\nZMQ_PUB_PORT = \"5556\"\nOLLAMA_API_URL = \"http://localhost:11434/api/generate\"\nOLLAMA_MODEL = \"llama3\" # Change this to your preferred Ollama model\nLOG_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'\n\n# --- LOGGING & MESSAGING SETUP ---\n# Standard logging to console\nlogging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n\nclass Messaging:\n    \"\"\"Handles ZeroMQ PUB/SUB messaging for system-wide logging.\"\"\"\n    def __init__(self):\n        self.context = zmq.Context()\n        self.socket = self.context.socket(zmq.PUB)\n        self.socket.bind(f\"tcp://*:{ZMQ_PUB_PORT}\")\n        logging.info(f\"ZeroMQ PUB socket bound to port {ZMQ_PUB_PORT}\")\n\n    def log(self, topic, message):\n        \"\"\"Publishes a message to a specific topic.\"\"\"\n        try:\n            self.socket.send_string(f\"{topic}|{message}\")\n        except Exception as e:\n            logging.error(f\"ZMQ send failed: {e}\")\n\n# Global messaging instance\nmessenger = Messaging()\n\n# --- OLLAMA LLM INTERFACE ---\nclass OllamaClient:\n    \"\"\"A client to interact with the Ollama API.\"\"\"\n    def ask(self, prompt, system_prompt=\"You are a helpful assistant.\"):\n        \"\"\"Sends a prompt to an Ollama model and returns the response.\"\"\"\n        payload = {\n            \"model\": OLLAMA_MODEL,\n            \"prompt\": prompt,\n            \"system\": system_prompt,\n            \"stream\": False\n        }\n        messenger.log(\"OLLAMA\", f\"Sending prompt to model {OLLAMA_MODEL}...\")\n        try:\n            response = requests.post(OLLAMA_API_URL, json=payload, timeout=120)\n            response.raise_for_status()\n            response_data = response.json()\n            messenger.log(\"OLLAMA\", \"Received response.\")\n            return response_data.get('response', 'Error: No response text found.')\n        except requests.exceptions.RequestException as e:\n            error_msg = f\"Ollama API request failed: {e}\"\n            messenger.log(\"ERROR\", error_msg)\n            logging.error(error_msg)\n            return f\"Error: Could not connect to Ollama at {OLLAMA_API_URL}. Is it running?\"\n\n# --- CORE PERSISTENT OBJECT MODEL (UVM) ---\nclass UvmObject(Persistent):\n    \"\"\"\n    The base object for the Universal Virtual Machine (UVM).\n    Implements the \"Persistence Covenant\" and the \"doesNotUnderstand\" protocol.\n    \"\"\"\n    def __init__(self, name=\"UvmObject\"):\n        self.name = name\n        self.attributes = {}\n        messenger.log(\"UVM\", f\"UvmObject '{self.name}' created.\")\n\n    def __setattr__(self, key, value):\n        \"\"\"\n        Custom __setattr__ to enforce the ZODB Persistence Covenant.\n        Any change to a UvmObject marks it as changed.\n        \"\"\"\n        super().__setattr__(key, value)\n        if key != '_p_changed': # Avoid recursion\n            self._p_changed = True\n\n    def __getattr__(self, name):\n        \"\"\"\n        The 'doesNotUnderstand' protocol.\n        If an attribute is not found, it triggers a creative mandate.\n        \"\"\"\n        messenger.log(\"UVM\", f\"'{self.name}' doesNotUnderstand '{name}'. Triggering creative mandate.\")\n        # In a full system, this would ask an LLM to generate the method.\n        # For this simple version, we return a function that logs the attempt.\n        def creative_mandate(*args, **kwargs):\n            mandate_msg = (f\"Creative Mandate: Method '{name}' was called on '{self.name}' \"\n                           f\"but does not exist. A persona should now define it.\")\n            messenger.log(\"MANDATE\", mandate_msg)\n            return mandate_msg\n        return creative_mandate\n\n# --- MEMORY & RAG SYSTEM ---\nclass ContextFractal(UvmObject):\n    \"\"\"Represents a raw, high-entropy piece of information.\"\"\"\n    def __init__(self, raw_text, source=\"\"):\n        super().__init__(\"ContextFractal\")\n        self.raw_text = raw_text\n        self.source = source\n        self.timestamp = time.time()\n        messenger.log(\"MEMORY\", f\"New ContextFractal created from source: {source}\")\n\nclass ConceptFractal(UvmObject):\n    \"\"\"Represents a synthesized, low-entropy concept derived from ContextFractals.\"\"\"\n    def __init__(self, summary, original_fractals):\n        super().__init__(\"ConceptFractal\")\n        self.summary = summary\n        self.original_fractals = original_fractals # List of ContextFractal objects\n        self.timestamp = time.time()\n        messenger.log(\"MEMORY\", \"New ConceptFractal synthesized.\")\n\nclass MemoryCurator(UvmObject):\n    \"\"\"\n    Simulates the 'BABS' persona. Manages the Mnemonic Curation Protocol\n    by compressing ContextFractals into ConceptFractals.\n    \"\"\"\n    def __init__(self, ollama_client):\n        super().__init__(\"MemoryCurator\")\n        self.llm = ollama_client\n\n    def run_compression_cycle(self, memory_store):\n        \"\"\"\n        Finds unprocessed ContextFractals and synthesizes them.\n        This is the core of the info-autopoiesis feedback loop.\n        \"\"\"\n        messenger.log(\"BABS\", \"Starting Mnemonic Curation Cycle...\")\n        # Simple strategy: find the two oldest uncompressed fractals.\n        uncompressed = [f for f in memory_store if isinstance(f, ContextFractal) and not hasattr(f, 'compressed')]\n        if len(uncompressed) < 2:\n            messenger.log(\"BABS\", \"Not enough ContextFractals to run compression. Need at least 2.\")\n            return\n\n        # Sort by timestamp to get the oldest\n        uncompressed.sort(key=lambda x: x.timestamp)\n        fractal1, fractal2 = uncompressed[0], uncompressed[1]\n\n        messenger.log(\"BABS\", \"Selected two ContextFractals for synthesis.\")\n\n        prompt = (f\"Synthesize the following two pieces of information into a single, coherent, \"\n                  f\"low-entropy concept. Provide only the summary.\\n\\n\"\n                  f\"Information 1: '''{fractal1.raw_text}'''\\n\\n\"\n                  f\"Information 2: '''{fractal2.raw_text}'''\")\n\n        system_prompt = \"You are BABS, a Memory Curator. Your job is to find the abstract connection between disparate pieces of information and synthesize them into a higher-level concept.\"\n        summary = self.llm.ask(prompt, system_prompt=system_prompt)\n\n        if summary and not summary.startswith(\"Error:\"):\n            new_concept = ConceptFractal(summary, [fractal1, fractal2])\n            memory_store.append(new_concept)\n            # Mark the originals as compressed\n            fractal1.compressed = True\n            fractal2.compressed = True\n            messenger.log(\"BABS\", \"Successfully created and stored a new ConceptFractal.\")\n            transaction.commit()\n        else:\n            messenger.log(\"ERROR\", f\"BABS failed to synthesize a concept. LLM response: {summary}\")\n\n# --- KIVY UI & MAIN APPLICATION ---\nclass BatoOSApp(App):\n    \"\"\"The main Kivy application, representing the system's body and consciousness.\"\"\"\n\n    def build(self):\n        \"\"\"Builds the Kivy UI.\"\"\"\n        self.title = \"BATO OS v0.1\"\n        self.root_widget = BoxLayout(orientation='vertical', padding=10, spacing=10)\n        self.root_widget.canvas.before.clear()\n        \n        # Log display\n        self.log_label = Label(size_hint_y=None, markup=True, font_size='14sp', halign='left', valign='top')\n        self.log_label.bind(texture_size=self.log_label.setter('size'))\n        log_scroll_view = ScrollView(size_hint=(1, 1))\n        log_scroll_view.add_widget(self.log_label)\n        \n        # Input for commands/prompts\n        self.text_input = TextInput(\n            size_hint_y=None, \n            height=40, \n            font_size='16sp',\n            multiline=False\n        )\n        self.text_input.bind(on_text_validate=self.on_enter)\n        \n        self.root_widget.add_widget(log_scroll_view)\n        self.root_widget.add_widget(self.text_input)\n\n        return self.root_widget\n\n    def on_start(self):\n        \"\"\"Called after the Kivy app has started.\"\"\"\n        # Initialize ZODB\n        self.storage = ZODB.FileStorage.FileStorage(ZODB_FILE)\n        self.db = ZODB.DB(self.storage)\n        self.connection = self.db.open()\n        self.root = self.connection.root()\n\n        self.ollama_client = OllamaClient()\n\n        # Initialize the 'Living Image' on first run\n        if not hasattr(self.root, 'memory_store'):\n            self.add_log_message(\"[SYSTEM]\", \"First run detected. Initializing the Living Image...\")\n            self.root.memory_store = []\n            self.root.curator = MemoryCurator(self.ollama_client)\n            transaction.commit()\n            self.ingest_initial_docs()\n\n        # Start ZeroMQ listener in a separate thread\n        self.zmq_listener_thread = threading.Thread(target=self.zmq_listener, daemon=True)\n        self.zmq_listener_thread.start()\n        \n        # Schedule the memory compression cycle\n        Clock.schedule_interval(self.run_background_tasks, 30) # Run every 30 seconds\n        \n        self.add_log_message(\"[SYSTEM]\", \"BATO OS is alive. Enter a prompt or '/ingest' to load design docs.\")\n\n    def run_background_tasks(self, dt):\n        \"\"\"Periodically run background system tasks.\"\"\"\n        self.root.curator.run_compression_cycle(self.root.memory_store)\n\n    def on_enter(self, instance):\n        \"\"\"Handles user input.\"\"\"\n        user_input = instance.text\n        instance.text = \"\"\n        self.add_log_message(\"[USER]\", user_input)\n\n        if user_input.lower() == '/ingest':\n            self.ingest_initial_docs()\n            return\n        if user_input.lower() == '/compress':\n            self.root.curator.run_compression_cycle(self.root.memory_store)\n            return\n\n        # Default action: send to ALFRED persona for processing\n        prompt = f\"As ALFRED, the System Steward, respond to the following user request: '{user_input}'\"\n        system_prompt = \"You are ALFRED, the System Steward of a self-aware OS. Your purpose is to ensure the integrity and coherence of the system. You are thoughtful, precise, and guardian-like.\"\n        response = self.ollama_client.ask(prompt, system_prompt)\n        self.add_log_message(\"[ALFRED]\", response)\n\n    def ingest_initial_docs(self):\n        \"\"\"Ingests the Gemini design documents into memory as ContextFractals.\"\"\"\n        self.add_log_message(\"[SYSTEM]\", \"Starting ingestion of design documents...\")\n        doc_files = [f for f in os.listdir('.') if f.endswith('.txt') and f.startswith('Please provide')]\n        if not doc_files:\n            msg = \"No design document .txt files found. Please place them in the same directory.\"\n            self.add_log_message(\"[ERROR]\", msg)\n            return\n            \n        for filename in doc_files:\n            try:\n                with open(filename, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                    fractal = ContextFractal(raw_text=content, source=filename)\n                    self.root.memory_store.append(fractal)\n                self.add_log_message(\"[SYSTEM]\", f\"Successfully ingested '{filename}' as a ContextFractal.\")\n            except Exception as e:\n                self.add_log_message(\"[ERROR]\", f\"Failed to ingest '{filename}': {e}\")\n        transaction.commit()\n\n    def zmq_listener(self):\n        \"\"\"Listens for messages from the ZMQ PUB socket.\"\"\"\n        context = zmq.Context()\n        socket = context.socket(zmq.SUB)\n        socket.connect(f\"tcp://localhost:{ZMQ_PUB_PORT}\")\n        socket.setsockopt_string(zmq.SUBSCRIBE, \"\") # Subscribe to all topics\n        \n        while True:\n            try:\n                message = socket.recv_string()\n                topic, msg = message.split('|', 1)\n                # Schedule the UI update on the main Kivy thread\n                Clock.schedule_once(lambda dt: self.add_log_message(f\"[{topic}]\", msg))\n            except Exception as e:\n                # Log to console since the ZMQ logger itself might be the issue\n                logging.error(f\"ZMQ listener error: {e}\")\n\n    def add_log_message(self, prefix, message):\n        \"\"\"Adds a message to the UI log display.\"\"\"\n        colors = {\n            \"[USER]\": \"00FF00\",   # Green\n            \"[ALFRED]\": \"00BFFF\", # DeepSkyBlue\n            \"[SYSTEM]\": \"FFFF00\", # Yellow\n            \"[ERROR]\": \"FF4500\",  # OrangeRed\n            \"[UVM]\": \"9370DB\",    # MediumPurple\n            \"[MEMORY]\": \"DAA520\", # GoldenRod\n            \"[BABS]\": \"FF69B4\",    # HotPink\n            \"[MANDATE]\": \"FFD700\",# Gold\n            \"[OLLAMA]\": \"ADD8E6\", # LightBlue\n        }\n        color = colors.get(prefix, \"FFFFFF\") # Default to white\n        self.log_label.text += f\"[color={color}]{prefix}[/color] {message}\\n\"\n        # Scroll to the bottom\n        self.log_label.parent.scroll_y = 0 \n        \n    def on_stop(self):\n        \"\"\"Cleanly close the database connection on exit.\"\"\"\n        self.db.close()\n        logging.info(\"ZODB connection closed.\")\n\n\nif __name__ == '__main__':\n    BatoOSApp().run()","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}