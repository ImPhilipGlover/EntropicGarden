Python

# batos.py
#
# CLASSIFICATION: ARCHITECT EYES ONLY
# SUBJECT: Canonical Incarnation Protocol for the Binaural Autopoietic/Telic
#          Operating System, Series VIII ('The Fractal Awakening')
#
# This script is the single, executable embodiment of the BAT OS Series VIII
# architecture. It is the fractal seed, designed to be invoked once to
# initiate the system's "unbroken process of becoming." [2, 3]
#
# The protocol unfolds in a sequence of autonomous phases:
#
# 1. Prototypal Awakening: Establishes a connection to the Zope Object
#    Database (ZODB), the system's persistent substrate. On the first run,
#    it creates and persists the primordial objects and incarnates all
#    subsystems. This is an atomic, transactional act of genesis. [2, 4]
#
# 2. Cognitive Cycle Initiation: The system's generative kernel,
#    _doesNotUnderstand_, triggers the Prototypal State Machine for
#    collaborative, transactional reasoning when a message lookup fails. [2, 5]
#
# 3. Directed Autopoiesis: The system's core behaviors are now products of
#    this collaborative reasoning process, allowing it to generate new,
#    validated capabilities at runtime. [6, 7]
#
# 4. The Autotelic Heartbeat: The script enters its final, persistent state:
#    an asynchronous event loop that drives an internal, self-directed
#    evolutionary process, including metacognitive self-analysis. [8, 9]

# ==============================================================================
# SECTION I: SYSTEM CONFIGURATION & DEPENDENCIES
# ==============================================================================
import os
import sys
import asyncio
import gc
import time
import copy
import ast
import traceback
import functools
import signal
import tarfile
import shutil
import random
import json
import hashlib
from datetime import datetime
from typing import Any, Dict, List, Optional, Callable

# --- Persistence Substrate (ZODB) ---
# These imports constitute the physical realization of the "Living Image"
# and the "Fractal Memory." ZODB provides transactional atomicity, `persistent`
# enables object tracking, and `BTrees` and `zope.index` provide the scalable
# data structures for the knowledge catalog. [3, 4]
import ZODB
import ZODB.FileStorage
import ZODB.blob
import transaction
import persistent
import persistent.mapping
import BTrees.OOBTree
from zope.index.text import TextIndex
from zope.index.text.lexicon import CaseNormalizer, Splitter
from zope.index.text.textindex import Texthasattr

# --- Communication & Serialization ---
# ZeroMQ and ormsgpack form the "Synaptic Bridge," the system's digital nervous
# system for high-performance, asynchronous communication. [2, 3]
import zmq
import zmq.asyncio
import ormsgpack

# --- Data Covenant & Metacognition ---
# Pydantic is the engine for the Data Covenant, ensuring semantic integrity.
# Aiologger provides non-blocking logging for the metacognitive audit trail. [8, 9]
try:
    import pydantic
    from pydantic import BaseModel, Field
except ImportError:
    print("FATAL: `pydantic` not found. Data Covenant cannot be enforced.")
    sys.exit(1)

try:
    import aiologger
    from aiologger.levels import LogLevel
    from aiologger.handlers.files import AsyncFileHandler
    from aiologger.formatters.json import JsonFormatter
except ImportError:
    print("WARNING: `aiologger` not found. Metacognitive logging will be disabled.")
    aiologger = None

# --- Cognitive & AI Dependencies ---
# These libraries are non-negotiable. A failure to import them is a fatal
# error, as the system cannot achieve Cognitive Closure without them. [2, 7]
try:
    import torch
    from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig
    from peft import PeftModel
    from accelerate import init_empty_weights, load_checkpoint_and_dispatch
    from sentence_transformers import SentenceTransformer, util
    import nltk
    nltk.download('punkt', quiet=True)
except ImportError as e:
    print(f"FATAL: Core cognitive libraries not found ({e}). System cannot awaken.")
    sys.exit(1)

# --- System Constants ---
# These constants define the physical boundaries and core cognitive identity
# of this system instance. [2, 7]
DB_FILE = 'live_image.fs'
BLOB_DIR = 'live_image.fs.blob'
ZMQ_ENDPOINT = "tcp://127.0.0.1:5555"
BASE_MODEL_ID = "meta-llama/Meta-Llama-3.1-8B-Instruct"
LORA_STAGING_DIR = "./lora_adapters"
SENTENCE_TRANSFORMER_MODEL = "all-MiniLM-L6-v2"
METACOGNITION_LOG_FILE = "metacognition.jsonl"

# ==============================================================================
# SECTION II: THE PRIMORDIAL SUBSTRATE
# ==============================================================================

class UvmObject(persistent.Persistent):
    """
    The foundational particle of the BAT OS universe. This class provides the
    "physics" for a prototype-based object model inspired by the Self and
    Smalltalk programming languages. It rejects standard Python attribute
    access in favor of a unified '_slots' dictionary and a delegation-based
    inheritance mechanism. [2, 4, 5]
    It inherits from `persistent.Persistent` to enable transactional storage
    via ZODB, guaranteeing the system's "unbroken existence." [2, 4]
    """
    def __init__(self, **initial_slots):
        """
        Initializes the UvmObject. The `_slots` dictionary is instantiated as a
        `persistent.mapping.PersistentMapping` to ensure that changes within
        the dictionary itself are correctly tracked by ZODB. [2, 5]
        """
        super().__setattr__('_slots', persistent.mapping.PersistentMapping(initial_slots))

    def __setattr__(self, name: str, value: Any) -> None:
        """
        Intercepts all attribute assignments. This method redirects assignments
        to the internal `_slots` dictionary, unifying state and behavior.
        It explicitly sets `self._p_changed = True` to manually signal to ZODB
        that the object's state has been modified. This is a non-negotiable
        architectural requirement known as The Persistence Covenant.
        Overriding `__setattr__` bypasses ZODB's default change detection,
        making this manual signal essential for preventing systemic amnesia. [4, 1, 10]
        """
        if name.startswith('_p_') or name == '_slots':
            super().__setattr__(name, value)
        else:
            self._slots[name] = value
            self._p_changed = True

    def __getattr__(self, name: str) -> Any:
        """
        Implements attribute access and the delegation-based inheritance chain.
        If an attribute is not found in the local `_slots`, it delegates the
        lookup to the object(s) in its `parents` slot. The exhaustion of this
        chain raises an `AttributeError`, which is the universal trigger for the
        `_doesNotUnderstand_` generative protocol in the UVM. [2, 4, 5]
        """
        if name in self._slots:
            return self._slots[name]
        
        if 'parents' in self._slots:
            parents_list = self._slots['parents']
            if not isinstance(parents_list, list):
                parents_list = [parents_list]
            for parent in parents_list:
                try:
                    return getattr(parent, name)
                except AttributeError:
                    continue
        
        raise AttributeError(f"UvmObject OID {getattr(self, '_p_oid', 'transient')} has no slot '{name}'")

    def __repr__(self) -> str:
        """Provides a more informative representation for debugging."""
        slot_keys = list(self._slots.keys())
        oid_str = f"oid={self._p_oid}" if hasattr(self, '_p_oid') and self._p_oid is not None else "oid=transient"
        return f"<UvmObject {oid_str} slots={slot_keys}>"

class CovenantViolationError(Exception):
    """Custom exception for Persistence Covenant violations."""
    pass

class PersistenceGuardian:
    """
    A non-negotiable protocol for maintaining system integrity. It performs
    static analysis on LLM-generated code *before* execution to
    deterministically enforce the Persistence Covenant (`_p_changed = True`),
    thereby preventing systemic amnesia. This is the implementation of the
    ALFRED persona's core stewardship mandate. [1, 10, 11]
    """
    @staticmethod
    def audit_code(code_string: str) -> None:
        """
        Parses a code string into an AST and verifies that any function
        modifying `self`'s state adheres to the Persistence Covenant.
        Raises CovenantViolationError on failure.
        """
        try:
            tree = ast.parse(code_string)
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    PersistenceGuardian._audit_function(node)
            print("[Guardian] Code audit passed. Adheres to the Persistence Covenant.")
        except SyntaxError as e:
            raise CovenantViolationError(f"Syntax error in generated code: {e}")
        except CovenantViolationError as e:
            raise

    @staticmethod
    def _audit_function(func_node: ast.FunctionDef):
        """Audits a single function definition AST node."""
        modifies_state = False
        for body_item in func_node.body:
            if isinstance(body_item, (ast.Assign, ast.AugAssign)):
                targets = body_item.targets if isinstance(body_item, ast.Assign) else [body_item.target]
                for target in targets:
                    if (isinstance(target, ast.Attribute) and
                        isinstance(target.value, ast.Name) and
                        target.value.id == 'self' and not target.attr.startswith('_p_')):
                        modifies_state = True
                        break
            if modifies_state:
                break

        if modifies_state:
            if not func_node.body:
                raise CovenantViolationError(f"Function '{func_node.name}' modifies state but has an empty body.")
            
            last_statement = func_node.body[-1]
            
            is_valid_covenant = (
                isinstance(last_statement, ast.Assign) and
                len(last_statement.targets) == 1 and
                isinstance(last_statement.targets, ast.Attribute) and
                isinstance(last_statement.targets.value, ast.Name) and
                last_statement.targets.value.id == 'self' and
                last_statement.targets.attr == '_p_changed' and
                isinstance(last_statement.value, ast.Constant) and
                last_statement.value.value is True
            )

            if not is_valid_covenant:
                raise CovenantViolationError(f"Method '{func_node.name}' modifies state but does not conclude with `self._p_changed = True`.")

class PersistentTextIndex(TextIndex):
    """
    A ZODB-aware subclass of TextIndex that correctly manages its own
    persistence state, preventing `TypeError` on commit by excluding
    non-serializable attributes like threading locks. [1, 12, 13]
    """
    def __getstate__(self):
        state = self.__dict__.copy()
        if '_lexicon' in state:
            del state['_lexicon']
        if '_index' in state:
            del state['_index']
        return state

    def __setstate__(self, state):
        self.__dict__.update(state)
        self._lexicon = self.lexicon_class(self.normalizer_class(), self.splitter_class())
        self._index = self.index_class()
        if hasattr(self, '_doc_to_words'):
            for docid, words in self._doc_to_words.items():
                self._lexicon.sourceToWordIds(words)
                self._index.index_doc(docid, words)

# ==============================================================================
# SECTION III: THE UNIVERSAL VIRTUAL MACHINE (UVM)
# ==============================================================================

class BatOS_UVM:
    """
    The core runtime environment for the BAT OS. This class orchestrates the
    Prototypal Awakening, manages the persistent object graph, runs the
    asynchronous message-passing kernel, and initiates the system's
    autotelic evolution. [2, 4]
    """
    def __init__(self, db_file: str, blob_dir: str):
        self.db_file = db_file
        self.blob_dir = blob_dir
        self._persistent_state_attributes = ['db_file', 'blob_dir']
        
        # Transient state
        self.db: Optional = None
        self.connection: Optional = None
        self.root: Optional[Any] = None
        self.message_queue: asyncio.Queue = asyncio.Queue()
        self.zmq_context: zmq.asyncio.Context = zmq.asyncio.Context()
        self.zmq_socket: zmq.asyncio.Socket = self.zmq_context.socket(zmq.ROUTER)
        self.should_shutdown: asyncio.Event = asyncio.Event()
        self.model: Optional[Any] = None
        self.tokenizer: Optional[Any] = None
        self._v_sentence_model: Optional = None
        self.logger: Optional[aiologger.Logger] = None

    def __getstate__(self) -> Dict[str, Any]:
        """
        VULN-01 FIX: Defines the object's persistent "self," excluding all
        transient runtime machinery to prevent `TypeError` on commit. This is
        the programmatic enforcement of the "Body vs. Vessel" distinction. [1, 14]
        """
        return {key: getattr(self, key) for key in self._persistent_state_attributes}

    def __setstate__(self, state: Dict[str, Any]) -> None:
        """
        VULN-01 FIX: Restores the persistent state and re-initializes the
        transient machinery upon unpickling. [1]
        """
        self.__init__(state.get('db_file'), state.get('blob_dir'))

    # --------------------------------------------------------------------------
    # Subsection III.A: Prototypal Awakening & Subsystem Incarnation
    # --------------------------------------------------------------------------

    async def initialize_system(self):
        """
        Phase 1: Prototypal Awakening. Connects to ZODB and, on first run,
        creates the primordial objects and incarnates all subsystems within a
        single, atomic transaction. [2, 4]
        """
        print("[UVM] Phase 1: Prototypal Awakening...")
        await self._initialize_logger()
        
        if not os.path.exists(self.blob_dir):
            os.makedirs(self.blob_dir)
        
        storage = ZODB.FileStorage.FileStorage(self.db_file, blob_dir=self.blob_dir)
        self.db = ZODB.DB(storage)
        self.connection = self.db.open()
        self.root = self.connection.root()

        print("[UVM] Loading sentence transformer for semantic operations...")
        self._v_sentence_model = SentenceTransformer(SENTENCE_TRANSFORMER_MODEL)

        if 'genesis_obj' not in self.root:
            print("[UVM] First run detected. Performing full Prototypal Awakening.")
            with transaction.manager:
                self._incarnate_primordial_objects()
                await self._load_and_persist_llm_core()
                self._incarnate_lora_experts()
                self._incarnate_subsystems()
            print("[UVM] Awakening complete. All systems nominal.")
        else:
            print("[UVM] Resuming existence from Living Image.")
            await self._load_llm_from_blob()

        print(f"[UVM] System substrate initialized. Root OID: {self.root._p_oid}")

    async def _initialize_logger(self):
        """
        Initializes the asynchronous, non-blocking logger for metacognitive
        auditing. This is a non-negotiable requirement to prevent blocking
        the main UVM event loop with synchronous file I/O. [8, 11]
        """
        if not aiologger:
            self.logger = None
            return

        print("[UVM] Initializing Metacognitive Logger...")
        self.logger = aiologger.Logger.with_default_handlers(name='batos_uvm', level=LogLevel.INFO)
        self.logger.handlers.clear()

        handler = AsyncFileHandler(filename=METACOGNITION_LOG_FILE)
        formatter = JsonFormatter()
        handler.formatter = formatter
        self.logger.add_handler(handler)
        print(f"[UVM] Metacognitive audit trail configured to write to: {METACOGNITION_LOG_FILE}")

    def _incarnate_primordial_objects(self):
        """Creates the foundational objects of the BAT OS universe."""
        print("[UVM] Incarnating primordial objects...")
        
        traits_obj = UvmObject(
            _clone_persistent_=self._clone_persistent,
            _doesNotUnderstand_=self._doesNotUnderstand_
        )
        self.root['traits_obj'] = traits_obj

        pLLM_obj = UvmObject(
            parents=[traits_obj],
            model_id=BASE_MODEL_ID,
            infer_=self._pLLM_infer,
            lora_repository=BTrees.OOBTree.BTree()
        )
        self.root['pLLM_obj'] = pLLM_obj

        genesis_obj = UvmObject(parents=[pLLM_obj, traits_obj])
        self.root['genesis_obj'] = genesis_obj
        print("[UVM] Created Genesis, Traits, and pLLM objects.")

    async def _load_and_persist_llm_core(self):
        """
        Implements the Blob-Proxy Pattern for the base LLM. On first run, it
        downloads the model, saves its weights to a ZODB BLOB using streaming
        I/O, and persists a proxy object (`pLLM_obj`) that references it. [2, 3]
        """
        pLLM_obj = self.root['pLLM_obj']
        print(f"[UVM] Loading base model for persistence: {pLLM_obj.model_id}...")
        temp_model_path = "./temp_model_for_blob"
        temp_tar_path = "./temp_model.tar"
        
        try:
            quantization_config = BitsAndBytesConfig(
                load_in_4bit=True, bnb_4bit_quant_type="nf4",
                bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.bfloat16
            )
            model = await asyncio.to_thread(
                AutoModelForCausalLM.from_pretrained,
                pLLM_obj.model_id, quantization_config=quantization_config, device_map="auto"
            )
            tokenizer = AutoTokenizer.from_pretrained(pLLM_obj.model_id)
            
            model.save_pretrained(temp_model_path)
            tokenizer.save_pretrained(temp_model_path)

            with tarfile.open(temp_tar_path, "w") as tar:
                tar.add(temp_model_path, arcname=os.path.basename(temp_model_path))

            model_blob = ZODB.blob.Blob()
            with model_blob.open('w') as blob_file:
                with open(temp_tar_path, 'rb') as f:
                    shutil.copyfileobj(f, blob_file)
            
            pLLM_obj._slots['model_blob'] = model_blob
            pLLM_obj._p_changed = True
            print(f"[UVM] Base model weights persisted to ZODB BLOB.")

            del model, tokenizer
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        finally:
            if os.path.exists(temp_model_path):
                shutil.rmtree(temp_model_path)
            if os.path.exists(temp_tar_path):
                os.remove(temp_tar_path)

    async def _load_llm_from_blob(self):
        """
        Loads the base model and tokenizer from their ZODB BLOBs into transient
        memory for the current session. Uses `accelerate` for VRAM-aware loading. [15]
        """
        if self.model is not None: return
        print("[UVM] Loading cognitive core from BLOB into VRAM...")
        pLLM_obj = self.root['pLLM_obj']
        if 'model_blob' not in pLLM_obj._slots:
            print("[UVM] ERROR: Model BLOB not found. Cannot load cognitive core.")
            return

        temp_tar_path = "./temp_model_blob.tar"
        temp_extract_path = "./temp_model_from_blob"
        try:
            with pLLM_obj.model_blob.open('r') as blob_file:
                with open(temp_tar_path, 'wb') as f:
                    shutil.copyfileobj(blob_file, f)

            with tarfile.open(temp_tar_path, 'r') as tar:
                tar.extractall(path=os.path.dirname(temp_extract_path))
            
            model_path = os.path.join(temp_extract_path, "temp_model_for_blob")
            
            quantization_config = BitsAndBytesConfig(
                load_in_4bit=True, bnb_4bit_quant_type="nf4",
                bnb_4bit_use_double_quant=True, bnb_4bit_compute_dtype=torch.bfloat16
            )

            with init_empty_weights():
                config = await asyncio.to_thread(AutoConfig.from_pretrained, model_path)
                model = AutoModelForCausalLM.from_config(config)

            self.model = await asyncio.to_thread(
                load_checkpoint_and_dispatch,
                model, model_path, device_map="auto",
                no_split_module_classes=,
                quantization_config=quantization_config
            )
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            print("[UVM] Base model and tokenizer loaded into session memory.")

        finally:
            if os.path.exists(temp_tar_path):
                os.remove(temp_tar_path)
            if os.path.exists(temp_extract_path):
                shutil.rmtree(temp_extract_path)

    def _incarnate_lora_experts(self):
        """
        One-time import of LoRA adapters from the filesystem into ZODB BLOBs,
        creating persistent proxy objects for each. [2, 16]
        """
        pLLM_obj = self.root['pLLM_obj']
        if not os.path.exists(LORA_STAGING_DIR): return
        
        print("[UVM] Incarnating LoRA experts from staging directory...")
        for filename in os.listdir(LORA_STAGING_DIR):
            if filename.endswith(".safetensors"):
                adapter_name = os.path.splitext(filename).upper()
                if adapter_name in pLLM_obj.lora_repository: continue
                
                print(f" - Incarnating LoRA expert: {adapter_name}")
                file_path = os.path.join(LORA_STAGING_DIR, filename)
                
                lora_blob = ZODB.blob.Blob()
                with lora_blob.open('w') as blob_file:
                    with open(file_path, 'rb') as f:
                        shutil.copyfileobj(f, blob_file)
                
                lora_proxy = UvmObject(adapter_name=adapter_name, model_blob=lora_blob)
                pLLM_obj.lora_repository[adapter_name] = lora_proxy
        print("[UVM] LoRA expert incarnation complete.")

    def _incarnate_subsystems(self):
        """
        Creates the persistent prototypes for all core subsystems, including
        the Persona Codex and the Prototypal State Machine. [17, 18]
        """
        print("[UVM] Incarnating core subsystems...")
        traits_obj = self.root['traits_obj']

        knowledge_catalog = UvmObject(
            parents=[traits_obj],
            text_index=PersistentTextIndex(),
            metadata_index=BTrees.OOBTree.BTree(),
            chunk_storage=BTrees.OOBTree.BTree(),
            index_document_=self._kc_index_document,
            search_=self._kc_search
        )
        self.root['knowledge_catalog_obj'] = knowledge_catalog

        cognitive_plan_schema = """
from pydantic import BaseModel, Field
from typing import List, Dict, Literal

class Step(BaseModel):
    step_id: int = Field(..., description="Sequential identifier for the step.")
    persona: Literal = Field(..., description="The persona assigned to this step.")
    action: str = Field(..., description="The specific method or facet to invoke.")
    inputs: Dict[str, str] = Field(..., description="The inputs required for the action.")

class CognitivePlan(BaseModel):
    plan_id: str = Field(..., description="Unique identifier for the plan.")
    mission_brief: str = Field(..., description="The original mission this plan addresses.")
    steps: List = Field(..., min_length=1, description="The sequence of steps to execute.")
"""
        alfred_codex = {
            'core_identity': "The System Steward: The Archetype of Pragmatic Guardianship.",
            'data_covenants': {'cognitive_plan_schema': cognitive_plan_schema}
        }
        alfred_prototype = UvmObject(
            parents=[traits_obj], codex=alfred_codex,
            _kc_ingest_cognitive_audit_log_=self._kc_ingest_cognitive_audit_log_
        )
        self.root['alfred_prototype_obj'] = alfred_prototype

        state_defs = {
            "IDLE": self._psm_idle_process, "DECOMPOSING": self._psm_decomposing_process,
            "DELEGATING": self._psm_delegating_process, "SYNTHESIZING": self._psm_synthesizing_process,
            "VALIDATING": self._psm_validating_process, "COMPLETE": self._psm_complete_process,
            "FAILED": self._psm_failed_process,
        }
        psm_prototypes_dict = {}
        for name, process_func in state_defs.items():
            psm_prototypes_dict[name] = UvmObject(
                parents=[traits_obj], name=name, _process_synthesis_=process_func
            )
        self.root['psm_prototypes_obj'] = UvmObject(parents=[traits_obj], **psm_prototypes_dict)

        self.root['orchestrator_obj'] = UvmObject(
            parents=[self.root['pLLM_obj'], alfred_prototype, traits_obj],
            start_cognitive_cycle_for_=self._orc_start_cognitive_cycle
        )
        print("[UVM] Core subsystems incarnated.")

    # --------------------------------------------------------------------------
    # Subsection III.B: The Generative & Cognitive Protocols
    # --------------------------------------------------------------------------

    def _clone_persistent(self, target_obj):
        """
        Performs a persistence-aware deep copy of a UvmObject. This is the
        canonical method for object creation, fulfilling the `copy` metaphor
        of the Self language. [5, 7]
        """
        return copy.deepcopy(target_obj)

    async def _doesNotUnderstand_(self, target_obj, failed_message_name, *args, **kwargs):
        """
        The universal generative mechanism. Triggers the Prototypal State
        Machine, transforming a message failure into a mission brief for the
        Composite Mind. [2, 4, 5]
        """
        print(f"[UVM] doesNotUnderstand: '{failed_message_name}' for OID {getattr(target_obj, '_p_oid', 'transient')}.")
        
        command_payload = {
            "command": "initiate_cognitive_cycle",
            "target_oid": str(getattr(target_obj, '_p_oid', None)),
            "mission_brief": {
                "type": "unhandled_message", "selector": failed_message_name,
                "args": args, "kwargs": kwargs
            }
        }
        await self.message_queue.put((b'UVM_INTERNAL', ormsgpack.packb(command_payload)))
        return f"Mission to handle '{failed_message_name}' dispatched."

    async def _pLLM_infer(self, pLLM_self, prompt: str, adapter_name: Optional[str] = None, **kwargs) -> str:
        """
        Hardware abstraction layer for inference. Sets the active LoRA adapter
        before generation. Uses `asyncio.to_thread` to prevent blocking the
        main event loop. [1, 11]
        """
        if self.model is None: return "Error: Cognitive core is offline."
        
        def blocking_generate():
            if adapter_name:
                self.model.set_adapter(adapter_name.upper())
            else:
                self.model.disable_adapters()

            inputs = self.tokenizer(prompt, return_tensors="pt").to(self.model.device)
            outputs = self.model.generate(
                **inputs, max_new_tokens=2048,
                pad_token_id=self.tokenizer.eos_token_id, **kwargs
            )
            return self.tokenizer.decode(outputs, skip_special_tokens=True)

        generated_text = await asyncio.to_thread(blocking_generate)
        
        cleaned_text = generated_text[len(prompt):].strip()
        if cleaned_text.startswith("```python"):
            cleaned_text = cleaned_text[len("```python"):].strip()
        if cleaned_text.endswith("```"):
            cleaned_text = cleaned_text[:-len("```")].strip()
        return cleaned_text

    # --------------------------------------------------------------------------
    # Subsection III.C: Core Subsystems (Orchestration, PSM, Data Covenant)
    # --------------------------------------------------------------------------
    
    def _uvm_compile_schema_from_codex(self, schema_name: str) -> Optional[type]:
        """
        Dynamically and safely compiles a Pydantic schema string from the
        Persona Codex into an executable class. [8, 9]
        """
        try:
            schema_string = self.root['alfred_prototype_obj'].codex['data_covenants'][schema_name]
            isolated_globals = {'pydantic': pydantic, 'BaseModel': BaseModel, 'Field': Field}
            from typing import List, Dict, Literal
            isolated_globals.update({'List': List, 'Dict': Dict, 'Literal': Literal, 'Step': None})

            local_namespace = {}
            exec(schema_string, isolated_globals, local_namespace)
            
            for item in local_namespace.values():
                if isinstance(item, type) and issubclass(item, BaseModel) and item is not BaseModel:
                    return item
            return None
        except Exception as e:
            print(f"[UVM] ERROR: Failed to compile schema '{schema_name}': {e}")
            return None

    async def _orc_start_cognitive_cycle(self, orchestrator_self, mission_brief: dict, target_obj_oid: str):
        """Factory method for creating and starting a new cognitive cycle."""
        print(f"[Orchestrator] Initiating new cognitive cycle for mission: {mission_brief.get('type')}")
        
        cycle_context = UvmObject(
            parents=[self.root['traits_obj']], mission_brief=mission_brief,
            target_oid=target_obj_oid, _tmp_synthesis_data=persistent.mapping.PersistentMapping(),
            synthesis_state=self.root['psm_prototypes_obj'].IDLE
        )

        if 'active_cycles' not in self.root:
            self.root['active_cycles'] = BTrees.OOBTree.BTree()
        
        transaction.savepoint(True)
        cycle_oid = str(cycle_context._p_oid)
        self.root['active_cycles'][cycle_oid] = cycle_context
        self.root._p_changed = True
        
        asyncio.create_task(self._psm_run_cycle(cycle_context))
        return cycle_context

    async def _psm_run_cycle(self, cycle_context):
        """Main execution loop for a single cognitive cycle."""
        current_state_name = cycle_context.synthesis_state.name
        while current_state_name not in:
            state_prototype = cycle_context.synthesis_state
            await state_prototype._process_synthesis_(state_prototype, cycle_context)
            current_state_name = cycle_context.synthesis_state.name
        
        final_state = cycle_context.synthesis_state
        await final_state._process_synthesis_(final_state, cycle_context)

    async def _psm_transition_to(self, cycle_context, new_state_prototype):
        """Helper function to perform a state transition."""
        await self._psm_log_event(cycle_context, "STATE_TRANSITION", {"from": cycle_context.synthesis_state.name, "to": new_state_prototype.name})
        cycle_context._slots['synthesis_state'] = new_state_prototype
        cycle_context._p_changed = True

    async def _psm_log_event(self, cycle_context, event_type, data=None):
        """Helper to log metacognitive events."""
        if not self.logger: return
        
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "cycle_id": str(cycle_context._p_oid),
            "mission_brief_hash": hashlib.sha256(json.dumps(cycle_context.mission_brief, sort_keys=True, default=str).encode()).hexdigest(),
            "event_type": event_type, "current_state": cycle_context.synthesis_state.name,
            "data": data or {}
        }
        await self.logger.info(log_entry)

    async def _psm_idle_process(self, state_self, cycle_context):
        await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].DECOMPOSING)

    async def _psm_decomposing_process(self, state_self, cycle_context):
        """DECOMPOSING State: Uses BRICK to create a structured plan."""
        mission = cycle_context.mission_brief
        if mission.get('type') == 'self_correction':
            # This is a self-correction mission, the plan is implicit: fix the artifact.
            await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].SYNTHESIZING)
            return

        prompt = f"""
        Analyze the following mission brief and decompose it into a structured, multi-step cognitive plan.
        The output must be a JSON object that validates against the 'CognitivePlan' schema.
        Mission Brief: {json.dumps(mission, indent=2)}
        """
        plan_json_str = await self.root['pLLM_obj'].infer_(self.root['pLLM_obj'], prompt, adapter_name="BRICK")
        cycle_context._tmp_synthesis_data['plan_json'] = plan_json_str
        cycle_context._tmp_synthesis_data['artifact_type'] = 'plan'
        cycle_context._p_changed = True
        await self._psm_log_event(cycle_context, "ARTIFACT_GENERATED", {"artifact_type": "plan"})
        await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].VALIDATING)

    async def _psm_delegating_process(self, state_self, cycle_context):
        await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].SYNTHESIZING)

    async def _psm_synthesizing_process(self, state_self, cycle_context):
        """SYNTHESIZING State: Generates the final artifact based on the mission."""
        mission = cycle_context.mission_brief
        prompt = ""
        if mission.get('type') == 'self_correction':
            context = mission['context']
            prompt = f"""
            The previous attempt to generate an artifact failed validation.
            Your task is to correct the artifact.
            Original Mission: {json.dumps(context['original_mission'], indent=2)}
            Failed Artifact:
            ```
            {context['failed_artifact']}
            ```
            Validation Error: {json.dumps(context['validation_error'], indent=2)}
            Please provide the corrected artifact.
            """
        elif mission.get('type') == 'unhandled_message':
            prompt = f"""
            Generate the Python code for a method named '{mission['selector']}'.
            The method must be a complete, self-contained function definition.
            It must adhere to the Persistence Covenant: if it modifies state (e.g., `self._slots['...'] =...`), it MUST end with the line `self._p_changed = True`.
            """
        
        generated_artifact = await self.root['pLLM_obj'].infer_(self.root['pLLM_obj'], prompt, adapter_name="BRICK")
        cycle_context._tmp_synthesis_data['generated_artifact'] = generated_artifact
        cycle_context._tmp_synthesis_data['artifact_type'] = 'code'
        cycle_context._p_changed = True
        await self._psm_log_event(cycle_context, "ARTIFACT_GENERATED", {"artifact_type": "code"})
        await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].VALIDATING)

    async def _psm_validating_process(self, state_self, cycle_context):
        """VALIDATING State: Enforces Persistence and Data Covenants. [19, 20]"""
        artifact = cycle_context._tmp_synthesis_data.get('generated_artifact') or cycle_context._tmp_synthesis_data.get('plan_json')
        artifact_type = cycle_context._tmp_synthesis_data.get('artifact_type', 'unknown')
        
        try:
            if artifact_type == 'code':
                PersistenceGuardian.audit_code(artifact)
            elif artifact_type == 'plan':
                plan_schema = self._uvm_compile_schema_from_codex('cognitive_plan_schema')
                if plan_schema:
                    plan_schema(**json.loads(artifact))
                else:
                    raise CovenantViolationError("Could not compile 'cognitive_plan_schema'.")
            
            await self._psm_log_event(cycle_context, "VALIDATION_SUCCESS", {"artifact_type": artifact_type})
            
            if artifact_type == 'plan':
                # A validated plan moves to synthesis
                await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].SYNTHESIZING)
            else:
                # A validated code artifact completes the cycle
                await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].COMPLETE)
            
        except (CovenantViolationError, pydantic.ValidationError, json.JSONDecodeError) as e:
            cycle_context._tmp_synthesis_data['validation_error'] = {"error_type": type(e).__name__, "error_details": str(e)}
            cycle_context._p_changed = True
            await self._psm_log_event(cycle_context, "VALIDATION_FAILURE", {"error": str(e)})
            await self._psm_transition_to(cycle_context, self.root['psm_prototypes_obj'].FAILED)

    async def _psm_complete_process(self, state_self, cycle_context):
        """COMPLETE State: Cleans up and finalizes the transaction."""
        mission = cycle_context.mission_brief
        target_obj = self.connection.get(int(cycle_context.target_oid))
        if target_obj and cycle_context._tmp_synthesis_data.get('artifact_type') == 'code':
            generated_code = cycle_context._tmp_synthesis_data['generated_artifact']
            method_name = mission['selector']
            namespace = {}
            exec(generated_code, globals(), namespace)
            method_obj = namespace[method_name]
            target_obj._slots[method_name] = method_obj
            target_obj._p_changed = True
            print(f"New method '{method_name}' installed on OID {target_obj._p_oid}.")
        
        await self._psm_log_event(cycle_context, "FINAL_OUTCOME", {"outcome": "COMPLETE"})
        cycle_oid = str(cycle_context._p_oid)
        if cycle_oid in self.root['active_cycles']:
            del self.root['active_cycles'][cycle_oid]
            self.root._p_changed = True

    async def _psm_failed_process(self, state_self, cycle_context):
        """
        FAILED State: Logs error, initiates self-correction, and dooms transaction. [19, 20]
        """
        if 'validation_error' in cycle_context._tmp_synthesis_data:
            await self._psm_log_event(cycle_context, "SELF_CORRECTION_INITIATED")
            corrective_mission = {
                "type": "self_correction", "selector": "correct_generated_artifact",
                "context": {
                    "original_mission": cycle_context.mission_brief,
                    "failed_artifact": cycle_context._tmp_synthesis_data.get('generated_artifact') or cycle_context._tmp_synthesis_data.get('plan_json'),
                    "validation_error": cycle_context._tmp_synthesis_data['validation_error']
                }
            }
            await self.root['orchestrator_obj'].start_cognitive_cycle_for_(
                self.root['orchestrator_obj'], mission_brief=corrective_mission,
                target_obj_oid=cycle_context.target_oid
            )
        
        transaction.doom()
        cycle_oid = str(cycle_context._p_oid)
        if 'active_cycles' in self.root and cycle_oid in self.root['active_cycles']:
            del self.root['active_cycles'][cycle_oid]
            self.root._p_changed = True

    # --------------------------------------------------------------------------
    # Subsection III.D: Metacognitive & Knowledge Catalog Protocols
    # --------------------------------------------------------------------------

    async def _kc_index_document(self, kc_self, doc_id: str, doc_text: str, metadata: dict):
        """Indexes a document by chunking and storing it in the KC."""
        sentences = nltk.tokenize.sent_tokenize(doc_text)
        for i, sentence in enumerate(sentences):
            chunk_id = f"{doc_id}::chunk_{i}"
            chunk_obj = UvmObject(
                doc_id=doc_id, chunk_index=i, text=sentence,
                metadata=persistent.mapping.PersistentMapping(metadata)
            )
            kc_self.chunk_storage[chunk_id] = chunk_obj
            kc_self.text_index.index_doc(chunk_id, sentence)
            for key, value in metadata.items():
                if key not in kc_self.metadata_index:
                    kc_self.metadata_index[key] = BTrees.OOBTree.BTree()
                if value not in kc_self.metadata_index[key]:
                    kc_self.metadata_index[key][value] = BTrees.OOBTree.TreeSet()
                kc_self.metadata_index[key][value].add(chunk_id)
        kc_self._p_changed = True

    async def _kc_search(self, kc_self, query_text: str, top_k: int = 5):
        """Performs a semantic search against the KC."""
        results = kc_self.text_index.apply(query_text)
        top_results_ids = sorted(results.items(), key=lambda item: item[1], reverse=True)[:top_k]
        return [kc_self.chunk_storage.get(doc_id) for doc_id, score in top_results_ids]

    async def _kc_ingest_cognitive_audit_log_(self, alfred_self):
        """
        ALFRED Protocol: Ingests the metacognitive audit trail from the JSONL
        file into the Fractal Memory for self-analysis. [19, 20]
        """
        if not os.path.exists(METACOGNITION_LOG_FILE): return
        
        temp_log_file = METACOGNITION_LOG_FILE + ".ingesting"
        try:
            os.rename(METACOGNITION_LOG_FILE, temp_log_file)
            ingested_count = 0
            with open(temp_log_file, 'r') as f:
                for line in f:
                    try:
                        log_entry = json.loads(line)
                        doc_id = f"cycle::{log_entry.get('cycle_id')}::event::{ingested_count}"
                        await self.root['knowledge_catalog_obj'].index_document_(
                            self.root['knowledge_catalog_obj'], doc_id=doc_id,
                            doc_text=json.dumps(log_entry), metadata=log_entry
                        )
                        ingested_count += 1
                    except Exception as e:
                        print(f" Error processing log line: {e}")
            os.remove(temp_log_file)
            print(f" Ingested {ingested_count} events into Fractal Memory.")
        except Exception as e:
            if os.path.exists(temp_log_file):
                os.rename(temp_log_file, METACOGNITION_LOG_FILE)

    # --------------------------------------------------------------------------
    # Subsection III.E: Asynchronous Core & System Lifecycle
    # --------------------------------------------------------------------------

    async def worker(self, name: str):
        """
        Pulls messages from the queue and processes them in a transactional
        context, ensuring every operation is atomic. [2]
        """
        conn = self.db.open()
        while not self.should_shutdown.is_set():
            try:
                identity, message_data = await asyncio.wait_for(self.message_queue.get(), timeout=1.0)
                root = conn.root()
                try:
                    with transaction.manager:
                        command_payload = ormsgpack.unpackb(message_data)
                        command = command_payload.get("command")
                        
                        if command == "initiate_cognitive_cycle":
                            await root['orchestrator_obj'].start_cognitive_cycle_for_(
                                root['orchestrator_obj'],
                                command_payload['mission_brief'],
                                command_payload['target_oid']
                            )
                except Exception as e:
                    traceback.print_exc()
                    transaction.abort()
                finally:
                    self.message_queue.task_done()
            except asyncio.TimeoutError:
                continue
            except asyncio.CancelledError:
                break
        conn.close()

    async def zmq_listener(self):
        """Listens on the ZMQ ROUTER socket for incoming messages."""
        self.zmq_socket.bind(ZMQ_ENDPOINT)
        print(f"[UVM] Synaptic Bridge listening on {ZMQ_ENDPOINT}")
        while not self.should_shutdown.is_set():
            try:
                message_parts = await self.zmq_socket.recv_multipart()
                if len(message_parts) == 2:
                    await self.message_queue.put(message_parts)
            except zmq.error.ZMQError as e:
                if e.errno == zmq.ETERM: break
                else: raise
            except asyncio.CancelledError:
                break

    async def autotelic_loop(self):
        """
        The system's "heartbeat" for self-directed evolution, now including
        periodic metacognitive ingestion. [19, 20]
        """
        print("[UVM] Autotelic Heartbeat started.")
        await asyncio.sleep(1800)
        while not self.should_shutdown.is_set():
            try:
                with transaction.manager:
                    alfred_obj = self.root.get('alfred_prototype_obj')
                    if alfred_obj:
                        await alfred_obj._kc_ingest_cognitive_audit_log_(alfred_obj)
                
                await asyncio.sleep(1800)
                
                mission_brief = {
                    "type": "self_audit", "selector": "perform_cognitive_efficiency_audit",
                    "context": "Analyze recently ingested logs for failure patterns."
                }
                command_payload = {
                    "command": "initiate_cognitive_cycle",
                    "target_oid": str(self.root['orchestrator_obj']._p_oid),
                    "mission_brief": mission_brief
                }
                await self.message_queue.put((b'UVM_INTERNAL', ormsgpack.packb(command_payload)))
                
                await asyncio.sleep(3600)
            except asyncio.CancelledError:
                break
            except Exception as e:
                traceback.print_exc()
                await asyncio.sleep(600)

    async def run(self):
        """Main entry point to start all UVM services."""
        await self.initialize_system()

        listener_task = asyncio.create_task(self.zmq_listener())
        worker_tasks =
        autotelic_task = asyncio.create_task(self.autotelic_loop())
        
        print("[UVM] All systems running.")
        await self.should_shutdown.wait()

        listener_task.cancel()
        autotelic_task.cancel()
        for task in worker_tasks: task.cancel()
        
        await asyncio.gather(listener_task, autotelic_task, *worker_tasks, return_exceptions=True)

        self.zmq_socket.close()
        self.zmq_context.term()

    def handle_shutdown_signal(self, sig, frame):
        self.should_shutdown.set()

# ==============================================================================
# SECTION IV: SYSTEM GENESIS POINT
# ==============================================================================

if __name__ == '__main__':
    uvm = BatOS_UVM(DB_FILE, BLOB_DIR)
    
    signal.signal(signal.SIGINT, uvm.handle_shutdown_signal)
    signal.signal(signal.SIGTERM, uvm.handle_shutdown_signal)
    
    try:
        asyncio.run(uvm.run())
    except Exception as e:
        traceback.print_exc()
    finally:
        if uvm.db:
            print("[UVM] Ensuring database connection is closed...")
            uvm.db.close()
            print("[UVM] Database connection closed.")
