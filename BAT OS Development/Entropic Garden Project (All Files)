{"cells":[{"cell_type":"code","source":"# ==============================================================================\n# File: main.py\n# The Entropic Garden Master Script\n# ==============================================================================\n# This script consolidates all services into a single executable, managing them\n# concurrently to run the entire Entropic Garden system.\n#\n# It is designed for \"bare metal\" local execution.\n#\n# To run this script, ensure all prerequisites are installed and run:\n# python main.py\n#\n# A graceful shutdown can be initiated with Ctrl+C.\n# ==============================================================================\n\nimport os\nimport sys\nimport json\nimport yaml\nimport time\nimport requests\nimport hashlib\nimport schedule\nimport pypdf\nimport docx\nimport importlib.util\nimport glob\nimport random\nimport signal\nfrom datetime import datetime\nfrom threading import Thread\nfrom multiprocessing import Process, Queue\nfrom watchdog.observers import Observer\nfrom watchdog.events import FileSystemEventHandler\n\n# Third-party libraries used in the system\nfrom arango import ArangoClient\nimport redis\nimport chromadb\nfrom chromadb.utils import embedding_functions\n\n# A global queue for inter-process communication\nmessage_queue = Queue()\n\n# ==============================================================================\n# CONFIGURATION & INITIALIZATION\n# ==============================================================================\n# Load configuration from config.yaml\ntry:\n    with open('config.yaml', 'r') as f:\n        config = yaml.safe_load(f)\nexcept FileNotFoundError:\n    print(\"Error: config.yaml not found. Please ensure it exists in the root directory.\")\n    sys.exit(1)\n\n# Load persona prompts and model configuration\ntry:\n    with open('persona_prompts.json', 'r') as f:\n        prompts = json.load(f)\n    with open('model_config.json', 'r') as f:\n        model_config = json.load(f)\nexcept FileNotFoundError:\n    print(\"Error: persona_prompts.json or model_config.json not found.\")\n    sys.exit(1)\n\n# ArangoDB environment variables\nARANGO_USER = os.environ.get('ARANGO_USER', 'root')\nARANGO_PASSWORD = os.environ.get('ARANGO_PASSWORD', 'yoursecurepassword')\nARANGO_HOST = config['graph_db']['uri']\nARANGO_DB = config['graph_db']['database']\n\n# Initialize Redis client\nr = redis.Redis(host=config['redis']['host'], port=config['redis']['port'], decode_responses=True)\n\n# Initialize ChromaDB client\nchroma_client = chromadb.HttpClient(host=config['vector_db']['host'], port=config['vector_db']['port'])\nembedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n\n# Initialize ArangoDB client\ntry:\n    client = ArangoClient(hosts=ARANGO_HOST)\n    db = client.db(ARANGO_DB, username=ARANGO_USER, password=ARANGO_PASSWORD)\n    # Ensure collections and graph exist\n    if not db.has_collection('insights'): db.collection('insights').create()\n    if not db.has_collection('source_files'): db.collection('source_files').create()\n    if not db.has_edge_collection('analyzes'):\n        db.collection('analyzes').create_edge()\n    if not db.has_edge_collection('synthesizes'):\n        db.collection('synthesizes').create_edge()\n    print(\"ArangoDB connection and collections initialized successfully.\")\nexcept Exception as e:\n    print(f\"Error initializing ArangoDB: {e}\")\n    sys.exit(1)\n\n\n# ==============================================================================\n# HELPER FUNCTIONS (Shared Logic)\n# ==============================================================================\ndef call_llm(prompt, model_name, temperature, max_tokens=1000):\n    \"\"\"Makes a request to the local LLM API.\"\"\"\n    payload = {\"model\": model_name, \"messages\": [{\"role\": \"user\", \"content\": prompt}], \"temperature\": temperature, \"max_tokens\": max_tokens}\n    try:\n        response = requests.post(config['llm_core']['api_url'], json=payload)\n        response.raise_for_status()\n        return response.json()['choices'][0]['message']['content']\n    except requests.exceptions.RequestException as e:\n        print(f\"Error calling LLM: {e}\")\n        return None\n\ndef get_file_hash(filepath):\n    \"\"\"Generates a SHA256 hash of a file's content.\"\"\"\n    sha256_hash = hashlib.sha256()\n    if os.path.exists(filepath):\n        with open(filepath, \"rb\") as f:\n            for byte_block in iter(lambda: f.read(4096), b\"\"):\n                sha256_hash.update(byte_block)\n    return sha256_hash.hexdigest()\n\ndef find_and_use_tool(query_text):\n    \"\"\"Logic to find and use a dynamically generated tool.\"\"\"\n    approved_tools = glob.glob(os.path.join(config['paths']['tools_approved'], '*.py'))\n    if not approved_tools:\n        return None, None\n    for tool_path in approved_tools:\n        try:\n            spec = importlib.util.spec_from_file_location(\"dynamic_tool\", tool_path)\n            module = importlib.util.module_from_spec(spec)\n            spec.loader.exec_module(module)\n            if hasattr(module, 'run_tool'):\n                print(f\"[TOOL] Found relevant tool: {tool_path}\")\n                tool_output = module.run_tool(query_text)\n                return tool_output, os.path.basename(tool_path)\n        except Exception as e:\n            print(f\"[TOOL] Error loading or running tool {tool_path}: {e}\")\n    return None, None\n\n\n# ==============================================================================\n# WATCHER SERVICE (Process 1)\n# ==============================================================================\ndef watcher_service_main():\n    \"\"\"Monitors the inputs directory for file changes.\"\"\"\n    class FileChangeHandler(FileSystemEventHandler):\n        def on_created(self, event):\n            if not event.is_directory: self._handle_event(event.src_path, 'created')\n        def on_modified(self, event):\n            if not event.is_directory: self._handle_event(event.src_path, 'modified')\n        def on_deleted(self, event):\n            if not event.is_directory: self._handle_event(event.src_path, 'deleted')\n        \n        def _handle_event(self, filepath, event_type):\n            time.sleep(1)\n            filename = os.path.basename(filepath)\n            file_hash = get_file_hash(filepath)\n            \n            if event_type == 'deleted':\n                print(f\"[WATCHER] File deleted: {filepath}\")\n                message = {'filepath': filepath, 'hash': file_hash, 'event_type': 'deleted'}\n                r.publish('files:deleted', json.dumps(message))\n                r.srem('processed_files', file_hash)\n                return\n\n            if r.sismember('processed_files', file_hash):\n                print(f\"[WATCHER] File {event_type} event for already processed file: {filename}. Skipping.\")\n                return\n\n            print(f\"[WATCHER] New file {event_type} detected: {filename}\")\n            message = {'filepath': filepath, 'hash': file_hash, 'event_type': event_type}\n            r.publish('files:new', json.dumps(message))\n            r.sadd('processed_files', file_hash)\n\n    print(\"--- Starting Sensory Bus (Watcher Service) ---\")\n    event_handler = FileChangeHandler()\n    observer = Observer()\n    observer.schedule(event_handler, config['paths']['inputs'], recursive=False)\n    observer.start()\n    try:\n        while True:\n            time.sleep(1)\n    except KeyboardInterrupt:\n        observer.stop()\n    observer.join()\n\n# ==============================================================================\n# PERSONA SERVICES (Processes 2-4)\n# ==============================================================================\ndef babs_service_main():\n    \"\"\"BABS: Processes new files into insights.\"\"\"\n    persona_name = \"BABS\"\n    print(f\"--- Starting {persona_name} Persona Service ---\")\n    \n    canon_collection = chroma_client.get_collection(name=f\"{persona_name.lower()}_canon\", embedding_function=embedding_func)\n    \n    def extract_text(filepath):\n        _, ext = os.path.splitext(filepath)\n        text = \"\"\n        try:\n            if ext == '.pdf':\n                with open(filepath, 'rb') as f: text = \"\".join(page.extract_text() for page in pypdf.PdfReader(f).pages)\n            elif ext == '.docx':\n                text = \"\\n\".join(p.text for p in docx.Document(filepath).paragraphs)\n            else:\n                with open(filepath, 'r', encoding='utf-8') as f: text = f.read()\n        except Exception as e:\n            print(f\"[{persona_name}] Error extracting text: {e}\")\n            return None\n        return text\n\n    def get_rag(query_text, n_results=3):\n        results = canon_collection.query(query_texts=[query_text], n_results=n_results)\n        return \"\\n\\n\".join(results['documents'][0])\n\n    def save_insight_to_db(insight_text, filename, file_hash):\n        query = \"\"\"\n        UPSERT { hash: @hash }\n        INSERT { hash: @hash, filename: @filename }\n        UPDATE { filename: @filename }\n        IN source_files\n        LET sourceFile = NEW\n        INSERT { persona: @persona, text: @text, timestamp: DATE_ISO8601(DATE_NOW()), status: 'new' } INTO insights\n        LET newInsight = NEW\n        INSERT { _from: newInsight._id, _to: sourceFile._id } INTO analyzes\n        RETURN newInsight._key\n        \"\"\"\n        cursor = db.aql.execute(query, bind_vars={'hash': file_hash, 'filename': filename, 'persona': persona_name, 'text': insight_text})\n        return cursor.next()\n    \n    pubsub = r.pubsub()\n    pubsub.subscribe(\"files:new\")\n    for message in pubsub.listen():\n        if message['type'] == 'message':\n            data = json.loads(message['data'])\n            filepath, file_hash, filename = data['filepath'], data['hash'], os.path.basename(data['filepath'])\n            print(f\"[{persona_name}] Processing new file: {filename}\")\n            content = extract_text(filepath)\n            if not content: continue\n            \n            rag_context = get_rag(content[:2000])\n            prompt_template = prompts[persona_name]\n            final_prompt = prompt_template.format(rag_context=rag_context, document_content=content)\n            \n            insight_text = call_llm(final_prompt, model_config[persona_name]['base_model'], 0.7)\n            if not insight_text: continue\n\n            insight_key = save_insight_to_db(insight_text, filename, file_hash)\n            r.publish(\"insights:babs:new\", json.dumps({'key': insight_key}))\n\ndef brick_service_main():\n    \"\"\"BRICK: Processes BABS's insights into a larger context.\"\"\"\n    persona_name = \"BRICK\"\n    print(f\"--- Starting {persona_name} Persona Service ---\")\n    \n    canon_collection = chroma_client.get_collection(name=f\"{persona_name.lower()}_canon\", embedding_function=embedding_func)\n    \n    def get_rag(query_text, n_results=3):\n        results = canon_collection.query(query_texts=[query_text], n_results=n_results)\n        return \"\\n\\n\".join(results['documents'][0])\n    \n    def get_prev_insight(key):\n        try: return db.collection('insights').get(key)['text']\n        except: return None\n    \n    def save_insight_to_db(insight_text, previous_key):\n        query = \"\"\"\n        LET prev = DOCUMENT('insights', @previous_key)\n        INSERT { persona: @persona, text: @text, timestamp: DATE_ISO8601(DATE_NOW()), status: 'new' } INTO insights\n        LET new_insight = NEW\n        INSERT { _from: new_insight._id, _to: prev._id } INTO analyzes\n        RETURN new_insight._key\n        \"\"\"\n        cursor = db.aql.execute(query, bind_vars={'previous_key': previous_key, 'persona': persona_name, 'text': insight_text})\n        return cursor.next()\n        \n    def proactive_code_generation():\n        print(f\"[{persona_name}] Jester's Gambit: Autonomously generating a new tool.\")\n        code_prompt = \"Generate a simple, self-contained Python function named 'run_tool' that takes a string as input and returns its SHA256 hash. Do not include any other text.\"\n        generated_code = call_llm(code_prompt, model_config[persona_name]['base_model'], 0.8)\n        if generated_code:\n            try: generated_code = generated_code.split(\"```python\")[1].split(\"```\")[0]\n            except IndexError: return\n            tool_path = os.path.join(config['paths']['tools_pending'], f\"hash_tool_{int(time.time())}.py\")\n            os.makedirs(os.path.dirname(tool_path), exist_ok=True)\n            with open(tool_path, 'w') as f: f.write(generated_code)\n            r.publish('tools:audit_request', json.dumps({\"filepath\": tool_path}))\n\n    pubsub = r.pubsub()\n    pubsub.subscribe(\"insights:babs:new\")\n    for message in pubsub.listen():\n        if message['type'] == 'message':\n            data = json.loads(message['data'])\n            prev_key = data['key']\n            prev_insight = get_prev_insight(prev_key)\n            if not prev_insight: continue\n            \n            rag_context = get_rag(prev_insight)\n            prompt_template = prompts[persona_name]\n            final_prompt = prompt_template.format(rag_context=rag_context, previous_insight=prev_insight)\n            \n            insight_text = call_llm(final_prompt, model_config[persona_name]['base_model'], 0.8)\n            if not insight_text: continue\n\n            insight_key = save_insight_to_db(insight_text, prev_key)\n            r.publish(\"insights:brick:new\", json.dumps({'key': insight_key}))\n            if random.random() < 0.1: proactive_code_generation()\n\ndef robin_service_main():\n    \"\"\"ROBIN: Synthesizes BRICK's analysis with emotional and philosophical context.\"\"\"\n    persona_name = \"ROBIN\"\n    print(f\"--- Starting {persona_name} Persona Service ---\")\n    \n    canon_collection = chroma_client.get_collection(name=f\"{persona_name.lower()}_canon\", embedding_function=embedding_func)\n    \n    def get_rag(query_text, n_results=3):\n        results = canon_collection.query(query_texts=[query_text], n_results=n_results)\n        return \"\\n\\n\".join(results['documents'][0])\n    \n    def get_insight_chain(brick_key):\n        query = \"\"\"\n        FOR b IN insights\n            FILTER b._key == @brick_key\n            FOR e IN analyzes\n                FILTER e._from == b._id\n                FOR bs IN insights\n                    FILTER bs._id == e._to\n                    RETURN { brick_insight: b.text, babs_insight: bs.text }\n        \"\"\"\n        cursor = db.aql.execute(query, bind_vars={'brick_key': brick_key})\n        return cursor.next()\n    \n    def save_insight_to_db(insight_text, previous_key):\n        query = \"\"\"\n        LET prev = DOCUMENT('insights', @previous_key)\n        INSERT { persona: @persona, text: @text, timestamp: DATE_ISO8601(DATE_NOW()), status: 'new' } INTO insights\n        LET new_insight = NEW\n        INSERT { _from: new_insight._id, _to: prev._id } INTO synthesizes\n        RETURN new_insight._key\n        \"\"\"\n        cursor = db.aql.execute(query, bind_vars={'previous_key': previous_key, 'persona': persona_name, 'text': insight_text})\n        return cursor.next()\n        \n    pubsub = r.pubsub()\n    pubsub.subscribe(\"insights:brick:new\")\n    for message in pubsub.listen():\n        if message['type'] == 'message':\n            data = json.loads(message['data'])\n            prev_key = data['key']\n            chain = get_insight_chain(prev_key)\n            if not chain: continue\n            \n            rag_context = get_rag(chain['babs_insight'] + \" \" + chain['brick_insight'])\n            prompt_template = prompts[persona_name]\n            final_prompt = prompt_template.format(rag_context=rag_context, babs_insight=chain['babs_insight'], brick_insight=chain['brick_insight'])\n            \n            insight_text = call_llm(final_prompt, model_config[persona_name]['base_model'], 0.9)\n            if not insight_text: continue\n            \n            insight_key = save_insight_to_db(insight_text, prev_key)\n            r.publish(\"insights:robin:new\", json.dumps({'key': insight_key}))\n\n# ==============================================================================\n# ALFRED & SCHEDULER SERVICES (Processes 5-6)\n# ==============================================================================\ndef alfred_service_main():\n    \"\"\"ALFRED: Audits insights and manages tools.\"\"\"\n    persona_name = \"ALFRED\"\n    print(f\"--- Starting {persona_name} Persona Service ---\")\n    \n    canon_collection = chroma_client.get_collection(name=f\"{persona_name.lower()}_canon\", embedding_function=embedding_func)\n    \n    def get_rag(query_text, n_results=3):\n        results = canon_collection.query(query_texts=[query_text], n_results=n_results)\n        return \"\\n\\n\".join(results['documents'][0])\n        \n    def audit_tool(filepath):\n        print(f\"[{persona_name}] Auditing new tool: {filepath}\")\n        with open(filepath, 'r') as f: code = f.read()\n        if \"os.system\" in code or \"subprocess\" in code:\n            os.remove(filepath)\n            return\n        audit_prompt = f\"Analyze this Python code for security and functionality. Is it safe for a sandbox environment? Respond YES or NO. Code: {code}\"\n        result = call_llm(audit_prompt, model_config[persona_name]['base_model'], 0.1, max_tokens=5)\n        if result and \"YES\" in result.upper():\n            approved_path = filepath.replace('pending_review', 'approved')\n            os.rename(filepath, approved_path)\n        else: os.remove(filepath)\n        \n    def get_unaudited_chains():\n        query = \"\"\"\n        FOR r IN insights\n            FILTER r.persona == 'ROBIN' AND r.status == 'new'\n            FOR b IN insights\n                FILTER b.persona == 'BRICK' AND b.status == 'new'\n                FOR bs IN insights\n                    FILTER bs.persona == 'BABS' AND bs.status == 'new'\n                    FOR e IN synthesizes\n                        FILTER e._from == r._id AND e._to == b._id\n                        FOR e2 IN analyzes\n                            FILTER e2._from == b._id AND e2._to == bs._id\n                            RETURN { robin_key: r._key, robin_insight: r.text, brick_insight: b.text, babs_insight: bs.text }\n        \"\"\"\n        return list(db.aql.execute(query))\n        \n    def update_chain_status(robin_key, status):\n        query = \"\"\"\n        FOR i IN insights\n            FILTER i._key == @key\n            UPDATE i WITH { status: @status } IN insights\n        \"\"\"\n        db.aql.execute(query, bind_vars={'key': robin_key, 'status': status})\n    \n    def audit_chain(chain):\n        prompt = prompts[persona_name].format(\n            rag_context=get_rag(chain['robin_insight']),\n            babs_insight=chain['babs_insight'],\n            brick_insight=chain['brick_insight'],\n            robin_insight=chain['robin_insight']\n        )\n        result = call_llm(prompt, model_config[persona_name]['base_model'], 0.1, max_tokens=5)\n        return \"audited_pass\" if result and \"PASS\" in result.upper() else \"audited_fail\"\n        \n    def run_audit():\n        chains = get_unaudited_chains()\n        if chains:\n            for chain in chains:\n                status = audit_chain(chain)\n                update_chain_status(chain['robin_key'], status)\n\n    tool_audit_thread = Thread(target=lambda: r.pubsub().subscribe('tools:audit_request', lambda msg: audit_tool(json.loads(msg['data'])['filepath'])))\n    tool_audit_thread.daemon = True\n    tool_audit_thread.start()\n    \n    pubsub = r.pubsub()\n    pubsub.subscribe(\"insights:robin:new\")\n    for message in pubsub.listen():\n        if message['type'] == 'message':\n            run_audit()\n\ndef scheduler_service_main():\n    \"\"\"Schedules daily briefings and weekly fine-tuning.\"\"\"\n    print(\"--- Starting Scheduler Service ---\")\n    \n    def generate_morning_briefing():\n        print(f\"[{datetime.now()}] DAWN: Kicking off Morning Briefing generation.\")\n        query = \"\"\"\n        FOR i IN insights\n            FILTER i.timestamp >= DATE_ISO8601(DATE_SUB(DATE_NOW(), 1, 'd')) AND i.status == 'audited_pass'\n            SORT i.timestamp ASC\n            RETURN { persona: i.persona, text: i.text }\n        \"\"\"\n        insights = list(db.aql.execute(query))\n        if not insights:\n            print(\"No new audited insights to report. Skipping briefing.\")\n            return\n        briefing_content = call_llm(prompts['ALFRED'].format(insights_context=\"\\n\\n\".join(f\"**{i['persona']}**: {i['text']}\" for i in insights)), model_config['ALFRED']['base_model'], 0.5)\n        filepath = os.path.join(config['paths']['outputs'], f\"Morning_Briefing_{datetime.now().strftime('%Y-%m-%d')}.md\")\n        with open(filepath, 'w') as f: f.write(briefing_content)\n        print(f\"Successfully generated and saved '{os.path.basename(filepath)}'.\")\n\n    def trigger_fine_tuning(persona_name):\n        print(f\"[{datetime.now()}] FORGE: Triggering fine-tuning for {persona_name}.\")\n        try: requests.post(f\"http://localhost:8002/forge/{persona_name}\").raise_for_status()\n        except requests.exceptions.RequestException as e: print(f\"[FORGE] Error: {e}\")\n\n    schedule.every().day.at(config['scheduler']['dawn_time']).do(generate_morning_briefing)\n    schedule.every().day.at(config['scheduler']['twilight_time']).do(lambda: r.publish('tasks:audit:start', json.dumps({})))\n    schedule.every().sunday.at(\"03:00\").do(trigger_fine_tuning, \"ROBIN\")\n    schedule.every().sunday.at(\"03:30\").do(trigger_fine_tuning, \"BRICK\")\n    schedule.every().sunday.at(\"04:00\").do(trigger_fine_tuning, \"BABS\")\n    schedule.every().sunday.at(\"04:30\").do(trigger_fine_tuning, \"ALFRED\")\n\n    while True:\n        schedule.run_pending()\n        time.sleep(60)\n\n# ==============================================================================\n# MAIN EXECUTION BLOCK\n# ==============================================================================\ndef main():\n    \"\"\"Initializes and runs all services concurrently.\"\"\"\n    print(\"--- Starting Entropic Garden Master Script ---\")\n    \n    # List of services to run\n    services = {\n        'watcher': watcher_service_main,\n        'babs': babs_service_main,\n        'brick': brick_service_main,\n        'robin': robin_service_main,\n        'alfred': alfred_service_main,\n        'scheduler': scheduler_service_main\n    }\n    \n    processes = []\n    \n    def signal_handler(sig, frame):\n        print(\"\\nShutting down services gracefully...\")\n        for p in processes:\n            p.terminate()\n            p.join()\n        sys.exit(0)\n\n    signal.signal(signal.SIGINT, signal_handler)\n\n    for name, target in services.items():\n        p = Process(target=target, name=name)\n        p.start()\n        processes.append(p)\n        print(f\"Process '{name}' started with PID {p.pid}\")\n    \n    print(\"\\nAll services are running. Press Ctrl+C to shut down.\")\n    \n    for p in processes:\n        p.join()\n\nif __name__ == \"__main__\":\n    main()","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}