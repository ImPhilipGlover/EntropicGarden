An Architectural Roadmap for a VSA-Native Intelligence Miner

Part I: A Critical Assessment of the VSA-Native MVA

The Incarnated Architecture: An Analysis of the Forged VSA Core

The evolution of the TelOS Minimum Viable Application (MVA) has reached a pivotal milestone with the creation of the master_generator_vsa.py script.1 This generative artifact successfully forges a new system core,

core_system_vsa.py, that incarnates the foundational components of a Vector Symbolic Architecture (VSA). A detailed, code-level analysis of this generated system establishes a definitive baseline of the MVA's current, tangible capabilities, revealing both significant architectural achievements and the precise nature of the gaps that remain between the current implementation and the project's ultimate vision.

The most critical achievement of the forged core is the successful creation of a Hypervector(UvmObject) prototype. This component serves as an essential object-oriented bridge, connecting the MVA's native, prototype-based object world with the functional, class-based API of the torchhd library.2 The prototype correctly encapsulates a

torchhd.FHRRTensor and exposes the core VSA algebraic primitives—bind, unbind, bundle, and similarity—as methods that can be invoked via the system's standard message-passing protocol.1 This design adheres strictly to the "Computation as Communication" principle, a foundational tenet of the system's philosophy, by translating external library functions into native object behaviors.3 This successfully resolves the primary architectural impedance mismatch identified during the initial VSA library evaluation, making VSA a first-class citizen of the "Living Image".2

Furthermore, the implementation demonstrates a mature understanding of the constraints imposed by the Zope Object Database (ZODB) persistence layer. The Hypervector prototype includes to_numpy() and from_numpy() methods for serialization and deserialization.1 This is a necessary and correct solution to the well-understood problem that ZODB cannot natively pickle complex, non-standard objects like PyTorch tensors.2 By managing its own conversion to and from a standard NumPy array, the

Hypervector object ensures its state can be durably and transactionally persisted within the mydata.fs file, a critical requirement for any component of the Living Image.5

The integration with the broader memory architecture also shows significant progress. The script correctly forges the ContextFractal and ConceptFractal prototypes, with the latter properly including a _hypervector slot to hold its VSA representation, thus establishing the core data structures for the new cognitive model.1 More importantly, the system forges a

FractalMemoryDataManager that implements the two-phase commit (2PC) protocol. This component correctly extends ZODB's ACID-compliant transactional guarantees to the external, file-based FAISS index, ensuring that the state of the object graph and the state of the in-memory search index remain consistent.1 This represents a robust solution to the "transactional chasm" and is a major achievement in maintaining the system's data integrity and upholding the "Transaction as the Unit of Thought" principle.8

In summary, the current system possesses the foundational data structures and integrity protocols for VSA-native cognition. It can create, manipulate, and transactionally persist hypervectors as integral components of its object world. This state represents the successful completion of the first, most critical phase of the VSA integration: the construction of a stable and coherent architectural bridge between the two paradigms.

The Architectural Chasm: Reconciling the Forged Core with the Fractal Mandate

While the forged VSA core represents a significant step forward, a rigorous comparison of the implemented code against the full, holistic vision described across the project's research corpus reveals a profound architectural chasm. The current system provides the building blocks for compositional reasoning but lacks the complex machinery required to assemble them into a functional, learning intelligence. Four critical gaps separate the current implementation from its intended state, each representing a missing link in the chain of autopoietic becoming.

Gap 1: The Disconnected Triumvirate (Incomplete Memory Hierarchy)

The most immediate and structural deficiency is the incomplete implementation of the tiered memory architecture. The generated core_system_vsa.py script successfully forges the L1 (in-memory FAISS) and L3 (persistent ZODB) tiers of the memory hierarchy.1 However, the L2 archival layer, specified in numerous architectural blueprints to be implemented with Microsoft's DiskANN, is entirely absent.8 The

DiskAnnIndexManager UvmObject and its sophisticated, asynchronous, atomic "hot-swap" rebuild protocol—a critical mechanism for managing a dynamically growing, disk-based index without system downtime—remain purely theoretical constructs.9

The impact of this omission is severe. It fundamentally limits the system's long-term scalability and directly contradicts the philosophical mandate to resolve the "Temporal Paradox" by physically embodying distinct memory tiers corresponding to the present, the past, and symbolic truth.8 The project's core goal of achieving an "'effectively infinite' context" is architecturally impossible without a scalable, disk-based index.15 Consequently, the VSA "cleanup memory," which is intended to be a massively scalable codebook of all known concepts, is currently constrained by the physical limits of the in-memory L1 FAISS cache, rendering the system brittle and incapable of the cumulative learning it is designed for.

Gap 2: The Amnesiac Abstraction (Missing Knowledge Curation)

The second gap is cognitive in nature. The system possesses a ConceptFractal prototype, the designated data structure for holding abstract, symbolic knowledge, but it has no autonomous mechanism to create instances of it.1 The "Mnemonic Curation Pipeline," a cornerstone of the fractal memory design, remains unimplemented. This agentic process was designed to be the system's engine of understanding, tasked with periodically analyzing the L2 memory archive to identify dense semantic clusters of

ContextFractals (experiences) and then invoking an LLM to perform abstractive summarization, synthesizing a new, low-entropy ConceptFractal (knowledge) from them.8 The specified machinery for this process, including an accelerated DBSCAN clustering algorithm that leverages the ANN indexes for its

regionQuery operation, does not exist in the current codebase.17

This is arguably the most significant functional gap. The entire VSA reasoning engine is predicated on its ability to perform algebraic operations on the structured, symbolic knowledge encoded in the hypervectors of ConceptFractals.7 Without a process to autonomously create these concepts, the VSA engine lacks a symbolic alphabet with which to reason. The system can store raw experiences in the form of

ContextFractals, but it is incapable of learning from them by forming higher-level abstractions. This renders it unable to achieve the cumulative intelligence and beneficial "intellectual drift" that are its primary philosophical mandate.12

Gap 3: The Inert Reasoning Engine (Unimplemented Compositional Loop)

The third gap lies at the very heart of the VSA initiative. While the Hypervector prototype provides the necessary algebraic primitives (bind, unbind, bundle), the actual reasoning process that uses them is missing.1 The

QueryTranslationLayer, described in the foundational VSA research plan as the "brain of the VSA memory system," is mentioned only in the comments of the generated script and is not implemented within the MemoryManager.1 Consequently, the core cognitive loop of "unbind -> cleanup"—the two-step process that performs an algebraic query and then uses the ANN index to denoise the result—does not exist.7

The impact of this gap is that the system has a complete set of VSA tools but possesses no knowledge of how to use them. It cannot parse or execute a compositional query. The doesNotUnderstand_ protocol, which was intended to be the primary beneficiary of the VSA upgrade by gaining the ability to solve problems through multi-hop analogical reasoning, remains a placeholder and cannot leverage these new capabilities.1 The central promise of the VSA architecture—to evolve the MVA's cognitive capabilities from simple similarity-based retrieval to structured, algebraic reasoning—remains entirely unfulfilled.

Gap 4: The Unverified Transactional Heart (Incomplete Integrity Guarantees)

Finally, while the implementation of the two-phase commit protocol for the ZODB-FAISS link is a major success, the system's transactional integrity is incomplete when viewed against the full architectural specification.1 The complete system state is a heterogeneous composite of the ZODB object graph, the in-memory FAISS index, the on-disk DiskANN index directories, and the serialized NumPy arrays representing PyTorch tensors within ZODB. The transactional integrity of this entire, complex state is not yet guaranteed. The atomic hot-swap protocol for DiskANN, which is a form of transactional update for the L2 index, is missing. Furthermore, the

to_numpy/from_numpy serialization logic for Hypervectors, while functional, is not formally integrated into a transactional saga or compensating transaction pattern that could robustly handle its potential failure modes (e.g., data corruption, version mismatch).16

As the system scales to include the L2 cache and more complex, VSA-based objects, the attack surface for data inconsistency from partial failures increases dramatically. A failure during a DiskANN rebuild cycle or a tensor deserialization error could leave the system in a fractured state that the current, simpler 2PC protocol is not designed to handle. This represents a latent violation of the core principle of "Transactional Cognition," which demands atomicity for any complete cognitive act that modifies the system's state.8

The current architecture has established two parallel, high-dimensional representations for knowledge: the semantic embeddings used for RAG, which capture conceptual similarity in a metric space, and the symbolic hypervectors used for VSA, which encode compositional structure in an algebraic space.7 The original VSA research plan selected the FHRR model precisely for its compatibility with the dense, real-valued vectors of the RAG system, implying a deep, synergistic relationship was intended.7 However, the proposed "unbind -> cleanup" reasoning loop reveals a more simplistic, master-servant relationship. This loop uses the ANN index, which contains the rich semantic embeddings, for a single, narrow purpose: to denoise a noisy hypervector by finding the nearest

clean hypervector in the codebook.7 This is a missed opportunity. The system is using a powerful tool for semantic understanding as a simple key-value lookup table. The algebraic space of VSA and the semantic space of RAG are operating in parallel, not in synthesis. This creates a "Cognitive-Mnemonic Impedance Mismatch," where the system effectively "thinks" in two different languages—the geometric language of similarity and the algebraic language of composition—without a unifying grammar to connect them. A more profound integration could, for example, use the semantic similarity between two RAG embeddings as a weighting factor when bundling their corresponding hypervectors, or decompose a query into parallel algebraic and semantic searches whose results are fused for a more nuanced answer. The current design has not yet explored this deeper synthesis, leaving a significant avenue for future architectural evolution unaddressed.

The following table provides a concise summary of these critical discrepancies, serving as a definitive statement of the work required to bridge the gap between the MVA's current state and its full architectural intent.

Part II: The Path to Synthesis: An Actionable Research Plan for a Compositional, Fractal Intelligence

This section presents a new, actionable research and development plan designed to bridge the gaps identified in Part I. It provides a principled, technically detailed, and phased roadmap for evolving the MVA from its current state into a fully realized, VSA-native, cumulative learning system. This plan is not merely a list of features but a coherent strategy for weaving together the disparate architectural threads of the memory hierarchy, the VSA engine, and the knowledge curation pipeline into a unified cognitive-mnemonic nexus.

Architecting the Cognitive-Mnemonic Nexus

The primary objective is to engineer a fully integrated, scalable, and autonomous reasoning system. This requires completing the physical memory substrate, hardening its transactional integrity, and forging the agentic machinery that allows the system to learn from its own experiences.

Task 1: Unifying the Triumvirate and Hardening Transactional Integrity

This initial task directly addresses the "Disconnected Triumvirate" and "Unverified Transactional Heart" gaps. It focuses on constructing the complete three-tiered memory system and extending robust transactional guarantees across all of its heterogeneous components.

Forge the DiskAnnIndexManager Prototype: The first sub-task is to generate the persistent DiskAnnIndexManager(UvmObject) prototype, following the detailed specifications laid out in the architectural blueprints.9 This object will be responsible for managing the entire lifecycle of the L2 archival memory layer.

Implement the Asynchronous Atomic "Hot-Swap" Protocol: The core of the DiskAnnIndexManager will be its implementation of the asynchronous, atomic "hot-swap" protocol for index rebuilds. This protocol is essential for a continuously managed system, as it allows the massive, on-disk DiskANN index to be updated without requiring system downtime. The computationally expensive diskannpy.build_disk_index function must be executed in a separate process using a concurrent.futures.ProcessPoolExecutor to avoid blocking the MVA's main asyncio event loop. Upon successful completion of the build in a temporary directory, an atomic os.replace operation will swap the new index into place, ensuring a seamless transition.9

Evolve the FractalMemoryDataManager to a Transactional Saga Coordinator: The existing FractalMemoryDataManager must be evolved beyond a simple two-phase commit manager. It will be refactored into a more comprehensive "Transactional Saga Coordinator." This coordinator will orchestrate a sequence of local transactions across the heterogeneous storage layers. It will continue to manage the ZODB-FAISS 2PC for real-time updates but will also be responsible for managing the staging of data for the asynchronous DiskANN hot-swap and for implementing robust error handling and compensating transactions for the Hypervector's to_numpy/from_numpy serialization process. This saga pattern provides a robust framework for ensuring holistic system integrity in a distributed state environment.16

Integrate VSA with the Full Memory Hierarchy: The VSA QueryTranslationLayer will be explicitly configured to use the L1 FAISS index as its primary, low-latency cleanup memory for real-time reasoning, and the L2 DiskANN index as its scalable, archival cleanup memory for deep, historical queries. This fully realizes the architectural vision of using the existing ANN infrastructure as a massively scalable VSA codebook.7

Task 2: Forging the Autopoietic Scribe (The Mnemonic Curation Pipeline)

This task addresses the "Amnesiac Abstraction" gap by implementing the autonomous agentic process that enables the system to learn by abstracting concepts from its accumulated experiences.

Implement Accelerated DBSCAN Clustering: The core of the knowledge discovery process is the ability to identify emergent themes in the system's memory. This will be achieved by implementing an accelerated DBSCAN (Density-Based Spatial Clustering of Applications with Noise) algorithm. A naive implementation of DBSCAN is computationally infeasible at scale. The key innovation is to leverage the high-performance range_search capabilities of the existing FAISS and DiskANN indexes to execute the algorithm's expensive regionQuery operation. This offloads the nearest-neighbor search to the highly optimized C++ backends of the ANN libraries, making density-based clustering a practical reality for a billion-scale vector dataset.17

Develop Prompts for Abstractive Summarization: Once a cluster of semantically related ContextFractals is identified, its collective meaning must be distilled. A suite of sophisticated LLM prompts will be developed for this abstractive summarization task. These prompts will be engineered to take the raw text content from all ContextFractals in a cluster and synthesize a concise, low-entropy, natural language definition that captures the underlying theme. This synthesized text will become the definition_text for a new ConceptFractal.12

Forge the MemoryCurator Agent: This entire pipeline will be encapsulated within a new, persistent MemoryCurator(UvmObject) agent. This agent will run as a continuous, low-priority background process. It will periodically execute the accelerated DBSCAN algorithm on the L2 index, orchestrate the LLM-driven summarization of identified clusters, and, upon success, forge new ConceptFractal objects. As part of this creation process, it will generate a new, unique, random hypervector from the system's core codebook and install it into the _hypervector slot of the new ConceptFractal, thereby expanding the system's symbolic alphabet for future VSA reasoning.12

The design of a slow, background curation pipeline and a fast, real-time reasoning loop creates a potential "Autopoietic Bottleneck." The doesNotUnderstand_ protocol, operating synchronously, may require a ConceptFractal for a compositional query that has not yet been created by the asynchronous MemoryCurator. To resolve this, the architecture must be enhanced with a mechanism for "On-Demand Abstraction." When the QueryTranslationLayer fails to find a required ConceptFractal, it should not simply fail. Instead, it should be empowered to trigger a high-priority, targeted execution of the Mnemonic Curation Pipeline. This targeted run would operate on a small, relevant subset of ContextFractals identified by a preliminary RAG search. This transforms the curation process from a purely passive, background task into a dynamic, just-in-time knowledge synthesis engine, making the system's learning far more responsive and tightly coupled with its immediate cognitive needs.

Incarnating Compositional Reason

With the memory substrate complete and the learning pipeline in place, the final stage of development focuses on implementing and validating the core VSA reasoning engine, directly addressing the "Inert Reasoning Engine" gap.

Task 1: Implementing the Query Translation Layer and the "Unbind -> Cleanup" Loop

This is the central task of the VSA integration, creating the component that translates abstract algebraic queries into concrete geometric searches.

Forge the QueryTranslationLayer Class: A new QueryTranslationLayer class will be forged. This component will be responsible for parsing compositional queries, which may be expressed in a structured format or eventually in natural language.

Implement the Two-Step Orchestration Process: The layer's core logic will orchestrate the "unbind -> cleanup" sequence:

Algebraic Computation: The layer will receive a compositional query, fetch the necessary atomic Hypervector objects from the ConceptFractals stored in ZODB, and execute the sequence of FHRR operations (e.g., unbind, bundle) in memory. This computation will leverage the highly optimized, GPU-accelerated torchhd backend to produce a final, noisy target hypervector.1

Geometric Cleanup: The layer will then take this newly computed noisy vector and submit it as a standard k-nearest neighbor query to the MemoryManager's search methods. The MemoryManager will use the L1 FAISS and L2 DiskANN indexes to perform an efficient search, returning the clean, canonical hypervectors from the codebook that are geometrically closest to the noisy target. These returned hypervectors are the final, denoised answer to the original compositional query.7

Task 2: Evolving the doesNotUnderstand_ Cognitive Cascade

The system's primary learning loop, the doesNotUnderstand_ protocol, will be refactored to intelligently select the most appropriate reasoning strategy for a given problem. This creates a "cognitive cascade" that prioritizes efficiency and determinism.

Step 1 (Algebraic Inquiry): When the protocol is triggered by a capability gap, its first response will be to attempt to solve the problem by formulating and executing a compositional VSA query via the QueryTranslationLayer. This is the preferred path for problems that can be solved by composing existing knowledge.

Step 2 (Semantic Retrieval): If the VSA query fails—for instance, because the necessary ConceptFractals do not yet exist—the system will fall back to the legacy RAG mechanism. It will perform a standard semantic search for relevant ContextFractals (raw experiences) that might contain the answer.

Step 3 (Generative Synthesis): Only if both the algebraic and semantic retrieval methods fail to provide a direct solution will the system invoke the full, computationally expensive LLM-based generative process as the final step.

This cascaded approach fundamentally alters the system's cognitive character. It prioritizes deterministic, efficient, and auditable algebraic reasoning over probabilistic and costly generation, making the system's self-modification process more robust, reliable, and efficient.

A Rigorous Validation Framework

To ensure that the system's evolution constitutes a genuine and measurable improvement, a two-part validation framework will be implemented. This framework moves beyond abstract assertions of progress to provide empirical, falsifiable evidence of the system's enhanced capabilities.25

Protocol 1: The Algebraic Crucible (Property-Based Testing)

This protocol is designed to validate the mathematical correctness of the VSA operations as they are exposed through the MVA's object-oriented Hypervector prototype. Using a library such as hypothesis, a comprehensive suite of property-based tests will be developed. These tests will automatically generate thousands of random Hypervector objects and verify that the core algebraic properties of the VSA model hold true. For example, the tests will confirm that for any two random hypervectors A and B, the result of unbind(bind(A, B), B) is highly similar to A, and that bundle(A, B) is highly similar to bundle(B, A).2 This protocol ensures that the MVA's object-oriented bridge and ZODB persistence layer do not corrupt the underlying mathematical integrity of the VSA algebra.

Protocol 2: The Compositional Gauntlet (Benchmark-Driven Evaluation)

This protocol will quantitatively measure the functional improvement in the system's reasoning capabilities. A bespoke benchmark of complex, multi-hop reasoning questions will be developed. This benchmark will be tailored to the MVA's evolving knowledge domain but will be inspired by the structure of academic datasets designed to test compositional reasoning, such as HotpotQA or NovelHopQA.26 The benchmark will be executed against two versions of the MVA: the legacy RAG-only system and the new VSA-native system. Key performance indicators—including accuracy on multi-hop questions, query latency, and the rate of successful problem resolution without resorting to LLM generation—will be measured and compared. This will provide empirical, falsifiable evidence of the VSA upgrade's efficacy and a quantitative measure of the system's cognitive evolution.

The following table deconstructs this research plan into a pragmatic, manageable project plan with discrete phases, clear objectives, and verifiable deliverables, making the ambitious vision practically achievable.

Conclusion

This research plan provides a comprehensive and actionable roadmap for the next critical stage of the MVA's evolution. By synthesizing the project's extensive history and philosophical underpinnings with a rigorous analysis of the currently forged system, it charts a course that is both ambitious in its vision and pragmatically achievable in its execution. The plan directly addresses the identified gaps between the current implementation and the full architectural intent, providing a clear path to bridge them.

The proposed architecture is not merely an aggregation of features but a deeply integrated, philosophically coherent system. The completed three-tiered memory substrate will physically embody the system's experience of time, resolving the "Temporal Paradox." The transactional saga coordinator will extend the "Transaction as the Unit of Thought" principle to a complex, heterogeneous storage landscape, guaranteeing data integrity. The Mnemonic Curation Pipeline will transform the system from a passive recorder of experience into an active learner that forges its own understanding.

Most significantly, the VSA-native cognitive core, built upon the foundation of the existing RAG infrastructure, represents an elegant and efficient evolutionary leap. It repurposes the system's semantic memory as a "cleanup memory" for a powerful algebraic reasoning engine, enabling true compositional thought. The phased, risk-driven development plan ensures that the most critical foundational challenges—resilience and transactional integrity—are solved first, providing a stable substrate for the subsequent integration of these advanced cognitive capabilities. By following this roadmap, the project can successfully transform the MVA from a reactive proof-of-concept into a resilient, continuously learning intelligence, fulfilling its ultimate mandate to create a system capable of directed, cumulative autopoiesis.

Works cited

Incarnating Reason: A Generative Blueprint for a VSA-Native Cognitive Core

VSA Library Research and Development

Dynamic OO Enhancing LLM Understanding

Multi-Persona LLM System Design

MVA Realization: Self-Improving AI Development

MVA Blueprint Evolution Plan

VSA Integration for AI Reasoning

Fractal Memory System Proof of Concept

Forge Script for Tiered Memory System

Co-Creative AI System Design Prompt

Building a Layered Memory System

Evolving Memory for Live Systems

Forge Deep Memory Subsystem Integration

Building TelOS: MVA Research Plan

Self Smalltalk Unified Memory System

Hybrid ZODB-FAISS Contextual Memory Evaluation

Deep Research Plan: FAISS, DiskANN, ZODB

Forge Script: RAG, Backup, Crash Tolerance

A fast DBSCAN clustering algorithm by accelerating neighbor searching using Groups method - ResearchGate, accessed September 10, 2025, https://www.researchgate.net/publication/301483487_A_fast_DBSCAN_clustering_algorithm_by_accelerating_neighbor_searching_using_Groups_method

DBSCAN - Wikipedia, accessed September 10, 2025, https://en.wikipedia.org/wiki/DBSCAN

19 DBSCAN Revisited, Revisited: Why and How You Should (Still) Use DBSCAN, accessed September 10, 2025, https://www.khoury.northeastern.edu/home/vip/teach/DMcourse/2_cluster_EM_mixt/notes_slides/revisitofrevisitDBSCAN.pdf

Abstractive Summarization Evaluation for Prompt Engineering | Request PDF, accessed September 10, 2025, https://www.researchgate.net/publication/374869293_Abstractive_Summarization_Evaluation_for_Prompt_Engineering

Chain-of-event prompting for multi-document summarization by large language models, accessed September 10, 2025, https://www.researchgate.net/publication/378232684_Chain-of-event_prompting_for_multi-document_summarization_by_large_language_models

Prompt Engineering Guide to Summarization - PromptLayer Blog, accessed September 10, 2025, https://blog.promptlayer.com/prompt-engineering-guide-to-summarization/

TelOS Future Development Research Plan

[2507.16403] ReasonVQA: A Multi-hop Reasoning Benchmark with Structural Knowledge for Visual Question Answering - arXiv, accessed September 10, 2025, https://arxiv.org/abs/2507.16403

[2508.13250] Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information - arXiv, accessed September 10, 2025, https://arxiv.org/abs/2508.13250

II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in Visual Question Answering - arXiv, accessed September 10, 2025, https://arxiv.org/html/2402.11058v1

MRKE: The Multi-hop Reasoning Evaluation of LLMs by Knowledge Edition - arXiv, accessed September 10, 2025, https://arxiv.org/html/2402.11924v2

NovelHopQA: Diagnosing Multi-Hop Reasoning Failures in Long Narrative Contexts - arXiv, accessed September 10, 2025, https://arxiv.org/abs/2506.02000

Reasoning Court: Combining Reasoning, Action, and Judgment for Multi-Hop Reasoning, accessed September 10, 2025, https://arxiv.org/html/2504.09781v1

Measuring and Narrowing the Compositionality Gap in Language Models - ACL Anthology, accessed September 10, 2025, https://aclanthology.org/2023.findings-emnlp.378.pdf

Gap Identifier | Current State (Implemented in core_system_vsa.py) | Target State (Defined in Research Corpus) | Impact of Gap | Key Source Documents

Disconnected Triumvirate | Implements L1 (FAISS) and L3 (ZODB) memory tiers only. | A complete three-tiered memory system including a scalable, on-disk L2 archive (DiskANN). | Severely limits scalability; prevents cumulative learning at scale; contradicts the philosophical goal of embodying time in the memory architecture. | 8

Amnesiac Abstraction | Contains a ConceptFractal prototype but no mechanism to create instances. | An autonomous "Mnemonic Curation Pipeline" that uses clustering and summarization to synthesize abstract ConceptFractals from raw ContextFractals. | The VSA engine lacks the symbolic alphabet (ConceptFractal hypervectors) needed for reasoning. The system cannot learn from its experiences. | 8

Inert Reasoning Engine | Provides VSA algebraic primitives (bind, unbind) but no reasoning loop. | A functional QueryTranslationLayer that executes a compositional "unbind -> cleanup" reasoning loop, leveraging the ANN indexes as a cleanup memory. | The system cannot perform compositional, multi-hop reasoning. The central goal of the VSA upgrade is unfulfilled. | 1

Unverified Transactional Heart | Implements 2PC for ZODB-FAISS link only. | Holistic transactional integrity across ZODB, FAISS, DiskANN, and tensor serialization, likely via a transactional saga pattern. | Increased risk of data inconsistency and corruption as system complexity grows, violating the "Transactional Cognition" mandate. | 8

Phase | Objective | Key Tasks | Primary Deliverable | Estimated Duration

1 | Foundational Integrity & Resilience | Implement DiskANN L2 cache with atomic hot-swap. Evolve 2PC manager into a transactional saga coordinator. | A continuously running MVA with a complete, transactionally consistent, three-tiered hybrid memory store. | 3-4 Weeks

2 | Autonomous Learning & Abstraction | Implement accelerated DBSCAN clustering. Develop abstractive summarization prompts. Forge the MemoryCurator agent. | An MVA capable of autonomously learning by synthesizing abstract ConceptFractals from its experiences. | 4-6 Weeks

3 | Compositional Reasoning & Validation | Implement the QueryTranslationLayer and "unbind -> cleanup" loop. Refactor doesNotUnderstand_ into a cognitive cascade. Develop and run validation benchmarks. | A fully functional "intelligence miner" capable of performing and learning from compositional reasoning, with empirically verified performance gains. | 5-7 Weeks