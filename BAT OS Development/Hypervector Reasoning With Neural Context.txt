Synergistic Cognition: Training Hyperdimensional Systems for Conceptual Analogy via Neural Contextualization

Foundational Paradigirms: Vector Symbolic Architectures and Neural Contextualization

The quest to build intelligent systems capable of human-like reasoning necessitates a synthesis of disparate computational paradigms. Historically, artificial intelligence has been characterized by a dichotomy between symbolic approaches, which excel at structured, logical manipulation, and connectionist approaches, which demonstrate powerful learning capabilities from raw data. The user's query probes the frontier where these paradigms converge, asking whether a system rooted in the symbolic algebra of Hyperdimensional Computing can be trained for the sophisticated cognitive task of analogical reasoning by leveraging the contextual prowess of modern neural networks. Answering this question requires a foundational understanding of the two pillars upon which such a hybrid architecture would rest: Vector Symbolic Architectures (VSA), a brain-inspired framework for symbolic computation, and Transformer-based neural networks, the state-of-the-art engine for contextual representation learning. This section establishes the theoretical groundwork for these technologies, detailing their core principles, operational mechanics, and the complementary nature of their strengths and weaknesses, which provides the essential motivation for their integration.

Hyperdimensional Computing (HDC) / Vector Symbolic Architectures (VSA): A Brain-Inspired Algebra for Cognition

Hyperdimensional Computing (HDC), also known and largely interchangeable with the term Vector Symbolic Architectures (VSA), is an emerging computational paradigm inspired by the observation that the brain represents and processes information using vast, high-dimensional patterns of neural activity.1 Rather than relying on traditional scalar values or sequential bit manipulation, HDC/VSA operates on high-dimensional vectors, or "hypervectors," which typically consist of thousands of dimensions (e.g.,

D≥10,000).1 This high dimensionality is not an incidental feature but the very foundation of the paradigm's power, turning the "curse of dimensionality" that plagues many machine learning algorithms into a "blessing of dimensionality".6

Core Principles

The mathematical bedrock of HDC/VSA lies in the geometric properties of high-dimensional spaces. A key property is that two randomly generated vectors in a sufficiently high-dimensional space are almost certain to be nearly orthogonal to each other.1 This quasi-orthogonality means their dot product or cosine similarity will be close to zero. This allows for the creation of a vast number of distinct, non-interfering representations for atomic symbols or concepts from a simple random generation process.7 For example, concepts like

CIRCLE, SQUARE, BLACK, and WHITE can each be assigned a unique, randomly generated 10,000-dimensional hypervector, and these vectors will be mathematically dissimilar from one another, providing a robust basis for a symbolic system.2

Another central principle is the use of a holographic and distributed representation. Information is not localized to specific components of a hypervector but is spread across all its dimensions.1 This redundancy confers remarkable robustness against noise, data corruption, and hardware failures. If a subset of a hypervector's dimensions is altered or lost, the overall information it represents is not catastrophically destroyed but degrades gracefully.1 This property mirrors the resilience of biological neural systems and makes HDC/VSA a compelling candidate for implementation on noisy, energy-efficient, and emerging neuromorphic hardware platforms.2

The VSA Algebra

The true power of HDC/VSA lies in its capacity for symbolic computation through a well-defined set of algebraic operations on hypervectors. These operations allow for the construction of complex, structured representations from atomic ones, with the crucial property that the result of any operation is itself a hypervector of the same dimensionality, enabling recursive composition.9 The three fundamental operations are bundling, binding, and permutation.

Bundling (Superposition, ⊕): This operation is used to create a representation of a set or a superposition of concepts. It is typically implemented as element-wise addition of the component hypervectors, often followed by a normalization or binarization step.8 The resulting bundled hypervector,
Z=A⊕B⊕C, retains information about its constituents in a distributed manner. It is mathematically similar to each of its components (e.g., the cosine similarity between Z and A is high), but it is not identical to any of them.1 This operation embodies the superposition principle, allowing multiple pieces of information to be combined into a single, coherent representation.1

Binding (⊗): This operation is used to create a structured association between two concepts, such as a variable-filler or role-value pair (e.g., binding the role COLOR to the value RED). It is implemented through operations like element-wise multiplication (often circular convolution for real-valued vectors or XOR for binary vectors).8 Unlike bundling, the result of a binding operation,
C=A⊗B, is a new hypervector that is dissimilar (i.e., nearly orthogonal) to both of its components, A and B.9 This property is essential for creating distinct, non-interfering structured representations. Binding is a powerful tool for addressing the "binding problem" in traditional connectionist models—the challenge of representing which features belong to which objects when multiple objects are present in a scene.8 The binding operation is typically invertible, meaning one can recover one of the original vectors if the other is known (e.g.,
A≈C⊗B−1).1

Permutation (ρ): This operation systematically reorders the components of a hypervector, often through a cyclic shift.1 A permuted hypervector,
ρ(A), is dissimilar to the original vector, A, but crucially, the permutation operation preserves the distance to any other vector in the space (i.e., the distance between ρ(A) and ρ(B) is the same as the distance between A and B). This property makes permutation invaluable for encoding ordered sequences. For instance, the sequence "A then B" can be represented as A⊕ρ(B), which is distinct from the representation for "B then A," B⊕ρ(A).8 Permutation is also used to create distinct role vectors from a single seed vector, ensuring that roles like
AGENT and PATIENT are orthogonal without needing to generate entirely new random vectors.8

Together, these three operations form a powerful and versatile algebra that allows HDC/VSA to construct, manipulate, and query complex symbolic structures—such as sets, sequences, and key-value pairs—entirely within a high-dimensional vector space.13

Neural Contextualization: The Rise of Transformer-Based Embeddings

While HDC/VSA provides a robust framework for symbolic reasoning, its traditional implementations often rely on randomly generated atomic hypervectors, which lack any inherent semantic grounding in real-world data.9 In parallel, the field of natural language processing (NLP) has been revolutionized by a class of models that excel at precisely this task: learning deeply semantic, context-rich representations from vast amounts of unstructured text. The pinnacle of this development is the Transformer architecture.

From Static to Dynamic Representations

Early successes in representing words as vectors, such as Word2Vec and GloVe, produced static embeddings. These models assigned a single, fixed vector to each word in the vocabulary, learned from its co-occurrence statistics across a large corpus.15 While a significant advance, this approach was fundamentally limited by its inability to handle polysemy—the fact that a word can have different meanings in different contexts. For example, the word "bank" would have the exact same vector representation in "the river bank" and "the bank account," failing to capture the distinct semantic nuances.15

The Transformer architecture, introduced in the paper "Attention Is All You Need," solved this problem by creating dynamic, contextual embeddings.17 Instead of a fixed dictionary of word vectors, a Transformer generates a unique vector representation for each word every time it appears, a representation that is computationally derived from the specific context in which it is used.

The Transformer Architecture and Self-Attention

The Transformer is a neural network architecture designed for processing sequential data, such as text, but it dispenses with the recurrent connections of its predecessors (like RNNs and LSTMs).17 This allows it to process all tokens in a sequence in parallel, leading to significant gains in training efficiency.17 The core innovation that enables this is the

self-attention mechanism.15

The self-attention mechanism allows the model to weigh the importance of all other words in the input sequence when processing a given word. The process can be broken down as follows:

Input Embeddings: The input text is first tokenized (broken into words or subwords), and each token is mapped to an initial, static embedding vector. A positional encoding is added to this embedding to give the model information about the token's position in the sequence.18

Query, Key, and Value Projections: For each token's embedding, the model learns three separate weight matrices to project it into three different vectors: a Query (Q), a Key (K), and a Value (V).16 The Query vector can be thought of as representing what the current token is "looking for." The Key vector represents what information the token "offers." The Value vector represents the actual content of the token.

Attention Score Calculation: To determine how much attention a specific token should pay to every other token, its Query vector is multiplied (via dot product) with the Key vectors of all other tokens in the sequence. This produces a set of "attention scores" that quantify the relevance of each token to the current one.16

Normalization and Weighting: These raw scores are scaled and then passed through a softmax function, which converts them into a probability distribution. The resulting values are the attention weights, which sum to 1. These weights dictate how much of each token's Value vector should be incorporated into the current token's new representation.19

Contextualized Output: The final contextualized embedding for a token is a weighted sum of all the Value vectors in the sequence, where the weights are the attention scores just computed. This process is performed for every token in parallel, and is often done multiple times in parallel ("multi-head attention") to allow the model to focus on different types of relationships simultaneously.17

The output of a Transformer layer is a new sequence of vectors, where each vector now represents its corresponding token but is deeply enriched with information from its entire surrounding context.18 By stacking multiple such layers, the model builds progressively more abstract and nuanced representations, capturing complex semantic, syntactic, and logical relationships within the data.16 These final, high-dimensional, continuous-valued vectors are the contextual embeddings that have become the standard for modern NLP.15

The juxtaposition of these two paradigms reveals a profound complementarity. HDC/VSA offers a robust, transparent, and computationally efficient algebra for symbolic reasoning, but its symbols are often ungrounded and randomly generated. Transformers excel at learning dense, semantically rich, and contextually grounded representations from raw data, but their internal reasoning is opaque and statistical rather than explicitly symbolic. This sets the stage for a powerful synthesis: a system where the semantically rich embeddings produced by a Transformer are used as the foundational "atomic" elements for the structured, compositional reasoning of a VSA. Such a hybrid architecture promises to combine the perceptual power of deep learning with the logical rigor of symbolic systems, creating a more holistic and capable form of artificial intelligence.

Architectures of Integration: Bridging Connectionist Learning and Symbolic Reasoning

The theoretical complementarity of Vector Symbolic Architectures and neural networks motivates the development of hybrid architectures that fuse their respective strengths. The central challenge lies in creating a functional interface between the two paradigms—a bridge that allows the semantically rich, continuous-valued embeddings from a neural network to be transformed into the structured, often discrete, hypervectors that the VSA algebra operates on. This section moves from theoretical possibilities to concrete architectural blueprints, examining the technical methodologies for this integration. It details the critical encoding problem, presents a comprehensive case study of IBM's state-of-the-art Neuro-Vector-Symbolic Architecture (NeuroVSA), and explores the broader landscape of emerging hybrid models. This analysis reveals a spectrum of integration strategies, from loosely coupled post-processing layers to deeply co-designed, end-to-end trainable systems.

The Encoding Challenge: Mapping Continuous Embeddings to Discrete Hyperspace

The primary technical hurdle in creating a hybrid system is the interface problem: how to convert the vectors generated by a Transformer—which are dense, continuous-valued, and of moderately high dimension (e.g., 768 to 4096)—into the format required by a VSA, which often uses sparse or dense, binary or bipolar, and hyper-dimensional vectors (D≥10,000).27 This is not merely a format conversion but a transformation of representational space.

The goal is to move beyond the traditional VSA practice of using randomly generated atomic hypervectors. Instead, the aim is to create non-random hypervectors where the geometric relationships in the VSA hyperspace—measured by metrics like cosine similarity or Hamming distance—meaningfully reflect the semantic relationships learned by the neural network in its embedding space.7 Several techniques have been developed to address this challenge:

Random Projection: This is a foundational and straightforward method. A fixed, randomly generated projection matrix, Ω, is used to map the lower-dimensional neural embedding, e, into the higher-dimensional VSA space: H=Ωe. According to the Johnson-Lindenstrauss lemma, such a projection approximately preserves the distances between points. This means that if two neural embeddings are close in their original space, their corresponding hypervectors will be close in the hyperspace.27 While simple and effective at preserving similarity, this method is static; the mapping itself does not adapt during training.

Quantization and Binarization: After projection, the resulting hypervector H is typically continuous-valued. To leverage the computational efficiency of VSA operations like element-wise XOR, it is often necessary to convert H into a binary or bipolar format. A simple method is to apply a sign function: Hbinary​=sign(H), which maps positive values to +1 and negative values to -1. While computationally efficient, this quantization step can lead to a loss of information and a degradation in accuracy.31 More sophisticated techniques aim to minimize this loss, for instance by operating on the bits of a quantized model one at a time to dynamically adjust precision based on classification confidence.32

Learnable Encoders: Representing the cutting edge of research, learnable encoders are mappings that are not fixed but are instead trained as part of the overall system, typically using gradient descent. This allows the system to optimize the transformation from embedding space to hyperspace for the specific downstream task.34 The
FLASH model is a prime example of this approach. It proposes learning the statistical distribution from which the projection matrix Ω is sampled. By training the parameters of this distribution, the model effectively adapts the kernel function of the encoder, creating a more suitable and task-specific VSA representation.34 This transforms the encoder from a static pre-processing step into an active, learnable component of the architecture.

Case Study: IBM's Neuro-Vector-Symbolic Architecture (NeuroVSA)

IBM's Neuro-Vector-Symbolic Architecture (NeuroVSA) stands as a landmark implementation of a deeply integrated hybrid paradigm. It was specifically designed to tackle complex abstract reasoning tasks, with Raven's Progressive Matrices (RPM) serving as its primary benchmark and proof of concept.11 NeuroVSA elegantly demonstrates how to combine a neural perception frontend with a VSA reasoning backend into a cohesive, high-performance system.

Architectural Overview

NeuroVSA is composed of two primary modules that communicate through the common language of hypervectors.37 The frontend is a neural network responsible for perception—translating raw visual input into a structured symbolic representation. The backend is a VSA-based engine responsible for reasoning—inferring logical rules from these representations and generating a solution.

The Neuro-Vector Frontend (Perception)

The frontend's main task is to analyze the input images (e.g., the panels of an RPM puzzle) and extract a structured description of their contents. It accomplishes this while directly addressing the "binding problem" inherent in neural networks.11

Feature Extraction: A standard convolutional neural network (CNN), such as a ResNet, processes each image panel to produce a set of feature vectors.38

Symbol Grounding and Binding: The core innovation lies in how these features are structured. The system maintains a pre-defined codebook of atomic hypervectors representing all possible attributes and their values (e.g., HV_color, HV_red, HV_shape, HV_square). The neural network is trained to output probability mass functions (PMFs) over the possible values for each attribute of each object it perceives in the image.38

Compositional Representation: These probabilistic outputs are then used to construct a composite hypervector for the entire scene. For an object identified as likely being a "red square," the system uses the VSA bind operation (⊗) to combine the corresponding codebook vectors: HV_red_square = (HV_color \otimes HV_red) \oplus (HV_shape \otimes HV_square). If multiple objects are present, their individual composite vectors are bundled (⊕) together to form a single hypervector representing the entire scene.11 The neural network is trained end-to-end with a loss function that encourages it to produce outputs that correctly map to this VSA-structured representation.

This process effectively teaches the neural network to "speak VSA," forcing its perceptual output into a format that is immediately amenable to symbolic manipulation.

The Vector-Symbolic Backend (Reasoning)

The backend receives the structured hypervector representations of the RPM context panels from the frontend and performs the abstract reasoning required to solve the puzzle.

Probabilistic Abduction: The core reasoning task is to infer the abstract rule(s) (e.g., Progression, Constant, XOR) that govern the changes between panels in the first two rows of the matrix. Instead of relying on a slow, exhaustive search through a symbolic rule database, NeuroVSA performs probabilistic abduction directly in the hyperspace.37

Rules as VSA Operations: Each potential rule is formulated as a sequence of VSA operations. For example, to test for a Progression rule between panel A and panel B, the system might compute a transformation vector T=B⊗A−1. It then applies this transformation to panel D (Epredicted​=T⊗D) and compares the result to the actual vector for panel E. The similarity between the predicted and actual vectors provides evidence for the Progression rule hypothesis.38

Efficient Inference: Because VSA operations like binding and bundling are computationally inexpensive (often reducible to bitwise operations) and can be performed in parallel, the backend can test many rule hypotheses simultaneously by computing in superposition. This makes the reasoning process orders of magnitude faster than traditional symbolic engines that rely on logical search.36

Performance

The efficacy of this deep integration is demonstrated by NeuroVSA's state-of-the-art performance. End-to-end trained versions of the architecture achieved record-breaking accuracy on standard RPM benchmarks, scoring 87.7% on RAVEN and 88.1% on I-RAVEN.11 This performance significantly surpassed that of pure connectionist models and other neuro-symbolic approaches, providing a powerful validation of the hybrid VSA-NN paradigm for abstract reasoning.

Emerging Hybrid Models and Techniques

The deep integration seen in NeuroVSA represents one point on a spectrum of possible hybrid architectures. Other approaches offer different trade-offs between integration depth, flexibility, and implementation complexity.

Fusing at the Output Layer: A more loosely coupled approach uses HDC as a final layer for classification or model fusion. In this architecture, the output signals of one or more trained neural networks (e.g., the logits just before the final softmax layer) are encoded into binary hypervectors. For a classification task, all hypervectors generated from examples of a single class are bundled together to form a prototype class hypervector. Inference is then performed by finding the class prototype with the highest similarity to a query hypervector.42 This "symbolic consensus" method allows multiple disparate neural networks to be fused into a single, robust ensemble. It also supports lifelong learning, as new information or even new models can be incorporated by simply bundling their output hypervectors into the existing prototypes with minimal overhead.42

HDC for Graph Reasoning: The compositional power of VSA is naturally suited for structured data like graphs. In hybrid GraphHDC models, Graph Neural Networks (GNNs) can be used first to generate rich, context-aware embeddings for nodes and edges. These embeddings are then encoded into atomic hypervectors. VSA operations are subsequently used to reason over the graph's structure. For example, a path through the graph can be represented by binding the hypervector of the starting node with permuted versions of the hypervectors for subsequent nodes and edges: Path=Node1​⊗ρ(Edge1→2​)⊗ρ2(Node2​)….44 This allows for complex structural queries and reasoning to be performed using efficient vector algebra.46

Spiking Neural Networks (SNNs) and HDC: Another promising direction involves combining two distinct brain-inspired paradigms. SNNs model the temporal, event-based nature of biological neurons, making them excellent for processing neuromorphic data. A hybrid architecture can use an SNN as a low-level feature extractor that processes noisy spike trains and a HDC system as a higher-level cognitive layer that performs robust learning and classification on the SNN's output. This creates a multi-layered bio-mimetic system, with the SNN modeling the physical properties of neurons and the HDC modeling the more abstract, functional properties of neural circuits.26

The evolution of these architectures reveals a significant trend. Initially, VSA was a static, designed framework lacking the adaptive learning capabilities of neural networks.9 The power of deep learning, conversely, stems from its end-to-end differentiability, which allows for learning complex functions via gradient descent. The most advanced hybrid models, like NeuroVSA and FLASH, are now bridging this gap by making VSA operations part of a differentiable system. NeuroVSA achieves this by designing a loss function that effectively trains the neural perception module to produce VSA-compatible outputs.37 FLASH goes a step further by making the VSA encoding matrix itself learnable.34 This innovation transforms VSA from a fixed symbolic engine into a dynamic, learnable

neuro-symbolic layer, a powerful new primitive for building intelligent systems that combines the structured reasoning of symbolic AI with the adaptive learning of neural networks.

Realizing Analogical Reasoning in a Hybrid System

Analogical reasoning, the ability to identify and transfer relational structures from a familiar source domain to a novel target domain, is a cornerstone of higher-level cognition.48 It underpins problem-solving, learning, and conceptual abstraction. The query's focus on this specific cognitive function is apt, as it represents a task that is difficult for purely connectionist or purely symbolic systems to master alone. This section applies the hybrid neuro-symbolic architecture to the task of analogical reasoning, demonstrating how the VSA algebra provides a natural syntax for such reasoning and how neural embeddings provide the necessary semantic content. Using the benchmark task of Raven's Progressive Matrices, it will be shown how this synthesis moves beyond simple pattern matching to a more robust, generative form of reasoning.

Formalizing Analogy with VSA Algebra

The structure of a classic four-term analogy, often expressed as "A is to B as C is to D" (or A:B::C:D), can be elegantly formalized using the mathematical operations of VSA.49 The core idea is to represent the relationship,

R, that transforms A into B as a hypervector. This relationship can be isolated using the inverse of the binding operation. If the binding operation is element-wise multiplication (⊗) and the vectors are bipolar (elements are {-1, 1}), then each vector is its own inverse (A−1=A).8 The relationship

R can be approximated by binding B with the inverse of A:

R≈B⊗A−1

Once this relationship vector R has been extracted from the source pair (A,B), it can be applied to the target item C to solve for the unknown D:

D≈C⊗R=C⊗(B⊗A−1)

The resulting hypervector D is a prediction for the missing element. This prediction can then be compared against a set of candidate options by measuring its similarity (e.g., cosine similarity or dot product) to the hypervector of each option.9

This algebraic formulation reveals both the power and the limitation of a pure VSA approach. The power lies in its generality; the same set of vector operations can, in principle, solve any analogy, regardless of the domain. The limitation, however, is profound: for this process to yield a meaningful result, the initial hypervectors for A, B, and C must encode rich and nuanced information about the concepts they represent. If the hypervector for "king" is generated randomly, it has no systematic relationship to a randomly generated vector for "man" or "queen." The VSA algebra can manipulate the symbols, but it cannot imbue them with meaning. This is the critical gap that must be filled by a perception module capable of generating semantically grounded representations—a role perfectly suited for a neural network.

Case Study Revisited: Analogical Reasoning in Raven's Progressive Matrices (RPM)

Raven's Progressive Matrices (RPM) is a canonical benchmark for non-verbal, fluid intelligence and is fundamentally a test of visual analogical reasoning.50 The task requires the test-taker to infer a set of abstract rules or relationships from the first two rows of a 3x3 matrix and then apply those same rules to the third row to determine the missing final panel.53

The NeuroVSA architecture is explicitly designed to solve this form of analogy:

Source Domain Analysis: The VSA reasoning backend analyzes the hypervector representations of the first two rows (the source domain). It performs probabilistic abduction to determine the most likely set of rules (e.g., Progression on the Number attribute, Constant on the Shape attribute). This process of rule inference is equivalent to extracting the relationship vector R in the formal analogy framework.37

Target Domain Application: Once the rules are inferred, the backend applies them to the first two panels of the third row (the target domain) to generate a prediction for the missing panel. For instance, if a Progression rule was identified, it applies the corresponding VSA transformation to the hypervector of the seventh panel to predict the hypervector for the eighth, and then again to predict the missing ninth panel.37

Generative Reasoning: A key strength of this approach is that it is generative. The system does not simply learn a direct mapping from the eight context panels to one of the eight answer choices. Instead, it first constructs an internal representation—a predicted hypervector—of what the correct answer should be. Only then does it compare this generated ideal to the available options to find the closest match.37 This two-step process, involving rule abduction and application before selection, is considered a more robust and human-like form of reasoning, as it is less susceptible to learning superficial correlations in the data.48

The success of this entire reasoning process hinges on the quality of the inputs provided by the neural frontend. The CNN must accurately perceive the visual attributes of the objects in each panel and map them to the correct VSA codebook representations. Any failure in perception—misidentifying a shape, miscounting objects—will provide a faulty input to the reasoning backend, leading to an incorrect conclusion. Thus, the neural network serves as the essential grounding mechanism that connects the abstract, symbolic reasoning of the VSA to the raw perceptual data of the problem.38

Generalizing Beyond Visual Puzzles

The same hybrid architectural principle can be generalized to other forms of analogy, including classic textual and even cross-modal examples.

Textual Analogies: Consider the well-known analogy "king is to man as queen is to what?" A hybrid system would first use a Transformer-based model to generate rich, contextual embeddings for the words "king," "man," and "woman".57 These dense, continuous vectors, which capture the learned semantic relationships from a vast text corpus, would then be encoded into hypervectors. The VSA backend would perform the algebraic operations:
KING \otimes MAN^{-1} \oplus WOMAN. The resulting vector is a prediction for the answer. This vector would then be compared against a codebook of all known concept hypervectors, and the one with the highest similarity (which, if the embeddings are good, should be QUEEN) is selected as the answer.58

Cross-Modal Analogies: The architecture holds the potential to solve even more abstract, cross-modal analogies, such as, "How is a satellite dish analogous to a cat's ear?" This would require a multimodal neural frontend, such as OpenAI's CLIP, which is trained to map both images and text into a shared embedding space. The frontend would generate an embedding for an image of a satellite dish and an image of a cat's ear. These embeddings would be mapped to hypervectors. The VSA backend could then attempt to find a relationship vector R that maps one to the other, potentially by unbinding shared functional attributes like RECEIVE_SIGNAL or FOCUS_WAVE.

In all these cases, the core principle remains the same. The neural network acts as a powerful perception and semantic extraction engine, taking raw, unstructured data (images, text, etc.) and converting it into meaningful vector representations. This process grounds the system in the rich statistical patterns of the world. The VSA then provides a formal, syntactic engine for manipulating these representations according to the rules of logic and analogy. The neural embeddings provide the semantics, while the VSA algebra provides the syntax for reasoning. This fusion allows the system to perform meaningful symbolic manipulation on concepts that are not pre-programmed but are learned directly from data.

The Pursuit of Conceptual Understanding

The ultimate goal articulated in the query is for the proposed system to achieve "conceptual understanding." This is the most ambitious and philosophically fraught aspect of the inquiry, as "understanding" is a notoriously difficult concept to define, let alone measure, in the context of artificial intelligence.28 This section dissects this notion, arguing that a functional definition of understanding in AI must be tied to the ability to abstract and generalize concepts across varied contexts.59 It then evaluates how the hybrid VSA-NN architecture measures up to this standard, particularly in contrast to the dominant paradigm of Large Language Models (LLMs). This comparison reveals a fundamental divergence in architectural philosophy—a choice between scaling statistical pattern matchers and explicitly building systems that operate on higher-level conceptual representations.

Defining and Measuring "Understanding" in AI

The debate over whether AI systems "understand" often devolves into semantic arguments about consciousness and subjective experience. For the purposes of a technical evaluation, it is more productive to focus on a functional definition: an AI system demonstrates understanding of a concept to the degree that it can use that concept flexibly, robustly, and generatively in novel contexts.59 This moves beyond mere pattern recognition or interpolation within a training distribution and toward the ability to generalize—a key marker of human intelligence.

To this end, the AI research community has developed increasingly sophisticated benchmarks designed to probe for deeper reasoning and abstraction capabilities, moving beyond simple accuracy on classification tasks 60:

Abstraction and Reasoning Corpus (ARC): This benchmark presents a collection of "few-shot" visual reasoning puzzles. An AI must observe a small number of input-output examples that demonstrate an abstract rule and then apply that rule to a new input. Success on ARC requires human-like intuition and the ability to form abstract concepts from very limited data.59

GPQA (A Graduate-Level Google-Proof Q&A Benchmark): This dataset consists of expert-level, multiple-choice questions in science domains that are designed to be difficult for even experts to answer using standard web search tools. It tests for deep, integrated knowledge and the ability to reason from first principles rather than retrieving memorized facts.61

MMLU (Massive Multitask Language Understanding): This benchmark evaluates a model's breadth of knowledge and problem-solving ability across 57 diverse academic and professional subjects, from elementary mathematics to law and ethics.61

These benchmarks provide a more rigorous yardstick for "understanding" by testing for generalization, abstraction, and deep reasoning—qualities that a simple pattern-matching system would lack.

VSA vs. LLMs: Two Paths to Representing Concepts

The hybrid VSA-NN architecture and Large Language Models represent two fundamentally different approaches to encoding and manipulating concepts.

LLMs as Statistical Concept Models: LLMs, built on the Transformer architecture, represent concepts implicitly and statistically. An LLM's "understanding" of a concept like "justice" is encoded in the complex web of statistical probabilities connecting the token "justice" to countless other tokens and phrases across its massive training corpus.23 This distributional hypothesis—that meaning is determined by context—allows LLMs to achieve remarkable fluency and performance on a wide range of tasks. However, this understanding is a byproduct of predicting the next token; it is not explicitly structured. This can lead to brittleness, non-human-like errors, and a documented struggle with abstract concepts compared to concrete, physical ones.28 The reasoning process is also opaque, residing within billions of uninterpretable weights.2

VSA as Compositional Concept Models: In contrast, a VSA-based system represents concepts explicitly and compositionally. A complex concept is deliberately constructed from simpler, atomic concepts using the VSA algebra. For example, a hypervector for a specific event like JOHN GAVE THE BOOK TO MARY could be constructed as: (AGENT \otimes JOHN) \oplus (ACTION \otimes GAVE) \oplus (PATIENT \otimes BOOK) \oplus (RECIPIENT \otimes MARY). This representation is transparent; one can query the resulting hypervector to deconstruct its components and understand the reasoning path. This inherent structure provides a foundation for systematic and interpretable reasoning.2 Furthermore, the holographic nature of hypervectors makes these representations highly robust to noise, a significant advantage over the often-brittle nature of neural networks.2

Convergent Evolution: Large Concept Models (LCMs) and SONAR Embeddings

The limitations of token-based LLMs have spurred research into alternative architectures that seek to operate at a higher level of semantic abstraction, a path that shows a remarkable convergence with the goals of VSA-based systems. This new direction is embodied by Large Concept Models (LCMs).25

Thinking in Concepts, Not Tokens: The core idea behind LCMs is to shift the fundamental unit of operation from a single token to a more meaningful semantic unit, typically a sentence or a coherent phrase, which the model treats as a "concept".25 Instead of autoregressively predicting the next token, an LCM predicts the vector embedding of the next sentence.25 This approach aims to better mimic human thought, which operates on ideas and concepts rather than individual words in isolation.25

SONAR Embeddings: The enabling technology for this shift is a powerful sentence encoder called SONAR (Sentence-level multimOdal and laNguage-Agnostic Representations).66 SONAR is a neural model trained to map sentences from over 200 languages—and even speech—into a single, shared, fixed-size (1024-dimensional) embedding space.66 The crucial property of this space is that sentences with the same semantic meaning will have vectors that are geometrically close to each other, regardless of their original language or modality (text vs. speech). For example, the English sentence "The cat is on the mat" and its French translation "Le chat est sur le tapis" would be mapped to nearly identical vectors in the SONAR space.65 This provides a powerful, language-agnostic representation of concepts.

SONAR-LLM: A recent architectural innovation, SONAR-LLM, refines the LCM approach. It is a decoder-only Transformer that "thinks" by autoregressively predicting the next SONAR sentence embedding. However, for training, it uses a frozen SONAR decoder to translate this predicted sentence embedding back into a probability distribution over tokens. The model is then trained with a standard token-level cross-entropy loss.70 This hybrid objective combines the semantic abstraction of operating on sentence-level concepts with the stability and effectiveness of likelihood-based training from traditional LLMs, representing a significant step toward more conceptually grounded language models.70

The emergence of LCMs and SONAR reveals a critical trend in AI: a move away from processing surface-level statistical patterns (tokens) toward manipulating more abstract, meaningful units (VSA's compositional symbols, SONAR's sentence-level embeddings). The VSA-NN hybrid architecture achieves this through an explicit, engineered algebra, while the LCM approach achieves it through a learned, continuous semantic space. Both point toward a future where AI reasoning is less about statistical correlation and more about conceptual manipulation.

The hybrid VSA-NN system is uniquely positioned to bridge these worlds and achieve a more robust form of conceptual understanding. It can leverage the power of Transformer-based models to generate grounded, contextual concepts from raw data, and then use the transparent, systematic, and compositional algebra of VSA to reason over them. An LLM might fail a novel analogy because the specific pattern of tokens has not appeared in its training data. A classic VSA system would fail because its random symbols are semantically empty. The hybrid system overcomes both limitations. Its neural frontend can understand novel concepts from context and generate meaningful embeddings, while its VSA backend can apply general-purpose algebraic rules for analogy that depend on the structure of the relationship, not on prior experience with the specific components. This powerful combination of learned semantics and generalized symbolic syntax offers a more plausible and robust path toward the flexible, abstract conceptual manipulation that characterizes genuine understanding.

Synthesis and Future Trajectories

The analysis of Vector Symbolic Architectures, neural contextualization, and their integration into hybrid systems provides a clear and affirmative answer to the central query. The development of an AI system capable of analogical reasoning and conceptual understanding is not only theoretically possible but represents a vibrant and highly promising frontier in artificial intelligence research. State-of-the-art models have already demonstrated the viability of this approach, establishing a powerful proof of concept and charting a course toward more robust, interpretable, and human-like AI. This concluding section synthesizes the findings of the report, reiterates the key advantages of the hybrid paradigm, and outlines the critical challenges and future research directions that will shape the next generation of neuro-symbolic systems.

Conclusion: A Resounding "Yes"

It is unequivocally possible to train a hypervector-based analogical reasoning system that achieves a meaningful level of conceptual understanding by using a neural network approach for context gathering. The feasibility of this paradigm is no longer a matter of speculation but is supported by concrete architectural blueprints and empirical results from leading research institutions.

Viability and Proof of Concept: Architectures like IBM's NeuroVSA provide a compelling proof of concept. By successfully solving complex abstract reasoning tasks like Raven's Progressive Matrices with record-breaking accuracy, these models demonstrate that a deep integration of neural perception and VSA-based symbolic reasoning is not only functional but can outperform both pure connectionist and other neuro-symbolic approaches.11

A Direct Path to Conceptual Understanding: The hybrid, neuro-symbolic architecture offers a more direct and robust path toward conceptual understanding than purely connectionist models like LLMs. Its fundamental strength lies in the synergy between its components. The neural network frontend grounds the system's symbols in rich, contextual, and semantically meaningful representations learned from data. The VSA backend then provides a formal, transparent, and computationally efficient algebra for manipulating these grounded symbols.35 The system does not merely learn statistical correlations between tokens; it learns to represent concepts in a structured, compositional format that directly supports the algebraic manipulation required for abstract thought and analogy. This mirrors the cognitive process of separating perception from reasoning, a hallmark of fluid intelligence.

Key Advantages of the Hybrid Paradigm

The synthesis of neural networks and VSA yields a system with a unique and powerful set of attributes that address the core limitations of each paradigm in isolation.

Synergy of Semantics and Syntax: The architecture achieves a true "best of both worlds" synthesis. Neural networks provide the semantics, learning the meaning of concepts from vast, unstructured data. VSA provides the syntax, a formal set of rules for composing and manipulating these concepts in a logical and structured manner.78 This combination allows for meaningful reasoning about learned, real-world concepts.

Efficiency and Robustness: The reasoning component of the hybrid system is remarkably efficient. VSA operations are computationally lightweight, often reducing to simple bitwise logic (e.g., XOR) and additions, which are far less demanding than the massive matrix multiplications of large Transformers or the exhaustive searches of traditional symbolic engines.26 Furthermore, the holographic, distributed nature of hypervectors provides inherent robustness to noise, hardware faults, and data corruption, leading to graceful degradation rather than catastrophic failure.2

Interpretability and Transparency: A significant advantage over "black box" models like LLMs is the interpretability of the reasoning process. Because VSA operations are well-defined and often reversible, an analyst can inspect the intermediate hypervectors and the algebraic steps taken by the system to understand how it arrived at a conclusion. This transparency is crucial for building trustworthy, verifiable, and debuggable AI systems, especially in critical applications.2

Future Research Directions and Open Challenges

While the promise of the hybrid VSA-NN paradigm is immense, several key challenges and research directions must be pursued to realize its full potential.

Advanced Encoding Schemes: The interface that maps neural embeddings to hypervectors remains the most critical and fertile area for innovation. Future research must move beyond static random projections and focus on developing more sophisticated, end-to-end learnable encoders. Techniques like those pioneered by the FLASH model, which adapt the encoding process itself, are essential for creating high-fidelity VSA representations from complex, dynamic contexts with minimal information loss.34

Scaling to Natural Language and Open Domains: While models like NeuroVSA have proven their mettle on constrained visual reasoning tasks, a grand challenge is scaling this architecture to the unbounded complexity and ambiguity of natural language. This will require developing methods to create and manage VSA codebooks for a vast vocabulary of linguistic concepts, entities, and relational structures, and training neural frontends to map free-form text into these structured representations.

New Benchmarks for Conceptual Analogy: The field requires more comprehensive benchmarks that test for deep conceptual reasoning beyond existing tests like RPM or simple A:B :: C:D word analogies. These new benchmarks should probe for more abstract, cross-modal, and metaphorical reasoning, pushing systems to demonstrate a more profound and flexible form of conceptual understanding.

Hardware Co-Design: The computational properties of VSA—highly parallel, simple bitwise operations—are an excellent match for emerging hardware paradigms like in-memory computing and neuromorphic chips.2 Future work should focus on the co-design of hybrid VSA-NN software with specialized hardware architectures. Such a synergistic approach could unlock orders-of-magnitude improvements in energy efficiency and processing speed, making powerful reasoning systems viable for deployment on edge devices with limited resources.31

Integration with Large Concept Models: An exciting and speculative frontier is the potential fusion of the two conceptual paradigms discussed in this report. A next-generation architecture could use a Large Concept Model with SONAR embeddings as its frontend. This would leverage the broad world knowledge and multimodal capabilities of a massive pre-trained model to generate high-level, sentence-based concept vectors. These vectors could then be fed into a VSA backend, which would apply its rigorous, compositional algebra to perform complex, multi-step reasoning over these learned concepts. Such a system could potentially combine the vast, implicit knowledge of an LLM with the explicit, transparent, and robust reasoning of a symbolic VSA, representing a significant step toward artificial general intelligence.

Works cited

Hyperdimensional computing in biomedical sciences: a brief review ..., accessed September 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC12192801/

Hyperdimensional computing - Wikipedia, accessed September 16, 2025, https://en.wikipedia.org/wiki/Hyperdimensional_computing

Vector Symbolic Architecture (VSA) Provides Cognitive Processing (AI) at the Edge, accessed September 16, 2025, https://www.sto.nato.int/document/vector-symbolic-architecture-vsa-provides-cognitive-processing-ai-at-the-edge/

A Survey on Hyperdimensional Computing aka Vector Symbolic Architectures, Part I: Models and Data Transformations, accessed September 16, 2025, https://redwood.berkeley.edu/wp-content/uploads/2022/11/2022_CSUR_survey_HDCVSA_part_1.pdf

Introduction to Hyperdimensional Computing, accessed September 16, 2025, https://www.hyperdimensionalcomputing.ai/hdc-intro/posts/hdc-intro/

An Introduction to Hyperdimensional Computing for Robotics - Redwood Center for Theoretical Neuroscience, accessed September 16, 2025, https://redwood.berkeley.edu/wp-content/uploads/2021/08/Neubert2019_Article_AnIntroductionToHyperdimension.pdf

Vector Symbolic Architectures as a Computing Framework for Emerging Hardware - PMC, accessed September 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC10588678/

Hyperdimensional Computing, accessed September 16, 2025, https://www.hd-computing.com/

Learning Vector Symbolic Architectures | Research | Automation Technology - TU Chemnitz, accessed September 16, 2025, https://www.tu-chemnitz.de/etit/proaut/en/research/vsa.html

Overview of different HD Computing/VSA models* | Redwood, accessed September 16, 2025, https://redwood.berkeley.edu/wp-content/uploads/2021/08/Module2_VSA_models_slides.pdf

A neuro-vector-symbolic architecture for solving Raven's progressive matrices | Request PDF - ResearchGate, accessed September 16, 2025, https://www.researchgate.net/publication/369117718_A_neuro-vector-symbolic_architecture_for_solving_Raven's_progressive_matrices

Developing a Foundation of Vector Symbolic Architectures Using Category Theory - arXiv, accessed September 16, 2025, https://arxiv.org/html/2501.05368v1

Hyperdimensional Computing: - Redwood Center for Theoretical Neuroscience, accessed September 16, 2025, https://redwood.berkeley.edu/wp-content/uploads/2018/01/kanerva2009hyperdimensional.pdf

An Introduction to Vector Symbolic Architectures and Hyperdimensional Computing - TU Chemnitz, accessed September 16, 2025, https://www.tu-chemnitz.de/etit/proaut/workshops_tutorials/vsa_ecai20/rsrc/vsa_slides.pdf

What are transformer-based embeddings and why are they important? - Milvus, accessed September 16, 2025, https://milvus.io/ai-quick-reference/what-are-transformerbased-embeddings-and-why-are-they-important

Understanding Contextual Embedding in Transformers · - dasarpAI, accessed September 16, 2025, https://main--dasarpai.netlify.app/dsblog/understanding-contextual-embedding-in-transformers/

Transformer (deep learning architecture) - Wikipedia, accessed September 16, 2025, https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)

How Transformers Work: A Detailed Exploration of Transformer Architecture - DataCamp, accessed September 16, 2025, https://www.datacamp.com/tutorial/how-transformers-work

What is a Transformer Model? - IBM, accessed September 16, 2025, https://www.ibm.com/think/topics/transformer-model

LLM Transformer Model Visually Explained - Polo Club of Data Science, accessed September 16, 2025, https://poloclub.github.io/transformer-explainer/

A Beginner's Guide to Vector Embeddings | TigerData, accessed September 16, 2025, https://www.tigerdata.com/blog/a-beginners-guide-to-vector-embeddings

What is Vector Embedding? | IBM, accessed September 16, 2025, https://www.ibm.com/think/topics/vector-embedding

What Large Language Models Know - UVA School of Data Science, accessed September 16, 2025, https://datascience.virginia.edu/news/what-large-language-models-know

Hyperdimensional computing: a fast, robust and interpretable paradigm for biological data, accessed September 16, 2025, https://arxiv.org/html/2402.17572v1

LCMs vs. LLMs: Why Concept-Based AI May Be the Key to AGI | by ..., accessed September 16, 2025, https://prajnaaiwisdom.medium.com/lcms-vs-llms-why-concept-based-ai-may-be-the-key-to-agi-bc11e1aac2a6

Memory-inspired spiking hyperdimensional network for robust online learning - PMC, accessed September 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9090930/

The transformative potential of vector symbolic architecture for ..., accessed September 16, 2025, https://www.spiedigitallibrary.org/conference-proceedings-of-spie/13206/1320612/The-transformative-potential-of-vector-symbolic-architecture-for-cognitive-processing/10.1117/12.3030949.full

[R] The Debate Over Understanding in AI's Large Language Models - Reddit, accessed September 16, 2025, https://www.reddit.com/r/MachineLearning/comments/125uxab/r_the_debate_over_understanding_in_ais_large/

Learning from Hypervectors: A Survey on Hypervector Encoding, accessed September 16, 2025, https://arxiv.org/abs/2308.00685

(PDF) Learning from Hypervectors: A Survey on Hypervector Encoding - ResearchGate, accessed September 16, 2025, https://www.researchgate.net/publication/372827538_Learning_from_Hypervectors_A_Survey_on_Hypervector_Encoding

Stochastic-HD: Leveraging Stochastic Computing on the Hyper-Dimensional Computing Pipeline - PMC, accessed September 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9189416/

INTEGRATING SIMCLR EMBEDDINGS FOR OPTIMIZED NEURAL HYPERDIMENSIONAL DATA CLUSTERING. - ScholarWorks, accessed September 16, 2025, https://scholarworks.calstate.edu/downloads/ws859q20c

An encoding framework for binarized images using hyperdimensional computing - PMC, accessed September 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC11214273/

Hyperdimensional computing with holographic and adaptive encoder - Frontiers, accessed September 16, 2025, https://www.frontiersin.org/journals/artificial-intelligence/articles/10.3389/frai.2024.1371988/full

Neuro-Vector-Symbolic Architecture - IBM Research, accessed September 16, 2025, https://research.ibm.com/projects/neuro-vector-symbolic-architecture

A Neuro-vector-symbolic Architecture for Solving Raven's Progressive Matrices | DeepAI, accessed September 16, 2025, https://deepai.org/publication/a-neuro-vector-symbolic-architecture-for-solving-raven-s-progressive-matrices

Solving Raven's Progressive Matrices via a Neuro-vector-symbolic Architecture - CEUR-WS, accessed September 16, 2025, https://ceur-ws.org/Vol-3432/paper43.pdf

A Neuro-vector-symbolic Architecture for Solving Raven's Progressive Matrices - Temple CIS, accessed September 16, 2025, https://cis.temple.edu/tagit/presentations/A%20Neuro-vector-symbolic%20Architecture%20for%20Ravens%20Progressive%20Matrices.pdf

Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture - arXiv, accessed September 16, 2025, https://arxiv.org/html/2501.11896v2

(PDF) A Neuro-vector-symbolic Architecture for Solving Raven's Progressive Matrices, accessed September 16, 2025, https://www.researchgate.net/publication/359130257_A_Neuro-vector-symbolic_Architecture_for_Solving_Raven's_Progressive_Matrices

A Neuro-vector-symbolic Architecture for Solving Raven's Progressive Matrices - IRIS - Università di Bologna, accessed September 16, 2025, https://cris.unibo.it/retrieve/fb8c47c8-9856-4e7b-87bd-bdf9dc64c770/2203.04571v2.pdf

Gluing Neural Networks Symbolically Through Hyperdimensional Computing - OpenReview, accessed September 16, 2025, https://openreview.net/forum?id=XbJd1jRZd3&referrer=%5Bthe%20profile%20of%20Peter%20Sutor%5D(%2Fprofile%3Fid%3D~Peter_Sutor1)

Gluing Neural Networks Symbolically Through Hyperdimensional Computing - arXiv, accessed September 16, 2025, https://arxiv.org/pdf/2205.15534

Symbolic Graph Intelligence: Hypervector Message Passing for Learning Graph-Level Patterns with Tsetlin Machines - arXiv, accessed September 16, 2025, https://arxiv.org/html/2507.16537v1

Hyperdimensional Computing for Graphs Machine Learning | by Jerry Tang - Medium, accessed September 16, 2025, https://medium.com/stanford-cs224w/hyperdimensional-computing-for-graphs-machine-learning-56b381ebbc27

MissionHD: Data-Driven Refinement of Reasoning Graph Structure through Hyperdimensional Causal Path Encoding and Decoding - arXiv, accessed September 16, 2025, https://arxiv.org/html/2508.14746v1

I Created An HDC Based Neural Network: Trainable Hyper vectors - YouTube, accessed September 16, 2025, https://www.youtube.com/watch?v=glGctCiO-Ic

Understanding the What and When of Analogical Reasoning Across Analogy Formats: An Eye‐Tracking and Machine Learning Approach - PubMed Central, accessed September 16, 2025, https://pmc.ncbi.nlm.nih.gov/articles/PMC9786648/

Analogy and Analogical Reasoning - Stanford Encyclopedia of Philosophy, accessed September 16, 2025, https://plato.stanford.edu/entries/reasoning-analogy/

Raven's Progressive Matrices - Wikipedia, accessed September 16, 2025, https://en.wikipedia.org/wiki/Raven%27s_Progressive_Matrices

Decoding Raven's Progressive Matrix: A Knowledge-Based AI Journey | by Jawahar Patgiri, accessed September 16, 2025, https://medium.com/@jawaharjyotpatgiri/decoding-ravens-progressive-matrix-a-knowledge-based-ai-journey-f6e31eb11b27

[2302.04238] Computational Models of Solving Raven's Progressive Matrices: A Comprehensive Introduction - arXiv, accessed September 16, 2025, https://arxiv.org/abs/2302.04238

Measuring Raven's Progressive Matrices Combining Eye-Tracking Technology and Machine Learning (ML) Models - MDPI, accessed September 16, 2025, https://www.mdpi.com/2079-3200/12/11/116

[2401.09966] Towards Generative Abstract Reasoning: Completing Raven's Progressive Matrix via Rule Abstraction and Selection - arXiv, accessed September 16, 2025, https://arxiv.org/abs/2401.09966

A Bayesian Model of Rule Induction in Raven's Progressive Matrices - Computational Cognitive Science Lab, accessed September 16, 2025, https://cocosci.princeton.edu/tom/papers/Little_WMCRavens.pdf

Towards Generative Abstract Reasoning: Completing Raven's ..., accessed September 16, 2025, https://openreview.net/forum?id=IcR1OOFzxm

The Unreasonable Effectiveness Of Neural Network Embeddings | by Peter Gao | Aquarium Learning | Medium, accessed September 16, 2025, https://medium.com/aquarium-learning/the-unreasonable-effectiveness-of-neural-network-embeddings-93891acad097

How do AI models perform analogical reasoning? - Milvus, accessed September 16, 2025, https://milvus.io/ai-quick-reference/how-do-ai-models-perform-analogical-reasoning

Evaluating Understanding on Conceptual Abstraction Benchmarks (Conference Paper), accessed September 16, 2025, https://par.nsf.gov/biblio/10350336-evaluating-understanding-conceptual-abstraction-benchmarks

The Race to Measure Machine Minds: Understanding AI Benchmarks - Sandgarden, accessed September 16, 2025, https://www.sandgarden.com/learn/benchmarks

Benchmarks in AI: Measuring and Comparing Model Performance - Forward Future AI, accessed September 16, 2025, https://www.forwardfuture.ai/p/benchmarks-in-artificial-intelligence-measuring-comparing-understanding

Enhancing Analogical Reasoning in the Abstraction and Reasoning Corpus via Model-Based RL - arXiv, accessed September 16, 2025, https://arxiv.org/html/2408.14855v1

Benchmarks: How do we evaluate and compare LLMs and Multimodals Models? - Medium, accessed September 16, 2025, https://medium.com/@daniellefranca96/benchmarks-how-do-we-evaluate-and-compare-llms-and-multimodals-models-105cec4f2ad4

CONCEPT UNDERSTANDING IN LARGE LANGUAGE MODELS: AN EMPIRICAL STUDY - OpenReview, accessed September 16, 2025, https://openreview.net/pdf?id=losgEaOWIL7

SONAR Embeddings Archives - Ajith's AI Pulse, accessed September 16, 2025, https://ajithp.com/tag/sonar-embeddings/feed/

NLP 13 SONAR Embeddings - Kaggle, accessed September 16, 2025, https://www.kaggle.com/code/selcukcan/nlp-13-sonar-embeddings

SONAR Explained. Sentence-Level Multimodal and… | by Bryan Teo - Medium, accessed September 16, 2025, https://medium.com/@bteo/sonar-explained-a9c99f1376e8

SONAR, a new multilingual and multimodal fixed-size sentence embedding space, with a full suite of speech and text encoders and decoders. - GitHub, accessed September 16, 2025, https://github.com/facebookresearch/SONAR

facebook/SONAR - Hugging Face, accessed September 16, 2025, https://huggingface.co/facebook/SONAR

SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens | OpenReview, accessed September 16, 2025, https://openreview.net/forum?id=755wKpz1s4

AIRI Blog - AIRI Institute, accessed September 16, 2025, https://airi.net/blog/SONAR-LLM

SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens - arXiv, accessed September 16, 2025, https://arxiv.org/html/2508.05305v1

SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens - arXiv, accessed September 16, 2025, https://www.arxiv.org/pdf/2508.05305

SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens - OpenReview, accessed September 16, 2025, https://openreview.net/pdf?id=755wKpz1s4

[2508.05305] SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings and Speaks in Tokens - arXiv, accessed September 16, 2025, https://arxiv.org/abs/2508.05305

Symbolic Representation and Learning With Hyperdimensional Computing - Frontiers, accessed September 16, 2025, https://www.frontiersin.org/journals/robotics-and-ai/articles/10.3389/frobt.2020.00063/full

Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents - arXiv, accessed September 16, 2025, https://arxiv.org/html/2407.08516

Enhancing Deep Learning Efficiency: A Hyperdimensional Computing Approach, accessed September 16, 2025, https://escholarship.org/uc/item/4d85d808

Hyperdimensional Computing vs. Neural Networks: Comparing Architecture and Learning Process - arXiv, accessed September 16, 2025, https://arxiv.org/pdf/2207.12932

Hyperdimensional Computing Versus Convolutional Neural Network: Architecture, Performance Analysis, and Hardware Complexity - Khalifa University, accessed September 16, 2025, https://khazna.ku.ac.ae/en/publications/hyperdimensional-computing-versus-convolutional-neural-network-ar

Feature | HDC/VSA | Transformer Architecture

Core Inspiration | Brain's high-dimensional circuits, cognitive models 1 | Statistical patterns in language data 18

Data Representation | High-dimensional (D>10,000), holographic, often binary/bipolar vectors 1 | High-dimensional (D≈103), dense, continuous-valued vectors 18

Core Operations | Algebraic: Binding (⊗), Bundling (⊕), Permutation (ρ) 1 | Neural: Matrix multiplication, Self-attention, Softmax 17

Learning Mechanism | Typically one-shot or few-shot learning by bundling examples 5 | Gradient descent via backpropagation on large datasets 17

Interpretability | High; operations are transparent and often reversible 2 | Low; "black box" nature makes reasoning paths opaque 2

Primary Strength | Robust symbolic reasoning, compositionality, noise tolerance 6 | Learning nuanced, context-aware representations from raw data 15

Primary Weakness | Ungrounded symbols if randomly generated; lacks a native deep learning mechanism 9 | Brittleness, opacity, lack of explicit symbolic structure; computationally intensive 25

Model/Architecture | Perception Module (NN) | Integration Method | Reasoning Module (VSA) | Key Innovation

NeuroVSA (Hersche et al.) | ResNet-based object/attribute detector 38 | NN output is mapped to a VSA codebook; VSA bind/bundle operations structure the representation 11 | VSA-based probabilistic abduction engine for rule inference 37 | Deep, co-designed integration; end-to-end training of perception module guided by VSA logic.

FLASH (Guo et al.) | Generic input | Learnable encoding matrix (trained via gradient descent) maps input features to hypervectors 34 | Standard HDC classifier or regressor | Makes the VSA encoder itself adaptive and optimizable for the task via a differentiable process.

Symbolic Consensus (Sutor et al.) | One or more pre-trained NNs | Output logits of each NN are encoded into binary hypervectors 42 | Bundling operation creates a consensus hypervector for classification | Loose coupling; uses HDC for robust, efficient, and lifelong model fusion and ensembling.

GraphHDC (Various) | Graph Neural Network (GNN) | Node/edge embeddings from GNN are encoded into hypervectors 44 | VSA bind/permute operations encode paths and neighborhoods for structural queries 46 | Extends VSA's compositional power to explicitly reason over graph-structured data.