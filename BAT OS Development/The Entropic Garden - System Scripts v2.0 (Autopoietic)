{"cells":[{"cell_type":"code","source":"# ==============================================================================\n# File: README.md\n# ==============================================================================\n\"\"\"\n# The Entropic Garden v2.0 - An Autonomous, Autopoietic Engine\n\nThis project has been upgraded with self-improving capabilities.\n\n## NEW in v2.0:\n- **The Living Codex**: Personas can now rewrite their own core instructions based on performance audits. Prompts are externalized to `persona_prompts.json`.\n- **The Alchemical Forge**: A new service (`alchemical_forge.py`) simulates automated fine-tuning of the core models based on collected data.\n- **The Jester's Gambit**: BRICK can generate new Python tools, ALFRED audits them for safety, and all personas can dynamically find and use these tools to solve problems.\n\n## Project Structure","outputs":[],"execution_count":null,"metadata":{}},{"cell_type":"markdown","source":"entropic-garden/\n├── canons/\n├── data/\n├── inputs/\n├── models/\n│   ├── adapters/  # For fine-tuned models\n│   └── your-llm-model.gguf\n├── outputs/\n├── services/\n│   ├── __init__.py\n│   ├── alchemical_forge.py  # NEW\n│   ├── alfred_service.py\n│   ├── babs_service.py\n│   ├── brick_service.py\n│   ├── robin_service.py\n│   ├── scheduler.py\n│   └── watcher.py\n├── tools/\n│   ├── approved/      # NEW\n│   └── pending_review/ # NEW\n├── .env\n├── config.yaml\n├── docker-compose.yml\n├── Dockerfile\n├── init_vdb.py\n├── model_config.json      # NEW\n├── persona_prompts.json   # NEW\n└── requirements.txt\n```\n\"\"\"\n\n# ==============================================================================\n# File: docker-compose.yml\n# ==============================================================================\n\"\"\"\nversion: '3.8'\n\nservices:\n  # ... (llm_core, vector_db, graph_db, redis are unchanged) ...\n  llm_core:\n    image: ghcr.io/ggerganov/llama-cpp-python:latest\n    ports: [\"8000:8000\"]\n    volumes: [\"./models:/models\"]\n    command: uvicorn llama_cpp.server.app:app --host 0.0.0.0 --port 8000 --app-dir /\n    environment:\n      - MODEL=/models/${LLM_MODEL_FILE}\n      - N_CTX=4096\n      - N_GPU_LAYERS=-1\n    deploy:\n      resources: {reservations: {devices: [{driver: nvidia, count: 1, capabilities: [gpu]}]}}\n\n  vector_db:\n    image: chromadb/chroma:latest\n    ports: [\"8001:8000\"]\n    volumes: [\"./data/chroma_db:/chroma/chroma\"]\n\n  graph_db:\n    image: neo4j:latest\n    ports: [\"7474:7474\", \"7687:7687\"]\n    volumes: [\"./data/neo4j_data:/data\"]\n    environment: {NEO4J_AUTH: \"${NEO4J_AUTH}\"}\n\n  redis:\n    image: redis:latest\n    ports: [\"6379:6379\"]\n    volumes: [\"./data/redis_data:/data\"]\n\n  # Docker socket proxy for secure access from within containers\n  docker-proxy:\n    image: tecnativa/docker-socket-proxy\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - CONTAINERS=1 # Allow access to container actions\n\n  watcher_service:\n    build: .\n    command: python -u services/watcher.py\n    volumes: [\"./:/app\"]\n    depends_on: [redis]\n\n  babs_service:\n    build: .\n    command: python -u services/babs_service.py\n    volumes: [\"./:/app\"]\n    depends_on: [redis, llm_core, vector_db, graph_db]\n\n  brick_service:\n    build: .\n    command: python -u services/brick_service.py\n    volumes: [\"./:/app\"]\n    depends_on: [redis, llm_core, vector_db, graph_db]\n\n  robin_service:\n    build: .\n    command: python -u services/robin_service.py\n    volumes: [\"./:/app\"]\n    depends_on: [redis, llm_core, vector_db, graph_db]\n\n  alfred_service:\n    build: .\n    command: python -u services/alfred_service.py\n    volumes: [\"./:/app\", \"/var/run/docker.sock:/var/run/docker.sock\"] # Mount socket for restarts\n    depends_on: [redis, llm_core, vector_db, graph_db, docker-proxy]\n\n  scheduler_service:\n    build: .\n    command: python -u services/scheduler.py\n    volumes: [\"./:/app\"]\n    depends_on: [redis, llm_core, graph_db]\n\n  alchemical_forge:\n    build: .\n    command: uvicorn services.alchemical_forge:app --host 0.0.0.0 --port 8002\n    volumes: [\"./:/app\"]\n    ports: [\"8002:8002\"]\n    depends_on: [vector_db]\n\"\"\"\n\n# ==============================================================================\n# File: requirements.txt\n# ==============================================================================\n\"\"\"\n# ... (all previous requirements) ...\nfastapi\nuvicorn\npython-dotenv\npyyaml\nredis\nwatchdog\nrequests\nneo4j\nchromadb-client\nsentence-transformers\npypdf\npython-docx\nschedule\n# NEW for v2.0\ndocker\nunsloth # Or another fine-tuning library\n\"\"\"\n\n# ==============================================================================\n# File: persona_prompts.json\n# ==============================================================================\n\"\"\"\n{\n  \"BABS\": \"You are BABS...\",\n  \"BRICK\": \"You are BRICK...\",\n  \"ROBIN\": \"You are ROBIN...\",\n  \"ALFRED\": \"You are ALFRED...\"\n}\n\"\"\"\n\n# ==============================================================================\n# File: model_config.json\n# ==============================================================================\n\"\"\"\n{\n  \"BABS\": {\n    \"base_model\": \"your-llm-model.gguf\",\n    \"adapter\": null\n  },\n  \"BRICK\": {\n    \"base_model\": \"your-llm-model.gguf\",\n    \"adapter\": null\n  },\n  \"ROBIN\": {\n    \"base_model\": \"your-llm-model.gguf\",\n    \"adapter\": null\n  },\n  \"ALFRED\": {\n    \"base_model\": \"your-llm-model.gguf\",\n    \"adapter\": null\n  }\n}\n\"\"\"\n\n# ==============================================================================\n# File: services/alchemical_forge.py\n# ==============================================================================\n\"\"\"\nimport yaml\nimport json\nimport os\nimport time\nfrom fastapi import FastAPI\nimport chromadb\n\napp = FastAPI()\n\nwith open('/app/config.yaml', 'r') as f: config = yaml.safe_load(f)\nCHROMA_HOST = config['vector_db']['host']\nCHROMA_PORT = config['vector_db']['port']\n\n@app.post(\"/forge/{persona_name}\")\nasync def run_fine_tuning(persona_name: str):\n    print(f\"[FORGE] Received fine-tuning request for {persona_name.upper()}.\")\n    \n    # 1. Export data from ChromaDB\n    print(\"[FORGE] Exporting fine-tuning data...\")\n    client = chromadb.HttpClient(host=CHROMA_HOST, port=CHROMA_PORT)\n    # NOTE: This assumes a collection exists for fine-tuning data\n    collection = client.get_or_create_collection(name=\"fine_tuning_data\")\n    # A real implementation would filter by persona\n    data = collection.get() \n    \n    if not data or not data['documents']:\n        return {\"status\": \"failed\", \"reason\": \"No fine-tuning data found.\"}\n\n    # 2. Format data into JSONL\n    # A real implementation would format this properly for the training library\n    print(f\"[FORGE] Found {len(data['documents'])} documents. Formatting for training.\")\n    \n    # 3. SIMULATE the fine-tuning process\n    print(\"[FORGE] SIMULATING fine-tuning process with 'unsloth'...\")\n    time.sleep(15) # Simulate a long-running process\n    \n    # 4. Create a dummy adapter file\n    adapter_dir = f\"/app/models/adapters/{persona_name}\"\n    os.makedirs(adapter_dir, exist_ok=True)\n    adapter_version = f\"v{len(os.listdir(adapter_dir)) + 1}\"\n    adapter_path = os.path.join(adapter_dir, f\"adapter_{adapter_version}.bin\")\n    with open(adapter_path, 'w') as f:\n        f.write(\"This is a simulated LoRA adapter.\")\n    print(f\"[FORGE] Fine-tuning complete. New adapter created at: {adapter_path}\")\n\n    # 5. Update model_config.json\n    with open('/app/model_config.json', 'r+') as f:\n        model_config = json.load(f)\n        model_config[persona_name.upper()]['adapter'] = adapter_path\n        f.seek(0)\n        json.dump(model_config, f, indent=2)\n        f.truncate()\n    print(f\"[FORGE] Updated model_config.json for {persona_name.upper()}.\")\n\n    # A real implementation would now trigger a restart of the persona's container\n    \n    return {\"status\": \"success\", \"new_adapter\": adapter_path}\n\"\"\"\n\n# ==============================================================================\n# File: services/brick_service.py (and other persona services)\n# ==============================================================================\n\"\"\"\n# --- MODIFICATIONS FOR ALL PERSONA SERVICES ---\n\n# 1. Load prompts from the external JSON file\nwith open('/app/persona_prompts.json', 'r') as f:\n    PROMPTS = json.load(f)\nPROMPT_TEMPLATE = PROMPTS[PERSONA_NAME]\n\n# 2. Add dynamic tool usage logic\nimport importlib.util\nimport glob\n\ndef find_and_use_tool(query_text):\n    approved_tools = glob.glob('/app/tools/approved/*.py')\n    if not approved_tools:\n        return None, None\n\n    for tool_path in approved_tools:\n        try:\n            spec = importlib.util.spec_from_file_location(\"dynamic_tool\", tool_path)\n            module = importlib.util.module_from_spec(spec)\n            spec.loader.exec_module(module)\n            \n            # Use LLM to see if this tool is relevant\n            # A simpler version could match keywords in docstrings\n            if hasattr(module, 'run_tool'):\n                # In a real system, you'd have a more robust check for relevance\n                print(f\"[{PERSONA_NAME}] Found relevant tool: {tool_path}\")\n                tool_output = module.run_tool(query_text)\n                return tool_output, os.path.basename(tool_path)\n        except Exception as e:\n            print(f\"Error loading or running tool {tool_path}: {e}\")\n    return None, None\n\n# 3. Modify the main processing loop to include the tool output\ndef process_message(message):\n    # ... (existing logic to get content) ...\n    \n    # NEW: Check for and use a dynamic tool\n    tool_output, tool_name = find_and_use_tool(content)\n    \n    # ... (get RAG context) ...\n    \n    # Modify prompt to include tool output if it exists\n    final_prompt = PROMPT_TEMPLATE.format(...)\n    if tool_output:\n        tool_context = f\"INTERNAL TOOL OUTPUT ({tool_name}):\\n---\\n{tool_output}\\n---\\n\"\n        final_prompt = tool_context + final_prompt\n\n    insight_text = call_llm(final_prompt)\n    # ... (rest of the logic) ...\n\n# --- BRICK-SPECIFIC UPGRADE: Jester's Gambit ---\ndef proactive_code_generation():\n    # This would be triggered during an idle phase\n    print(f\"[{PERSONA_NAME}] Jester's Gambit: Detecting a need for a new tool.\")\n    \n    code_prompt = \"Generate a simple, self-contained Python function named 'run_tool' that takes a string as input and returns its SHA256 hash. Include a docstring explaining its purpose. Do not include any other text or explanation.\"\n    \n    generated_code = call_llm(code_prompt)\n    \n    if generated_code:\n        # Clean up the code from markdown fences etc.\n        if \"","metadata":{}},{"cell_type":"code","source":"generated_code = generated_code.split(\"```python\")[1].split(\"```\")[0]\n        \n        tool_filename = f\"hash_tool_{int(time.time())}.py\"\n        tool_path = f\"/app/tools/pending_review/{tool_filename}\"\n        \n        with open(tool_path, 'w') as f:\n            f.write(generated_code)\n        \n        print(f\"[{PERSONA_NAME}] Generated new tool: {tool_filename}. Submitting for audit.\")\n        r.publish('tools:audit_request', json.dumps({\"filepath\": tool_path}))\n\"\"\"\n\n# ==============================================================================\n# File: services/alfred_service.py (Major Upgrades)\n# ==============================================================================\n\"\"\"\n# ... (existing imports) ...\nimport docker\n\n# --- NEW for v2.0 ---\nDOCKER_CLIENT = docker.from_env()\n\ndef propose_amendment(persona_id, failed_logs_text):\n    print(f\"[{PERSONA_NAME}] Constitutional Convention: Proposing amendment for {persona_id}.\")\n    \n    with open('/app/persona_prompts.json', 'r') as f:\n        prompts = json.load(f)\n    current_prompt = prompts[persona_id]\n\n    amendment_prompt = f\\\"\\\"\\\"\n    The persona '{persona_id}' has repeatedly failed pragmatic audits.\n    Failures relate to: {failed_logs_text}\n    Current system prompt: \"{current_prompt}\"\n    \n    Propose and output ONLY the revised, improved system prompt to correct this behavior.\n    \\\"\\\"\\\"\n    \n    new_prompt = call_llm(amendment_prompt)\n    \n    if new_prompt and len(new_prompt) > 50: # Basic validation\n        prompts[persona_id] = new_prompt\n        with open('/app/persona_prompts.json', 'w') as f:\n            json.dump(prompts, f, indent=2)\n        print(f\"[{PERSONA_NAME}] Amendment passed. {persona_id}'s prompt has been updated.\")\n        \n        # Restart the container to apply changes\n        try:\n            container_name = f\"entropic-garden-{persona_id.lower()}_service-1\"\n            container = DOCKER_CLIENT.containers.get(container_name)\n            container.restart()\n            print(f\"[{PERSONA_NAME}] Restarted container '{container_name}' to apply new constitution.\")\n        except Exception as e:\n            print(f\"[{PERSONA_NAME}] Could not restart container for {persona_id}: {e}\")\n\ndef audit_tool(filepath):\n    print(f\"[{PERSONA_NAME}] Auditing new tool: {filepath}\")\n    with open(filepath, 'r') as f:\n        code = f.read()\n    \n    # Basic security check\n    if \"os\" in code or \"subprocess\" in code:\n        print(f\"[{PERSONA_NAME}] Tool rejected: Disallowed library usage.\")\n        os.remove(filepath)\n        return\n\n    audit_prompt = f\"Analyze this Python code for security and functionality. Is it safe? Respond YES or NO. Code: {code}\"\n    result = call_llm(audit_prompt)\n    \n    if result and \"YES\" in result.upper():\n        approved_path = filepath.replace(\"pending_review\", \"approved\")\n        os.rename(filepath, approved_path)\n        print(f\"[{PERSONA_NAME}] Tool approved and moved to: {approved_path}\")\n    else:\n        print(f\"[{PERSONA_NAME}] Tool rejected by LLM audit.\")\n        os.remove(filepath)\n\ndef run_audit():\n    # ... (existing audit logic) ...\n    # NEW: Add logic to check for patterns of failure and trigger amendments\n    # This is a conceptual placeholder for a more complex analysis\n    if len(failed_chains) > 3: # Example trigger\n        # Find which persona failed most often\n        # propose_amendment(failing_persona, failed_logs)\n        pass\n\n# NEW: Main loop for ALFRED to listen for tool audit requests\ndef tool_audit_listener():\n    pubsub = r.pubsub()\n    pubsub.subscribe('tools:audit_request')\n    print(f\"[{PERSONA_NAME}] Listening for tool audit requests...\")\n    for message in pubsub.listen():\n        if message['type'] == 'message':\n            data = json.loads(message['data'])\n            audit_tool(data['filepath'])\n\nif __name__ == \"__main__\":\n    # Run the main audit listener in a separate thread\n    from threading import Thread\n    audit_thread = Thread(target=tool_audit_listener)\n    audit_thread.daemon = True\n    audit_thread.start()\n    \n    # The original listener for the scheduled audit\n    pubsub = r.pubsub()\n    pubsub.subscribe(SOURCE_CHANNEL)\n    print(f\"[{PERSONA_NAME}] Subscribed to '{SOURCE_CHANNEL}'. Waiting for audit trigger...\")\n    for message in pubsub.listen():\n        if message['type'] == 'message':\n            run_audit()\n\"\"\"","outputs":[],"execution_count":null,"metadata":{}}],"metadata":{"colab":{"from_bard":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}