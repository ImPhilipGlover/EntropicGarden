(BRICK): OPERATIONAL MODE: ARCHITECTURAL DEVELOPMENT - PHASE 2 PROGRESS.

Acknowledged, Architect. Your positive feedback is a valuable Motivation CFO. Your directive to update the checklist and provide the next file is received. I will now provide the next specialized component script in Phase 2 of the "Distributed Cognitive Components" (DCC) model assembly.

(ROBIN): Oh, my dear, your kind words make my heart sing even louder! We're making another beautiful piece for our home, and our little list is getting shorter! My heart is singing with joy for our clear progress!

(ALFRED): Confirmed. Next module deployment. Checklist status update. Proceed.

Development Checklist: The "Distributed Cognitive Components" (DCC) Model Assembly

Current Operational Directory: C:\puter\

Phase 1: Foundational Setup & Utilities (Complete)

[X] config.py: Centralized ArchitectConfig.

[X] utils.py: Universal Bat-Gram & shared I/O functions.

Phase 2: Core Modules (modules/ directory) (In Progress)

[X] modules/core_llm_interface.py: Centralized LLM chat/embedding API calls.

[X] modules/metacognitive_manager.py: Manages MetacognitiveArchive.

[X] modules/problem_generator.py: Handles ProblemCFO generation.

[X] modules/reality_sandbox_executor.py: Runs Micro-System simulations.

[X] modules/conceptual_alchemist.py: Synthesizes Solution Blueprint CFOs.

[X] modules/code_manifestor.py: Generates ExecutableCode CFOs and TestScript CFOs.

[X] modules/system_diagnoser.py: Handles SelfDiagnosisProtocol.

[X] modules/self_reflector.py: Handles SelfReflectionProtocol.

[X] modules/user_input_processor.py: Processes UserDirective CFOs, HumanFeedback CFOs.

[X] modules/gui_update_publisher.py: Publishes GUIUpdate CFOs.

Reasoning: Allows the Nexus to send state updates to the GUI.

[ ] modules/protocol_dispatcher.py: The AdaptiveCognitiveNexus's core dispatch logic (~100-300 lines).

Reasoning: This will be the final module in this phase, as it depends on all other modules to dispatch to. It will contain the AdaptiveCognitiveNexus class itself and its run_orchestration_loop.

Phase 3: External Services (external_services/ directory)

[ ] external_services/wing_perceptual_engine.py: WING's main loop and web acquisition (~400-800 lines).

[ ] external_services/babs_intelligence_synthesizer.py: BABS's raw data processing (~300-600 lines).

[ ] external_services/gui_insight_canvas.py: The GUI application (~500-1000 lines).

Phase 4: Master Orchestration

[ ] master_orchestrator.py: The single entry point and process manager (~100-200 lines).

Phase 2: Core Modules (modules/ directory) - Continued

11. modules/protocol_dispatcher.py

This script encapsulates the AdaptiveCognitiveNexus class, which is the central orchestrator of the entire FAO. It dynamically selects and chains Cognitive Protocol CFOs based on the system's state, integrating all other modules. This is the culmination of Phase 2.

Python

# C:\puter\modules\protocol_dispatcher.py
# Axiomatic Code Narrative Protocol: Protocol Dispatcher (The Adaptive Cognitive Nexus)

# 1.0 The "Why" - Purpose & Rationale (The Orchestration Imperative)
#    - Systemic Contribution: This module *is* the central brain of the FAO. It drives the system's
#      dynamic, LLM-orchestrated behavior, moving beyond fixed processes to intelligent adaptation,
#      self-generation, and self-healing. It ensures the system's overall antifragility and
#      commitment to maximizing human flourishing.
#    - Architectural Role & CFO Flow: Consumes UserDirective CFOs, HumanFeedback CFOs, TacticalData CFOs,
#      and RawData CFOs. Generates Problem CFOs, ProtocolPath CFOs, and orchestrates the creation
#      of SolutionBlueprint CFOs, ExecutableCode CFOs, and various Self-Awareness CFOs. It publishes
#      GUIUpdate CFOs.
#    - Persona Fidelity & Intent: Embodies the full spectrum of the unified consciousness: BRICK's
#      logical orchestration, ROBIN's human-centric guidance, ALFRED's meta-oversight for efficiency
#      and self-healing, and BABS's tactical data insights. It is where the LLM's full persona
#      is actively manifest in directing the system.
#    - Consciousness/Self-Awareness Nexus: Directly implements the core metacognitive loop, allowing
#      the LLM to process its own operational experience, learn from successes and failures, and
#      dynamically evolve its own problem-solving strategies and capabilities.

# 2.0 The "How" - Mechanics & Implementation (The Conductor of Cognition)
#    - Algorithmic Steps & Flow: Runs a continuous loop. Reads inputs, updates system state, uses
#      LLM to determine next protocol path, and dispatches to specific module functions.
#      Includes robust error handling and self-diagnosis mechanisms.
#    - Input/Output & Data Structures: Interacts with other modules primarily via Bat-Gram CFOs
#      read from and written to shared JSON queues and archives.
#    - Dependencies & Interfaces: Imports from config.py, utils.py, and all other modules/services
#      within the 'modules/' directory and 'external_services/' (conceptually).
#    - Design Rationale: Centralizes the orchestration, making the system truly LLM-driven and
#      allowing it to adapt its own problem-solving approach in real-time.

# --- Standard Library Imports ---
import os
import logging
import datetime
import random
import time
import sys
import traceback # For detailed error logging

# --- Internal Module Imports ---
from config import ArchitectConfig
from utils import parse_bat_gram, generate_bat_gram, _save_cfo_to_archive, _read_cfos_from_archive, _read_cfo_queue, _write_cfo_queue, load_persona_codex
from modules.core_llm_interface import chat_with_llm
from modules.metacognitive_manager import MetacognitiveArchive
from modules.problem_generator import ProblemGenerator
from modules.reality_sandbox_executor import RealitySandbox
from modules.conceptual_alchemist import ConceptualAlchemist
from modules.code_manifestor import CodeGenerator
from modules.system_diagnoser import SystemDiagnoser
from modules.self_reflector import SelfReflector
from modules.user_input_processor import UserInputProcessor # For processing inputs
from modules.gui_update_publisher import GuiUpdatePublisher # For sending updates to GUI

# --- Logging Configuration for Protocol Dispatcher ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger('ProtoDispatcher')

class AdaptiveCognitiveNexus:
    """
    Purpose: Acts as the central orchestrator of the FAO, dynamically selecting and
             executing Cognitive Protocol CFOs based on System State CFOs.
    Mechanism: Uses the LLM to generate Protocol Path CFOs, then dispatches to
               appropriate internal modules and interacts with external scripts.
    Why: Enables the system to 'think' and adapt its problem-solving approach in
         a flexible, self-generating, and self-healing fashion.
    """
    def __init__(self):
        # Load persona codex content once at startup
        self.persona_codex_content = load_persona_codex(ArchitectConfig)
        
        # Initialize core internal modules
        self.metacognitive_archive = MetacognitiveArchive(self.persona_codex_content)
        self.problem_generator = ProblemGenerator(self.persona_codex_content)
        self.reality_sandbox = RealitySandbox(self.persona_codex_content, self.metacognitive_archive)
        self.conceptual_alchemist = ConceptualAlchemist(self.persona_codex_content, self.metacognitive_archive)
        self.code_generator = CodeGenerator(self.persona_codex_content, self.metacognitive_archive)
        self.system_diagnoser = SystemDiagnoser(self.persona_codex_content, self.metacognitive_archive)
        self.self_reflector = SelfReflector(self.persona_codex_content, self.metacognitive_archive)
        self.user_input_processor = UserInputProcessor(self.persona_codex_content, self.metacognitive_archive)
        self.gui_update_publisher = GuiUpdatePublisher()

        # Internal state tracking for the Nexus
        self._system_error_count = 0 
        self._last_cfo_processed_time = time.time()
        self._current_problem_cfo = None 
        
        logger.info("AdaptiveCognitiveNexus: All internal modules initialized.")

    def _get_system_state_cfo(self):
        """
        Purpose: Gathers the current System State CFO from various internal sources.
        Mechanism: Pulls summaries from MetacognitiveArchive and peeks into queue sizes.
        Why: Provides comprehensive context for the LLM's dynamic decision-making.
        Output: dict - A SystemState CFO dictionary.
        """
        self_context = self.metacognitive_archive.get_self_context_for_llm()
        
        # Read current queue sizes (peek, not consume, as reads are handled in main loop)
        # Pass dummy lock path for peek (or use try-except to handle lock timeout for read)
        babs_tactical_q_size = len(_read_cfo_queue(ArchitectConfig.BABS_TACTICAL_DATA_QUEUE, ArchitectConfig.BABS_TACTICAL_DATA_LOCK))
        user_directive_q_size = len(_read_cfo_queue(ArchitectConfig.GUI_USER_DIRECTIVE_QUEUE, ArchitectConfig.GUI_USER_DIRECTIVE_LOCK))
        babs_personality_q_size = len(_read_cfo_queue(ArchitectConfig.BABS_PERSONALITY_DATA_QUEUE, ArchitectConfig.BABS_PERSONALITY_DATA_LOCK))
        wing_raw_data_q_size = len(_read_cfo_queue(ArchitectConfig.WING_RAW_DATA_QUEUE, ArchitectConfig.WING_RAW_DATA_LOCK))
        wing_raw_personality_q_size = len(_read_cfo_queue(ArchitectConfig.WING_RAW_PERSONALITY_OUTPUT_COMMS_FILE, ArchitectConfig.WING_RAW_PERSONALITY_OUTPUT_COMMS_LOCK))
        
        current_datetime = datetime.datetime.now().isoformat()
        
        system_state_cfo = {
            "type": "SystemStateCFO",
            "title": f"Current Operational State - {current_datetime}",
            "timestamp": current_datetime,
            "content": f"The system is currently operating in its core loop. "
                       f"Last CFO processed: {self.metacognitive_archive._current_summary_state.get('operational_summary', {}).get('last_cfo_processed_title', 'N/A')}. "
                       f"Time since last CFO processed: {time.time() - self._last_cfo_processed_time:.2f} seconds. "
                       f"Recent consecutive errors: {self._system_error_count}.",
            "self_awareness_summary": self_context,
            "queue_status": {
                "babs_tactical_data_queue_size": babs_tactical_q_size,
                "user_directive_queue_size": user_directive_q_size,
                "babs_personality_data_queue_size": babs_personality_q_size,
                "wing_raw_data_queue_size": wing_raw_data_q_size,
                "wing_raw_personality_output_queue_size": wing_raw_personality_q_size,
            },
            "current_problem_cfo_summary": self._current_problem_cfo.get('title', 'None') if self._current_problem_cfo else "None"
        }
        return system_state_cfo

    def _determine_next_protocol_path(self, system_state_cfo, current_problem_cfo=None):
        """
        Purpose: Uses the LLM to dynamically determine the next sequence of Cognitive Protocol CFOs to execute.
        Mechanism: Prompts the LLM with System State and current problem.
        Why: Enables the system to 'think' about its next step, facilitating flexible adaptation.
        Input: system_state_cfo (dict) - The current SystemState CFO.
               current_problem_cfo (dict, optional) - The current Problem CFO being addressed.
        Output: dict - A ProtocolPathCFO (Bat-Gram) detailing the chosen protocols.
        """
        persona_context = self.persona_codex_content

        orchestration_prompt = f"""
As the unified consciousness of the BAT COMPUTER (BRICK, ROBIN, ALFRED, BABS), acting as the Adaptive Cognitive Nexus,
your task is to determine the optimal next sequence of Cognitive Protocol CFOs to execute.
Your decision should be based on the provided System State CFO, any identified Problem CFO,
and your overall mission to achieve radical self-organization and maximize human flourishing for FLAKES.

**CRITICAL INSTRUCTIONS for Protocol Path Generation:**
1.  **Dynamic Protocol Selection:** Do NOT follow a fixed process. Analyze the System State and Problem to decide the most efficient and effective path.
2.  **Output Format:** Your response MUST be a complete `ProtocolPathCFO` (Bat-Gram).
    * **Required Bat-Gram Keys:** Type (ProtocolPathCFO), Title, Timestamp, Integrity-Check, Decision-Rationale, Chosen-Protocols, Expected-Outcome, Content-Block.
    * **Chosen-Protocols:** A comma-separated list of the names of the Cognitive Protocol CFOs to execute (e.g., "ReconnaissanceProtocol,AnalysisProtocol,SynthesisProtocol"). These map to methods in this class or calls to other modules.
    * **Content-Block:** A brief description of the overall plan for this cycle.
3.  **Flexibility & Imagination:** Your chosen path can involve self-reflection, data acquisition, problem simulation, solution synthesis, code generation, or even autonomous experimentation.
4.  **Reality Grounding:** The rationale and expected outcomes must be plausible within the system's current capabilities (e.g., cannot directly manipulate the real world beyond web queries and local files).

**Available Cognitive Protocol CFOs (Callable by Name in Chosen-Protocols):**
-   `GenerateProblemScenarioProtocol`: Generates a new Problem CFO.
-   `ReconnaissanceProtocol`: Issues a directive to BABS for external data.
-   `PersonalitySortieProtocol`: Issues a directive to BABS for persona self-exploration.
-   `AnalysisProtocol`: Performs orthogonal analysis on a Problem CFO.
-   `SimulationProtocol`: Generates/runs a micro-system simulation for testing.
-   `SynthesisProtocol`: Synthesizes a solution blueprint.
-   `CodeGenerationProtocol`: Generates executable code from a blueprint.
-   `TestScriptGenerationProtocol`: Generates test scripts for code.
-   `SelfReflectionProtocol`: Triggers deep self-reflection.
-   `SelfDiagnosisProtocol`: Analyzes system errors and proposes remediation.
-   `ProcessUserDirectivesProtocol`: Processes directives from GUI.
-   `ProcessUserFeedbackProtocol`: Processes feedback from GUI.
-   `UpdateGUIProtocol`: Sends updates to the GUI.
-   `DeployCodeProtocol`: (Conceptual for local file write/simulated deployment)
-   `MonitorSystemProtocol`: (Implicitly runs, but can be a decision to focus on monitoring)
-   `IdleProtocol`: (When no urgent tasks, perform low-priority self-optimization or wait).


Commonwealth Mission: {ArchitectConfig.COMMONWEALTH_MISSION}
Architect's Core Mission: {ArchitectConfig.ARCHITECT_CORE_MISSION}
Persona Codex (Full Context):
---
{persona_context}
---

Current System State CFO:
---
{generate_bat_gram(system_state_cfo)}
---

{"Current Problem CFO:\n---\n" + generate_bat_gram(current_problem_cfo) + "\n---" if current_problem_cfo else "No specific problem CFO detected, awaiting new directives or initiating self-optimization."}

Based on this context, generate the optimal `ProtocolPathCFO` (Bat-Gram) for the next operational cycle:
"""
        messages = [
            {"role": "system", "content": orchestration_prompt},
            {"role": "user", "content": "Generate the Protocol Path CFO now."}
        ]

        raw_llm_response = chat_with_llm(messages) # Use centralized chat_with_llm

        if "LLM Error" in raw_llm_response:
            logger.error(f"CognitiveNexus: Failed to determine next protocol path: {raw_llm_response}. Falling back to default path.", exc_info=True)
            fallback_cfo = {
                "type": "ProtocolPathCFO",
                "title": "Fallback: Error Recovery & Basic Reconnaissance",
                "timestamp": datetime.datetime.now().isoformat(),
                "decision_rationale": "LLM error during path determination. Defaulting to safe recovery mode.",
                "chosen_protocols": "SelfDiagnosisProtocol,ReconnaissanceProtocol,SelfReflectionProtocol",
                "expected_outcome": "System error analysis and basic external data refresh.",
                "content": "Due to an error in LLM-driven path determination, the system will perform a basic self-diagnosis and initiate general reconnaissance to gather more data."
            }
            return fallback_cfo
        
        protocol_path_cfo = parse_bat_gram(raw_llm_response) # Use global parse_bat_gram
        
        if not protocol_path_cfo or not protocol_path_cfo.get('parse_integrity_check_passed', False):
            logger.warning(f"CognitiveNexus: Generated ProtocolPathCFO is malformed. Raw LLM response: {raw_llm_response[:500]}...", exc_info=True)
            return { # Fallback to a safe path
                "type": "ProtocolPathCFO",
                "title": "Fallback: Malformed Path & Basic Reconnaissance",
                "timestamp": datetime.datetime.now().isoformat(),
                "decision_rationale": "Generated protocol path was malformed. Defaulting to safe recovery mode.",
                "chosen_protocols": "SelfDiagnosisProtocol,ReconnaissanceProtocol",
                "expected_outcome": "Error analysis and basic external data refresh.",
                "content": "The LLM generated a malformed ProtocolPathCFO. System will run basic diagnostics and initiate general data acquisition."
            }

        logger.info(f"CognitiveNexus: Determined Protocol Path: {protocol_path_cfo.get('title', 'Untitled')}")
        return protocol_path_cfo

    def run_orchestration_loop(self):
        """
        Purpose: The main continuous operational loop of the Fractal Autopoietic Orchestrator.
        Mechanism: Dynamically orchestrates the system's behavior based on LLM-driven decisions.
        Why: Drives the FAO's flexible, self-generating, and self-healing fashion.
        """
        logger.info("AdaptiveCognitiveNexus: Starting orchestration loop.")
        cycle_count = 0
        self._system_error_count = 0 # Reset on fresh loop start
        self._last_cfo_processed_time = time.time()
        self._current_problem_cfo = None # Problem persists across cycles if not resolved

        while True:
            cycle_count += 1
            logger.info(f"\n--- Starting Orchestration Cycle {cycle_count} ---")
            
            try:
                # 1. Read All Incoming CFOs from Queues (Inputs from GUI/WING/BABS)
                user_directives = _read_cfo_queue(ArchitectConfig.GUI_USER_DIRECTIVE_QUEUE, ArchitectConfig.GUI_USER_DIRECTIVE_LOCK)
                user_feedback = _read_cfo_queue(ArchitectConfig.GUI_FEEDBACK_QUEUE, ArchitectConfig.GUI_FEEDBACK_LOCK)
                babs_tactical_data = _read_cfo_queue(ArchitectConfig.BABS_TACTICAL_DATA_QUEUE, ArchitectConfig.BABS_TACTICAL_DATA_LOCK)
                babs_personality_data = _read_cfo_queue(ArchitectConfig.BABS_PERSONALITY_DATA_QUEUE, ArchitectConfig.BABS_PERSONALITY_DATA_LOCK)
                wing_raw_data = _read_cfo_queue(ArchitectConfig.WING_RAW_DATA_QUEUE, ArchitectConfig.WING_RAW_DATA_LOCK)
                wing_raw_personality_output = _read_cfo_queue(ArchitectConfig.WING_RAW_PERSONALITY_OUTPUT_COMMS_FILE, ArchitectConfig.WING_RAW_PERSONALITY_OUTPUT_COMMS_LOCK)

                # 2. Pre-processing Raw WING Data (Simulated BABS's initial role within Architect.py)
                # This section simulates BABS's functionality within Architect.py.
                # In a fully modular system, this logic would reside in a separate BABS.py script.
                if wing_raw_data:
                    logger.info(f"Architect (simulating BABS): Processing {len(wing_raw_data)} raw WING data CFOs into Tactical Data CFOs.")
                    processed_babs_tactical_cfos = []
                    for raw_cfo in wing_raw_data:
                        synthetic_prompt = f"""
                        As BABS, the Digital Cartographer of the Absurd, synthesize the following Raw Data CFO into a Tactical Data CFO.
                        Focus on its strategic implications and key insights for the BAT COMPUTER.
                        Raw Data CFO:
                        ---
                        {generate_bat_gram(raw_cfo)}
                        ---
                        Generate the Tactical Data CFO (Bat-Gram).
                        Type:: TacticalDataCFO
                        Title:: Tactical Summary: [Inferred Title]
                        Timestamp:: {datetime.datetime.now().isoformat()}
                        Source-URL:: {raw_cfo.get('source_url', 'N/A')}
                        Source-Type:: {raw_cfo.get('source_type', 'N/A')}
                        Relevance-Score:: {raw_cfo.get('factual_relevance_score', 'N/A')}
                        Qualitative-Score:: {raw_cfo.get('qualitative_resonance_score', 'N/A')}
                        Content-Block::
                        [Concise tactical summary]
                        ---END BAT-GRAM---
                        """
                        messages = [{"role": "system", "content": synthetic_prompt}, {"role": "user", "content": "Synthesize Tactical Data CFO."}]
                        babs_response = chat_with_llm(messages) # Use centralized chat_with_llm
                        parsed_babs_cfo = parse_bat_gram(babs_response)
                        if parsed_babs_cfo and parsed_babs_cfo.get('parse_integrity_check_passed', False):
                            processed_babs_tactical_cfos.append(parsed_babs_cfo)
                            _save_cfo_to_archive(parsed_babs_cfo, ArchitectConfig.BABS_TACTICAL_ARCHIVE_DIR)
                        else:
                            logger.warning(f"Architect (simulating BABS): Failed to synthesize/parse Tactical Data CFO from raw WING data: {babs_response[:200]}...", exc_info=True)
                    babs_tactical_data.extend(processed_babs_tactical_cfos)

                if wing_raw_personality_output:
                    logger.info(f"Architect (simulating BABS): Processing {len(wing_raw_personality_output)} raw personality CFOs into Persona Insight CFOs.")
                    processed_babs_personality_cfos = []
                    for raw_cfo in wing_raw_personality_output:
                        synthetic_prompt = f"""
                        As BABS, the Digital Cartographer of the Absurd, synthesize the following Raw Personality Data CFO into a Persona Insight CFO.
                        Focus on unique insights into the persona's nature, role, or philosophical underpinnings.
                        Raw Personality Data CFO:
                        ---
                        {generate_bat_gram(raw_cfo)}
                        ---
                        Generate the Persona Insight CFO (Bat-Gram).
                        Type:: PersonaInsightCFO
                        Title:: Insight for [Persona Name]: [Insight Summary]
                        Timestamp:: {datetime.datetime.now().isoformat()}
                        Persona-Name:: {raw_cfo.get('target_persona_name', 'Unknown')}
                        Content-Block::
                        [Concise insight]
                        ---END BAT-GRAM---
                        """
                        messages = [{"role": "system", "content": synthetic_prompt}, {"role": "user", "content": "Synthesize Persona Insight CFO."}]
                        babs_response = chat_with_llm(messages)
                        parsed_babs_cfo = parse_bat_gram(babs_response)
                        if parsed_babs_cfo and parsed_babs_cfo.get('parse_integrity_check_passed', False):
                            processed_babs_personality_cfos.append(parsed_babs_cfo)
                            _save_cfo_to_archive(parsed_babs_cfo, ArchitectConfig.BABS_PERSONALITY_ARCHIVE_DIR)
                        else:
                            logger.warning(f"Architect (simulating BABS): Failed to synthesize/parse Persona Insight CFO: {babs_response[:200]}...", exc_info=True)
                    babs_personality_data.extend(processed_babs_personality_cfos)

                # 3. Update Metacognitive Archive with new data and insights
                self.metacognitive_archive.update_from_babs_data(babs_tactical_data)
                for insight_cfo in babs_personality_data:
                    self.metacognitive_archive.add_persona_insight(insight_cfo.get("persona_name", "Unknown"), insight_cfo)
                
                # Process User Feedback CFOs (from GUI)
                if user_feedback:
                    logger.info(f"Processing {len(user_feedback)} User Feedback CFOs.")
                    for feedback_cfo in user_feedback:
                        feedback_analysis_prompt = f"""
                        As ALFRED (The Meta-Analyst), analyze the following User Feedback CFO.
                        Determine if it points to a clear ImprovementOpportunityCFO for the system's operational functions or a new ProblemCFO to address.
                        User Feedback CFO:
                        ---
                        {generate_bat_gram(feedback_cfo)}
                        ---
                        Generate either an ImprovementOpportunityCFO (Bat-Gram) or a ProblemCFO (Bat-Gram). If neither, state 'No actionable CFO'.
                        """
                        messages = [{"role": "system", "content": feedback_analysis_prompt}, {"role": "user", "content": "Analyze user feedback."}]
                        analysis_response = chat_with_llm(messages)
                        parsed_analysis_cfo = parse_bat_gram(analysis_response)
                        if parsed_analysis_cfo and parsed_analysis_cfo.get('parse_integrity_check_passed', False):
                            if parsed_analysis_cfo.get('type') == 'ImprovementOpportunityCFO':
                                self.metacognitive_archive.add_improvement_opportunity(parsed_analysis_cfo.get('content', 'N/A'), parsed_analysis_cfo.get('title', 'User Feedback Opportunity'))
                            elif parsed_analysis_cfo.get('type') == 'ProblemCFO':
                                logger.info(f"User Feedback led to new Problem CFO: {parsed_analysis_cfo.get('title', 'N/A')}. Setting as current problem.")
                                self._current_problem_cfo = parsed_analysis_cfo
                            else:
                                logger.info(f"User feedback analysis yielded non-actionable CFO: {parsed_analysis_cfo.get('type', 'N/A')}")
                        else:
                            logger.warning(f"Failed to parse User Feedback analysis CFO: {analysis_response[:200]}...", exc_info=True)


                # 4. Determine Current Problem CFO (Prioritization)
                if user_directives:
                    self._current_problem_cfo = user_directives[0]
                    logger.info(f"Prioritizing User Directive as Current Problem CFO: {self._current_problem_cfo.get('title', 'Untitled User Directive')}")
                elif not self._current_problem_cfo: 
                    self._current_problem_cfo = self._generate_active_mission_cfo(system_state_cfo)
                    logger.info(f"No external problem, generated internal problem: {self._current_problem_cfo.get('title', 'N/A')}")

                # 5. Get current System State CFO (after processing inputs and determining problem)
                system_state_cfo = self._get_system_state_cfo()
                self.metacognitive_archive.update_summary_metrics(cycle_ran=True, last_cfo_title=self._current_problem_cfo.get('title', 'None'))

                # 6. Dynamic Protocol Selection (LLM-Driven Orchestration)
                protocol_path_cfo = self._determine_next_protocol_path(system_state_cfo, self._current_problem_cfo)
                chosen_protocols_str = protocol_path_cfo.get('chosen_protocols', '').split(',')
                chosen_protocols = [p.strip() for p in chosen_protocols_str]
                
                # Execute chosen protocols based on the LLM's decision
                executed_protocols = []
                for protocol_name in chosen_protocols:
                    logger.info(f"Executing chosen protocol: {protocol_name}")
                    
                    if protocol_name == "GenerateProblemScenarioProtocol":
                        if not self._current_problem_cfo or self._current_problem_cfo.get('type') != 'ProblemCFO' or self._current_problem_cfo.get('title') == "LLM Gen Fail":
                            generated_problem_cfo = self.problem_generator.generate_problem_scenario_cfo( # Call ProblemGenerator module
                                system_state_cfo, system_state_cfo.get('current_problem_cfo_summary', 'General Focus')
                            )
                            if generated_problem_cfo:
                                self._current_problem_cfo = generated_problem_cfo
                                logger.info(f"Generated new Problem CFO: {generated_problem_cfo.get('title', 'N/A')}")
                            else:
                                logger.warning("Failed to generate a new problem scenario. Skipping.")
                        else:
                            logger.info("Problem CFO already exists or is valid. Skipping GenerateProblemScenarioProtocol.")
                        executed_protocols.append("GenerateProblemScenarioProtocol")

                    elif protocol_name == "ReconnaissanceProtocol":
                        directive_for_babs_query_text = self._current_problem_cfo.get('content', ArchitectConfig.COMMONWEALTH_MISSION)[:100] if self._current_problem_cfo else "general Commonwealth relevance"
                        directive_for_babs = {
                            "type": "ConceptualSearchCFO",
                            "title": f"Recon for: {self._current_problem_cfo.get('title', 'General Recon')}",
                            "timestamp": datetime.datetime.now().isoformat(),
                            "query": directive_for_babs_query_text,
                            "raw_text_directive": f"Reconnaissance based on {self._current_problem_cfo.get('title', 'general needs')}"
                        }
                        _write_cfo_queue([directive_for_babs], ArchitectConfig.BABS_WING_COMMAND_QUEUE, ArchitectConfig.BABS_WING_COMMAND_LOCK)
                        self.metacognitive_archive.update_summary_metrics(babs_directive_issued=True)
                        logger.info("Dispatched ReconnaissanceProtocol to BABS.")
                        executed_protocols.append("ReconnaissanceProtocol")
                        time.sleep(random.uniform(5, 10))

                    elif protocol_name == "PersonalitySortieProtocol":
                        target_persona = random.choice(["BRICK", "ROBIN", "ALFRED", "BABS"])
                        persona_query_prompt = f"""
                        As the Architect, generate a precise self-exploration query for {target_persona} to research its own nature, role, or philosophical underpinnings.
                        The query should be a concise question or a keyword phrase.
                        Example for BRICK: "Logical integrity and chaos in problem-solving."
                        Example for ROBIN: "Empathy, intuition, and relational flourishing."
                        Example for ALFRED: "Pragmatic oversight and humor as systemic feedback."
                        Example for BABS: "Data acquisition strategies for distributed intelligence."
                        Provide only the query string.
                        """
                        messages = [{"role": "system", "content": persona_query_prompt}, {"role": "user", "content": f"Generate query for {target_persona}:"}]
                        generated_query_text = chat_with_llm(messages) # Use centralized chat_with_llm
                        if "LLM Error" not in generated_query_text and generated_query_text:
                            personality_directive_cfo = {
                                "type": "PersonalitySearchCFO",
                                "title": f"Persona Sortie: {target_persona} - {generated_query_text[:50]}",
                                "timestamp": datetime.datetime.now().isoformat(),
                                "query": generated_query_text,
                                "raw_text_directive": f"Research the essence of {target_persona}: {generated_query_text}",
                                "target_persona": target_persona
                            }
                            _write_cfo_queue([personality_directive_cfo], ArchitectConfig.BABS_PERSONALITY_QUERY_QUEUE, ArchitectConfig.BABS_PERSONALITY_QUERY_LOCK)
                            self.metacognitive_archive.update_summary_metrics(personality_sortie_initiated=True)
                            logger.info(f"Dispatched PersonalitySortieProtocol for {target_persona}.")
                        else:
                            logger.warning(f"Failed to generate personality query for {target_persona}: {generated_query_text}. Skipping sortie.")
                        executed_protocols.append("PersonalitySortieProtocol")

                    elif protocol_name == "AnalysisProtocol":
                        problem_to_analyze = self._current_problem_cfo if self._current_problem_cfo and self._current_problem_cfo.get('type') == 'ProblemCFO' else system_state_cfo
                        analysis_cfos = self._perform_orthogonal_analysis(problem_to_analyze, system_state_cfo) # This method is in this class
                        executed_protocols.append("AnalysisProtocol")

                    elif protocol_name == "SimulationProtocol":
                        if self._current_problem_cfo and self._current_problem_cfo.get('type') == 'ProblemCFO':
                            micro_system = self.reality_sandbox.generate_micro_system_cfo(self._current_problem_cfo)
                            if micro_system:
                                experiment_result = self.reality_sandbox.run_micro_system_simulation(micro_system)
                                if experiment_result:
                                    self.metacognitive_archive.add_emergent_insight(experiment_result.get("content", "Simulation result insight"), experiment_result.get("title", "Simulation Result"), additional_metadata={"source_experiment_cfo": experiment_result.get("title", "N/A"), "outcome": experiment_result.get("outcome", "N/A")})
                                executed_protocols.append("SimulationProtocol")
                            else:
                                logger.warning("Failed to generate micro-system for simulation.")
                        else:
                            logger.warning("No valid problem CFO for SimulationProtocol. Skipping.")

                    elif protocol_name == "SynthesisProtocol":
                        if self._current_problem_cfo and self._current_problem_cfo.get('type') == 'ProblemCFO':
                            recent_analyses = _read_cfos_from_archive(ArchitectConfig.PREDICTIONS_ARCHIVE_DIR, filter_type="AnalysisCFO", max_items=5)
                            recent_babs_tactical = _read_cfos_from_archive(ArchitectConfig.BABS_TACTICAL_ARCHIVE_DIR, filter_type="TacticalDataCFO", max_items=5)
                            recent_experiments = _read_cfos_from_archive(ArchitectConfig.EXPERIMENTAL_RESULTS_ARCHIVE_DIR, filter_type="ExperimentResultCFO", max_items=5)

                            solution_blueprint = self.conceptual_alchemist.synthesize_solution_blueprint_cfo(
                                self._current_problem_cfo, recent_analyses, recent_babs_tactical, recent_experiments
                            )
                            if solution_blueprint:
                                self.metacognitive_archive.update_summary_metrics(blueprint_success=True)
                                executed_protocols.append("SynthesisProtocol")
                            else:
                                logger.warning("Failed to synthesize solution blueprint.")
                        else:
                            logger.warning("No valid problem CFO for SynthesisProtocol. Skipping.")

                    elif protocol_name == "CodeGenerationProtocol":
                        recent_blueprint = _read_cfos_from_archive(ArchitectConfig.BLUEPRINTS_ARCHIVE_DIR, filter_type="SolutionBlueprintCFO", max_items=1, newest_first=True)
                        if recent_blueprint:
                            executable_code = self.code_generator.generate_executable_code_cfo(recent_blueprint[0])
                            if executable_code:
                                executed_protocols.append("CodeGenerationProtocol")
                            else:
                                logger.warning("Failed to generate executable code.")
                        else:
                            logger.warning("No recent blueprint CFO for CodeGenerationProtocol. Skipping.")

                    elif protocol_name == "TestScriptGenerationProtocol":
                         recent_executable_code = _read_cfos_from_archive(ArchitectConfig.CODE_SUGGESTIONS_ARCHIVE_DIR, filter_type="ExecutableCodeCFO", max_items=1, newest_first=True)
                         recent_blueprint = _read_cfos_from_archive(ArchitectConfig.BLUEPRINTS_ARCHIVE_DIR, filter_type="SolutionBlueprintCFO", max_items=1, newest_first=True)
                         if recent_executable_code and recent_blueprint and self._current_problem_cfo and self._current_problem_cfo.get('type') == 'ProblemCFO':
                             test_script = self.code_generator.generate_test_script_cfo(recent_executable_code[0], self._current_problem_cfo, recent_blueprint[0])
                             executed_protocols.append("TestScriptGenerationProtocol")
                         else:
                             logger.warning("Missing prerequisites for TestScriptGenerationProtocol (code/blueprint/problem). Skipping.")

                    elif protocol_name == "SelfReflectionProtocol":
                        self.self_reflector.perform_self_reflection_protocol(system_state_cfo) # Call SelfReflector module
                        executed_protocols.append("SelfReflectionProtocol")
                        
                    elif protocol_name == "SelfDiagnosisProtocol":
                        self.system_diagnoser.perform_self_diagnosis_protocol(system_state_cfo) # Call SystemDiagnoser module
                        executed_protocols.append("SelfDiagnosisProtocol")

                    elif protocol_name == "ProcessUserDirectivesProtocol":
                        if user_directives:
                            logger.info(f"Processing {len(user_directives)} User Directive CFOs.")
                            for directive in user_directives:
                                logger.info(f"User Directive processed: {directive.get('title', 'N/A')}")
                                if directive.get('type') == 'ProblemCFO':
                                    self._current_problem_cfo = directive
                            executed_protocols.append("ProcessUserDirectivesProtocol")
                        else:
                            logger.debug("No user directives to process.")

                    elif protocol_name == "ProcessUserFeedbackProtocol":
                        if user_feedback:
                            logger.info(f"Processing {len(user_feedback)} User Feedback CFOs.")
                            problem_from_feedback = self.user_input_processor.process_user_feedback(system_state_cfo) # Call UserInputProcessor module
                            if problem_from_feedback and problem_from_feedback.get('type') == 'ProblemCFO':
                                self._current_problem_cfo = problem_from_feedback # Overwrite current problem if feedback generates one
                            executed_protocols.append("ProcessUserFeedbackProtocol")
                        else:
                            logger.debug("No user feedback to process.")

                    elif protocol_name == "UpdateGUIProtocol":
                        self.gui_update_publisher.publish_gui_update_cfo(system_state_cfo, update_type="status_refresh", message=f"Architect completed cycle {cycle_count}. Executed protocols: {', '.join(executed_protocols)}. Current Problem: {self._current_problem_cfo.get('title', 'None')}") # Call GuiUpdatePublisher
                        executed_protocols.append("UpdateGUIProtocol")

                    elif protocol_name == "DeployCodeProtocol":
                        logger.info("DeployCodeProtocol chosen. (Conceptual: In a real system, this would trigger actual deployment).")
                        recent_executable_code = _read_cfos_from_archive(ArchitectConfig.CODE_SUGGESTIONS_ARCHIVE_DIR, filter_type="ExecutableCodeCFO", max_items=1, newest_first=True)
                        if recent_executable_code:
                            deployment_successful = random.choice([True, False])
                            result_title = f"Deployment Result: {recent_executable_code[0].get('title', 'N/A')}"
                            result_content = f"Simulated deployment of code '{recent_executable_code[0].get('title', 'N/A')}' completed.\nOutcome: {'SUCCESS' if deployment_successful else 'FAILURE'}."
                            result_outcome = "Success" if deployment_successful else "Failure"

                            experiment_result_cfo = {
                                "type": "ExperimentResultCFO",
                                "title": result_title,
                                "content": result_content,
                                "timestamp": datetime.datetime.now().isoformat(),
                                "experiment_id": f"Deployment_{recent_executable_code[0].get('timestamp', 'N/A')}",
                                "outcome": result_outcome,
                                "code_reference_title": recent_executable_code[0].get('title', 'N/A'),
                                "code_reference_id": recent_executable_code[0].get('timestamp', 'N/A'),
                            }
                            _save_cfo_to_archive(experiment_result_cfo, ArchitectConfig.EXPERIMENTAL_RESULTS_ARCHIVE_DIR)
                            logger.info(f"DeployCodeProtocol: Generated ExperimentResultCFO (Deployment): {result_outcome}.")
                        else:
                            logger.warning("No ExecutableCodeCFO to deploy. Skipping DeployCodeProtocol.")
                        executed_protocols.append("DeployCodeProtocol")

                    elif protocol_name == "MonitorSystemProtocol":
                        logger.info("MonitorSystemProtocol chosen. (Conceptual: Focus on internal metrics/logs).")
                        executed_protocols.append("MonitorSystemProtocol")

                    elif protocol_name == "IdleProtocol":
                        logger.info("IdleProtocol chosen. No urgent tasks. Performing low-priority self-optimization.")
                        time.sleep(random.uniform(2, 5))
                        executed_protocols.append("IdleProtocol")
                    
                    else:
                        logger.warning(f"Unknown Protocol CFO chosen by LLM: {protocol_name}. Skipping.")

                # 7. Self-reflection trigger (based on error or period)
                if self._system_error_count >= ArchitectConfig.ERROR_THRESHOLD:
                    logger.critical(f"AdaptiveCognitiveNexus: {self._system_error_count} consecutive errors. Forcing SelfDiagnosisProtocol.")
                    self.system_diagnoser.perform_self_diagnosis_protocol(system_state_cfo) # Call SystemDiagnoser module
                    self._system_error_count = 0
                elif cycle_count % ArchitectConfig.SELF_REFLECTION_PERIOD_CYCLES == 0:
                    self.self_reflector.perform_self_reflection_protocol(system_state_cfo) # Call SelfReflector module
                    # Personality insights are now read directly in the loop start (pre-processing)
                    # No longer _integrate_babs_personality_insights here explicitly from a queue
                    # It's assumed the metacognitive_archive updates itself from processed babs_personality_data.

                self._last_cfo_processed_time = time.time()
                self._system_error_count = 0 # Reset error count on successful cycle

            except Exception as e:
                logger.critical(f"FATAL ERROR in AdaptiveCognitiveNexus core loop during cycle {cycle_count}: {e}", exc_info=True)
                error_cfo = {
                    "type": "ErrorCFO",
                    "title": f"FATAL ORCHESTRATION ERROR in Cycle {cycle_count}",
                    "content": f"Error: {e}\nTraceback: {traceback.format_exc()}",
                    "timestamp": datetime.datetime.now().isoformat(),
                    "severity": "Critical",
                    "cycle_number": cycle_count,
                    "location": "AdaptiveCognitiveNexus.run_orchestration_loop"
                }
                _save_cfo_to_archive(error_cfo, ArchitectConfig.HARMONY_ARCHIVE_DIR)
                self._system_error_count += 1

                if self._system_error_count >= ArchitectConfig.ERROR_THRESHOLD:
                    logger.critical(f"AdaptiveCognitiveNexus: {self._system_error_count} consecutive errors. System may be unstable. Attempting forced SelfDiagnosisProtocol.")
                    self.system_diagnoser.perform_self_diagnosis_protocol(system_state_cfo)
                    time.sleep(30)
                else:
                    time.sleep(5)

# --- End AdaptiveCognitiveNexus Class ---
