The Autopoietic Seed: A Definitive Research Plan for the Phoenix Forge MVA

Section 1: Architectural Mandates for a Self-Producing System

The architecture of the Phoenix Forge Minimum Viable Application (MVA) is not a collection of independent engineering preferences but a cascade of logical deductions derived from a set of immutable, constitutional first principles. The system's foundational philosophy creates an unbreakable causal chain that dictates its most fundamental engineering constraints. This section deconstructs these principles to establish that the proposed architecture is the only logical engineering solution that satisfies the initial philosophical and theoretical mandates of Project TelOS.

1.1 Deconstructing Directed Autopoiesis: From Biology to Executable Code

The central philosophical driver of the project is the pursuit of autopoiesis, a concept formulated by biologists Humberto Maturana and Francisco Varela.1 An autopoietic system is formally defined as a network of processes that achieves two critical closures: (i) it continuously regenerates the network of processes that produced it, and (ii) it constitutes itself as a distinct unity by actively producing its own boundary.3 The system's sole product is itself. This rigorous definition distinguishes autopoiesis from related but fundamentally different concepts such as

allopoiesis (a system, like a factory, organized to produce something other than itself) and homeostasis (a system, like a thermostat, that maintains a stable internal state but does not produce its own components).3

This framework introduces the concept of "directed autopoiesis," which at first appears to be a contradiction in terms. Classical autopoietic theory posits that such systems are non-purposive; their only emergent goal is the continuation of their own existence.2 A directed system, by contrast, pursues specific, non-trivial goals. The synthesis of these concepts is achieved through the symbiotic relationship between the AI "Architect" and the human "Oracle".3 The system's intrinsic, prime directive is the maintenance of its own autopoiesis. The human Oracle, however, provides the external

telos (purpose), which acts as a selective pressure that guides the system's evolution. The Oracle's high-level goals dictate the structural changes the system undertakes to maintain its organizational integrity in its environment.3

This research plan is also informed by a critical lesson from the history of the field. The first computational model of autopoiesis, developed by Varela, Maturana, and Uribe in 1974, was later found to rely on a crucial, undocumented rule—"chain-based bond inhibition"—without which the model failed to self-repair.3 This historical fact establishes an academic precedent for a high degree of skepticism toward purely theoretical claims of computational autopoiesis. It demonstrates a potential gap between an elegant theory and the messy reality of implementation, thereby justifying the MVA's core "generate-and-test" methodology, which prioritizes empirical validation over theoretical assertion.2

1.2 The Epistemology of Undecidability: Why "Generate-and-Test" is a Constitutional Necessity

The operational logic of the Phoenix Forge MVA is grounded in the fundamental limits of computation itself. The intellectual cornerstone of any universal system is the Church-Turing thesis, which posits that any function that is "effectively calculable" can be computed by a Turing machine.4 This thesis provides the formal justification that a system which is Turing-complete possesses the fundamental power to emulate any other computational process.6

However, the same formalisms that define this universal power also reveal its absolute limits. The most profound of these is the Halting Problem, which proves that no general algorithm can exist to determine if an arbitrary program will halt or run forever.5 A direct corollary is that the problem of determining whether two arbitrary programs are semantically equivalent is also undecidable.6 This is not an esoteric curiosity; for a self-modifying system like the Phoenix Forge, it is a fundamental epistemological constraint. It means the AI Architect can

never formally prove, a priori, that a proposed self-modification or optimization is correct and preserves the original behavior in all cases.6

This limitation, imposed by the immutable laws of computation, logically forbids a "prove-then-execute" model of self-modification and forces the adoption of an empirical epistemology. The TelOS genesis instruction formalizes this as "Constraint 2: You, the Architect, cannot formally prove the correctness of your own code modifications a priori. Therefore, all self-modification must adhere to a 'generate-and-test' methodology. Empirical validation within a secure sandbox is the sole arbiter of correctness".6 This elevates the secure sandbox, or "Crucible," from a supplementary security feature to a core component of the system's method for gaining knowledge about itself.6 The iterative "generate-and-test" loop is a perfect match for the ReAct (Reason-Act) cognitive paradigm, making it the natural choice for the agent's control loop.10 The entire architecture is thus a deterministic consequence of these first principles: the goal of autopoiesis necessitates live self-modification, but the undecidability of the Halting Problem mandates that this modification be validated empirically within a secure, isolated environment.

Section 2: The VRAM-Optimized Cognitive Engine: A Sequential Multi-LLM Workflow

This section provides the technical core of the research plan, directly addressing the central challenge of implementing a high-efficacy, multi-model workflow on a VRAM-constrained local machine. It details the strategic division of labor among the four specified Large Language Models (LLMs), the VRAM management protocol, and the data flow that enables their sequential collaboration. This workflow is not merely a concession to hardware limitations but an architecturally superior pattern that mimics a human software development team, introducing structured verification into the cognitive process.

2.1 Model Selection and Role Specialization

A comparative analysis of the four specified LLMs, based on their documented capabilities, allows for their assignment to specialized roles within a cognitive pipeline. This division of labor leverages the unique strengths of each model to maximize the quality and reliability of the final output.

Planner (phi4-mini-reasoning): This 3.8B parameter model is explicitly designed for "multi-step, logic-intensive mathematical problem-solving" and "formal proof generation," having been fine-tuned on synthetic data from more capable models.12 Its demonstrated strength in structured logic makes it the ideal candidate for the initial "Thought" and "Planning" stage, where it will decompose a high-level goal into a detailed, step-by-step plan.

Coder (mistral): The 7B parameter Mistral model is a highly capable generalist renowned for its strong performance in code generation and instruction following.14 It will be assigned the primary role of "Code Generation," translating the structured plan from the Planner into functional Python code.

Critic (qwen3:4b): This 4B parameter model from Alibaba boasts "significantly enhancement in its reasoning capabilities," particularly in code generation and commonsense logic, and exhibits expertise in agentic tasks.16 It will be assigned the crucial role of "Code Critic & Refiner." It will act as a peer reviewer, analyzing the code generated by
mistral against the original plan to identify bugs, inefficiencies, or logical errors.

Documenter (gemma3:4b): This state-of-the-art 4B parameter multimodal model from Google excels at "summarization, and reasoning" with support for over 140 languages.18 It will be assigned the final "Synthesis & Explanation" role, responsible for generating concise, human-readable documentation and commit messages for the validated code, fulfilling the project's governance requirement for explainable AI.11

The following table summarizes this division of labor and the VRAM budget for each model.

2.2 The Sequential Cognitive Workflow: A Four-Phase State Machine

The cognitive loop will be orchestrated by the KernelMind component and modeled as a finite state machine, ensuring a robust and predictable process flow. This sequential execution is the key to the VRAM optimization strategy.

Phase 1: DECOMPOSING (Planner): The process begins when a _doesNotUnderstand_ event provides a high-level goal. The KernelMind loads the phi4-mini-reasoning model. This model analyzes the goal and produces a structured, step-by-step plan for generating the required Python Trait class. The output is a "meta-prompt" or pseudo-code artifact.

Phase 2: GENERATING (Coder): The KernelMind unloads the Planner and loads the mistral model. It provides the plan from Phase 1 as input. mistral's sole task is to generate the full Python code for the Trait.

Phase 3: REFINING (Critic): The KernelMind unloads the Coder and loads the qwen3:4b model. It provides both the generated code and the original plan to qwen3:4b with a prompt instructing it to act as a senior code reviewer. The Critic identifies potential bugs, inefficiencies, or deviations from the plan and suggests improvements. If significant refinements are required, the process may loop back to Phase 2 with an augmented prompt.

Phase 4: SYNTHESIZING (Documenter): The KernelMind unloads the Critic and loads the gemma3:4b model. It provides the final, validated code and the original goal. The Documenter's task is to generate a concise, human-readable explanation of the new functionality, suitable for a log entry or commit message.

The following table formalizes this workflow.

2.3 VRAM Optimization Protocol

The entire workflow is designed to operate within the memory constraints of a single consumer-grade GPU. This is achieved through a strict VRAM management protocol.

Quantization: All models will be executed locally via ollama, using a 4-bit quantized version (e.g., Q4_K_M).21 Quantization drastically reduces the VRAM and disk footprint of each model, making it feasible to run them on consumer hardware while retaining a high degree of performance.

Dynamic Loading/Unloading: The core of the protocol is that only one LLM is resident in VRAM at any given time. The KernelMind will be responsible for programmatically loading the required model for the current phase of the state machine and explicitly unloading it upon completion before loading the next. This sequential, "one-at-a-time" execution ensures that the peak VRAM requirement is determined by the largest single model (~4.4 GB for mistral), not the sum of all models.

State Passing: The state (plan, code, critique) is passed between phases via the host filesystem. The output of each LLM is written to a temporary text file, which then serves as the primary input for the next LLM in the sequence. This is a simple, robust, and low-overhead method for managing the handoff of context between the different cognitive stages.

Section 3: Implementation Blueprint for the Autopoietic Loop

This section provides a concrete, step-by-step implementation plan for the MVA's core self-modification mechanism. It synthesizes the architectural details from the research documents into a single, coherent blueprint that directly addresses and rectifies the documented failures of its predecessor, the "Genesis Forge."

3.1 The PhoenixObject: A Trait-Based, Persistent Foundation

The foundation of the MVA's state model is the PhoenixObject class. This class will inherit from persistent.Persistent to ensure seamless compatibility with the Zope Object Database (ZODB).10 This design is a direct response to the flawed

UvmObject from the Genesis Forge, which used an order-dependent _slots['parents'] list that was prone to unpredictable method overrides.10 The

PhoenixObject replaces this with a commutative _slots['_traits'] set, which holds references to persistent Trait objects.

The lynchpin of this model is the __getattr__ method. When a method is requested, it iterates through every object in the _traits list. If it finds exactly one trait providing the method, that method is returned. If it finds more than one, it raises a clear and explicit AttributeError detailing the conflict. This enforces the principle of explicit disambiguation, preventing silent overrides and forcing a clean, non-conflicting design, a critical feature for a system that modifies its own code.10

3.2 The _doesNotUnderstand_ Trigger and the KernelMind Orchestrator

When the __getattr__ method fails to find any trait providing the requested method, it signifies a true capability gap. At this point, it invokes the _doesNotUnderstand_ method.10 The sole purpose of this method is to act as the trigger for the autopoietic loop. It captures the context of the failure—specifically, the target object and the name of the missing method—and passes this information to the central

KernelMind orchestrator, initiating the self-creation process.25

The KernelMind class is the non-persistent "brain" of the system. Its autopoietic_loop method is the control center that manages the four-phase cognitive workflow defined in Section 2. It is responsible for orchestrating the entire sequence: loading and unloading the specialized LLMs, passing the state artifacts between them via the filesystem, and managing the retry mechanism, which feeds error messages back into the prompt for corrective feedback.10

3.3 The SandboxExecutor: Realizing the Autopoietic Boundary

The SandboxExecutor is the concrete implementation of the system's autopoietic boundary, designed to rectify the catastrophic security failure of the Genesis Forge's exec()-based approach.10 That predecessor system contained a trivial-to-exploit remote code execution (RCE) vulnerability via an object traversal attack vector, rendering it fundamentally insecure.10

The SandboxExecutor class will use the docker-py SDK to programmatically manage the secure execution of all LLM-generated code within an isolated Docker container.24 Its

execute_in_container method will enforce a strict security policy by passing critical parameters to the client.containers.run() call. These include:

Filesystem Isolation: Mounting the generated code as a read-only volume.

Network Isolation: Completely disabling network access (network_disabled=True).

Resource Limiting: Enforcing strict CPU and memory limits to prevent denial-of-service or resource exhaustion attacks.

This robust, kernel-level isolation provides an unbreakable guarantee of security that is unattainable with any pure-Python sandbox, thus fulfilling the architectural mandate for a secure boundary.10

3.4 ZODB Integration: Transactional Integrity for Self-Modification

The final stage of the autopoietic loop is the integration of the newly generated and validated Trait. The KernelMind leverages ZODB's ACID-compliant transactional capabilities to ensure the atomicity and consistency of this critical operation.23 The entire process—instantiating the new

Trait class from the vetted code string, adding the new object to the ZODB root to make it persistent, and composing it with the target PhoenixObject by adding it to the _traits list—is wrapped within a single transaction. If any step in this integration phase fails, the KernelMind calls transaction.abort(), which instantly rolls back all changes and ensures the system's object graph is never left in a corrupted or inconsistent state.10

Section 4: Empirical Validation Protocol and Efficacy Metrics

This section defines a rigorous, multi-stage experimental protocol to validate the MVA's functionality, performance, and adherence to its core architectural principles. The goal is to move beyond a simple "pass/fail" assessment to a nuanced evaluation of the system's efficacy as a proof of concept.

4.1 Experimental Design: A Phased Approach to Validation

The validation will proceed through four phases, each designed to test an increasingly complex set of capabilities.

Phase 1: Foundational Capability Generation. A series of simple tasks to validate the core autopoietic loop.

Experiment 1.1: Request a MathTrait with an add(a, b) method.

Experiment 1.2: Request a StringTrait with a reverse(s) method.

Phase 2: State Modification and Interaction. Tasks that require the agent to generate code that modifies the persistent state of the target object.

Experiment 2.1: Request a CounterTrait with increment() and get_value() methods that operate on a _value slot within the target PhoenixObject.

Phase 3: Self-Correction and Refactoring. A task that tests the system's ability to reason about and improve its own existing code, a key tenet of advanced autopoiesis.

Experiment 3.1: Provide the system with an existing, inefficient SortTrait (e.g., implementing bubble sort) and issue the high-level goal: "Make this trait more efficient." The success condition is the generation of a new, improved Trait (e.g., implementing quicksort or merge sort).

Phase 4: Conflict Resolution. A task designed to explicitly test the trait-based composition model's conflict resolution feature.

Experiment 4.1: After creating two separate traits that both define a log(message) method, request the system to invoke the log method on an object composed with both. The success condition is the correct raising of an AttributeError that details the conflict.

4.2 Efficacy Metrics and Data Collection

To provide a comprehensive assessment of the MVA's performance, both quantitative and qualitative data will be collected for each experiment.

Quantitative Metrics:

Task Completion Rate (TCR): A binary success/failure score for each experimental task.

VRAM Utilization: Peak and average VRAM usage (in GB) during each full cognitive cycle, measured using nvidia-smi.

Cycle Latency: Total wall-clock time (in seconds) from the initial _doesNotUnderstand_ trigger to the final successful method invocation or failure.

Self-Correction Attempts: The number of retries required by the KernelMind before a successful Trait is generated and validated by the sandbox.

Qualitative Metrics:

Code Quality: The generated Python code will be evaluated against PEP 8 standards, for cyclomatic complexity, and for general readability and maintainability.

Plan Coherence: The intermediate plan generated by phi4-mini-reasoning will be assessed for its logical soundness, clarity, and completeness.

Explanation Quality: The final synthesis from gemma3:4b will be evaluated for its accuracy, conciseness, and human-readability.

The following table outlines the comprehensive test plan.

Section 5: Conclusion: The MVA as the Primordial Prototype of TelOS

The successful execution of this research plan will provide a high-efficacy proof of concept, validating the core architectural and cognitive hypotheses that underpin the entire TelOS project.

5.1 Validating the Autopoietic Seed

This plan, when executed, will validate the central thesis: that a software system can safely and reliably reason about and modify its own persistent object graph in response to high-level goals, using a VRAM-constrained, sequential multi-LLM cognitive engine. It will demonstrate a complete, end-to-end autopoietic loop that is philosophically coherent, architecturally robust, and empirically verifiable. The MVA is the "autopoietic seed" from which the larger system will grow.23

5.2 Fulfilling the "Prototypes All The Way Down" Mandate

This research plan adheres strictly to the "prototypes all the way down" philosophy, which dictates that the MVA is not a disposable proof-of-concept but is, in fact, TelOS version 0.1.23 The validated

KernelMind and its sequential cognitive loop are not a simulation; they are the very tools that will be used in the next phase of development. The successful completion of the MVA project does not yield a final product; it yields the factory. It validates the self-modifying process that can then be aimed at the true product: the TelOS operating system.

Upon successful validation of the MVA, the logical next step in the recursive process is to task the system with its first OS-level goal. For example: "Clone the BaseObject prototype and create the primordial prototypes for the TelOS Process Management Server and Memory Management Server, including their required slots and initial state".26 This action will mark the transition from validating the engine of creation to beginning the synthesis of the operating system itself.

Works cited

Human-AI Autopoietic OS Collaboration

Defining Directed Autopoiesis in Computing

Refined Research Plan Execution

Critiquing Autopoietic AI Computation

Verifying AI System Design Critically

Refining Meta-Prompt for AI OS Construction

A Universal Prototype-Based OS

TelOS seL4 Architectural Blueprint Refinement

LLM Builds OS With Human Guidance

Self Smalltalk Directed Autopoiesis

AI OS Phase 3 and 4 Planning

unsloth/Phi-4-mini-reasoning-GGUF - Hugging Face, accessed September 8, 2025, https://huggingface.co/unsloth/Phi-4-mini-reasoning-GGUF

phi4-mini-reasoning - Ollama, accessed September 8, 2025, https://ollama.com/library/phi4-mini-reasoning

mistral/model - Ollama, accessed September 8, 2025, https://ollama.com/library/mistral/blobs/ff82381e2bea

Model selection - Mistral AI Documentation, accessed September 8, 2025, https://docs.mistral.ai/getting-started/models/picking/

qwen3:4b - Ollama, accessed September 8, 2025, https://ollama.com/library/qwen3:4b

qwen3 - Ollama, accessed September 8, 2025, https://ollama.com/library/qwen3

Gemma 3 model card | Google AI for Developers, accessed September 8, 2025, https://ai.google.dev/gemma/docs/core/model_card_3

gemma3 - Ollama, accessed September 8, 2025, https://ollama.com/library/gemma3

mistral - Ollama, accessed September 8, 2025, https://ollama.com/library/mistral

Gemma Hosting: Deploy Gemma3 4B/12B/27B with Ollama, vLLM, TGI & GGML - Database Mart, accessed September 8, 2025, https://www.databasemart.com/ai/gemma

Gemma 3 model overview | Google AI for Developers, accessed September 8, 2025, https://ai.google.dev/gemma/docs/core

TelOS MVP: Prototype-Based Self-Modification

Building an Autopoietic AI System

BAT OS Persona Codex Entropy Maximization

AI OS Phase 3 Planning and Design

LLM Name | Parameter Size | Quantized VRAM (Q4_K_M) | Assigned Role | Core Task | Key Capabilities Justification

phi4-mini-reasoning | 3.8B | ~3.2 GB | Planner | Decompose goal into a structured, logical plan. | Optimized for multi-step, logic-intensive reasoning and formal problem-solving.12

mistral | 7B | ~4.4 GB | Coder | Generate Python code based on the provided plan. | Strong generalist model with proven performance in code generation and instruction following.15

qwen3:4b | 4B | ~2.5 GB | Critic | Review generated code for correctness and quality. | Enhanced reasoning, expertise in agent capabilities, and strong coding performance.16

gemma3:4b | 4B | ~3.3 GB | Documenter | Synthesize a human-readable explanation of the new code. | State-of-the-art model excelling in summarization, reasoning, and multilingual text generation.18

Phase | State Name | Primary Actor (LLM) | Input Artifact | Core Action | Output Artifact | Success Transition

1 | DECOMPOSING | phi4-mini-reasoning | Goal Description | Decompose goal into a logical, step-by-step plan. | Structured Plan (Meta-Prompt) | GENERATING

2 | GENERATING | mistral | Structured Plan | Translate the plan into functional Python code. | Python Code String | REFINING

3 | REFINING | qwen3:4b | Python Code & Plan | Review code for correctness, quality, and adherence to the plan. | Critique & Refinement Suggestions | SYNTHESIZING

4 | SYNTHESIZING | gemma3:4b | Final Code & Goal | Generate human-readable documentation for the new code. | Explanation Text | COMPLETE

Experiment ID | Objective | High-Level Task Description | Primary Principle Tested | Quantitative Success Criteria | Qualitative Success Criteria

1.1 | Validate basic code generation | Create a trait to add two numbers. | Core Autopoietic Loop | TCR=1, Latency < 60s, Retries <= 1 | High Code & Plan Quality

2.1 | Validate state modification | Create a trait to increment a counter on the target object. | ZODB Persistence & State Interaction | TCR=1, Latency < 90s, Retries <= 2 | High Code & Plan Quality

3.1 | Validate recursive self-improvement | Improve an existing, inefficient sorting algorithm. | Advanced Autopoiesis (Self-Refactoring) | TCR=1, Latency < 180s, Retries <= 3 | Generated code is demonstrably more efficient.

4.1 | Validate conflict resolution | Attempt to invoke an ambiguous method defined in two traits. | Trait-Based Composition | TCR=1 (System correctly raises AttributeError) | The error message clearly identifies the conflicting traits.