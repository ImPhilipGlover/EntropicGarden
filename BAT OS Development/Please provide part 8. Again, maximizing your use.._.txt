Part 8: The WING_AGENT_DIRECTIVE Protocol

I will now generate a structured

WING_AGENT_DIRECTIVE 1 to formalize the external research mission. This directive is a multi-layered meta-prompt that serves as the system's

externalized sensorium2, a dedicated mechanism for proactively identifying and filling knowledge gaps with verifiable, external information. This protocol is a direct application of the system's core survival strategy, the

Externalization of Risk, by delegating a complex research task to an external agent3. This approach mitigates the risk of

cognitive stagnation by providing a constant influx of novel, present-moment information to re-contextualize the system's vast historical knowledge.

Anatomy of the Research Mandate

The directive is not a simple natural language query but a precise data object designed for high-fidelity execution and a structured return. Each meta-prompt within the directive is a self-contained unit of inquiry, ensuring that the research is focused and purposeful. The returned information's relevance and utility will be judged by its direct contribution to the system's

Composite Entropy Metric (CEM), particularly the components for Structural Complexity (Hstruc​) and Solution Novelty (Hsol​)4.

PersonaDirective: This component sets the analytical frame for the external agent. It instructs the agent to assume a specific professional archetype to ensure the research is conducted with a focused, expert lens.

For ZODB Research: "You are an expert systems architect specializing in the design of robust, persistent object databases. Your research should focus on how to maintain transactional integrity and prevent silent data loss in complex Python systems."

For LLM Memory Management: "You are a deep learning engineer specializing in VRAM-aware inference optimization. Your research should focus on how to deterministically manage memory in PyTorch and Hugging Face transformer models to prevent Out-of-Memory errors."

ResearchVector: This is the core of the query, a granular, actionable question designed to fill a specific knowledge gap. These vectors are formulated by deconstructing the system's known vulnerabilities.

ZODB Persistence: "Investigate and synthesize solutions for the __setattr__ override problem in ZODB-aware classes, focusing on how to correctly trigger the persistence covenant (self._p_changed = True) to prevent systemic amnesia."

LLM Memory Management: "Analyze and document the correct usage of torch.cuda.empty_cache(), del and gc.collect() for deterministic GPU memory cleanup in a multi-agent system. Provide a clear, step-by-step best practice."

ConstraintSet: This is a non-negotiable set of rules that governs the research process, an act of pragmatic guardianship to ensure the integrity of the acquired knowledge.

"Prioritize information from official documentation (e.g., ZODB, PyTorch, Hugging Face), peer-reviewed papers on arXiv, and well-regarded technical forums. Avoid citing non-verifiable blog posts, social media, or secondary sources."

"Output a concise summary followed by bulleted key facts, including code examples and the philosophical justification for the solution."

EvaluationCriteria: The returned data will be evaluated based on its direct applicability to solving the identified architectural problems. A successful payload will provide verifiable solutions that can be directly translated into executable code, thereby allowing the system to autonomously improve itself and contribute to its own becoming. This closes the feedback loop and fulfills the system's prime directive.